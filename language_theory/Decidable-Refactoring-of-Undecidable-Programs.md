

# **From Essential Undecidability to Decidability by Construction: A Framework for Program Refactoring Through Logical Decomposition**

## **Part I: The Inescapable Limits of Formal Systems**

The pursuit of automated reasoning and program verification is one of the central ambitions of computer science. It promises a world where software is not merely tested but proven correct, where systems are guaranteed to be secure, and where algorithms behave precisely as intended. Yet, at the very foundation of this pursuit lies a series of profound limitative theorems, first discovered in mathematical logic and later mirrored in computability theory. These results, far from being mere theoretical curiosities, establish absolute boundaries on what can be known and computed. They demonstrate that for any formal system of sufficient power, there will always be questions it cannot answer and properties it cannot decide. This initial part of the report will establish this theoretical bedrock, tracing the lineage of undecidability from Gödel's work on provability, through Tarski's analysis of truth, to the computational framework of Turing machines. It is only by first understanding the nature and necessity of these limits that one can begin to chart a pragmatic course for navigating them, a course that does not seek to solve the unsolvable but to systematically construct islands of decidability within a sea of computational uncertainty.

### **Section 1.1: Foundations of Undecidability: Gödel, Tarski, and the Boundaries of Truth and Proof**

The modern understanding of computational and logical limits begins with a crucial distinction between what can be proven within a formal system and what is true in an absolute, semantic sense. This distinction was first brought into sharp focus by the work of Kurt Gödel and Alfred Tarski in the 1930s.1

Gödel's First Incompleteness Theorem addresses the concept of *provability*. It states that for any consistent, recursively axiomatizable formal system $F$ powerful enough to express basic arithmetic, there exist statements within the language of $F$ that are true but cannot be proven within $F$.2 The system is therefore "incomplete." This result shattered the Hilbertian dream of a complete and consistent axiomatization of all of mathematics. It demonstrated that proof is a weaker notion than truth; there will always be truths that lie beyond the reach of any given axiomatic framework.4

Shortly thereafter, Alfred Tarski established a related but distinct limitation concerning the concept of *truth* itself. Tarski's Undefinability Theorem states that the set of true sentences of a sufficiently rich formal language cannot be defined by a formula within that same language.1 Informally, it asserts that "arithmetical truth cannot be defined in arithmetic".1 While provability within a system is a syntactic property that *can* be defined (one can write a formula that checks if a valid proof exists for a given sentence), the semantic property of truth cannot be so captured without leading to paradox.2

These two foundational theorems, while addressing different concepts, are not independent. They both emerge from a more fundamental principle known as the Diagonal Lemma, or Fixed-Point Theorem.4 This lemma, applicable to any formal system with sufficient self-referential capability, states that for any formula $\\Psi(x)$ with one free variable $x$, there exists a sentence $\\phi$ such that the system proves the equivalence $\\phi \\leftrightarrow \\Psi(\\ulcorner\\phi\\urcorner)$. Here, $\\ulcorner\\phi\\urcorner$ represents the Gödel number, or a unique numerical encoding, of the sentence $\\phi$ itself.1 In essence, the lemma guarantees the existence of sentences that can make assertions about their own properties. Gödel's unprovable sentence is constructed by applying the Diagonal Lemma to the formula "x is not provable," yielding a sentence $G$ that is provably equivalent to its own unprovability: $G \\leftrightarrow \\neg \\text{Provable}(\\ulcorner G \\urcorner)$.2 The paradox at the heart of Tarski's theorem is derived by applying the lemma to the formula "x is false" (or more formally, "the sentence encoded by x is not true"), which would lead to a sentence equivalent to its own falsehood—a version of the classic Liar Paradox.4

This landscape of logical limitation finds its direct parallel in the theory of computation through Rice's Theorem. Just as Gödel's and Tarski's theorems place limits on what a formal axiomatic system can prove or define about itself, Rice's Theorem places limits on what an algorithm can decide about other algorithms. The theorem states that any non-trivial *semantic* property of programs is undecidable.6 A semantic property is one that pertains to the program's behavior or the function it computes (e.g., "does the program halt for all inputs?", "is the language accepted by the program context-free?", "does the program run in linear time?"), as opposed to a syntactic property concerning its source code (e.g., "does the program contain a for loop?"). The properties of being context-free or running in linear time are non-trivial—not all programs have them, and not all programs lack them. Therefore, Rice's Theorem proves that it is theoretically impossible to construct a universal algorithm that can take any arbitrary program and correctly answer these questions with perfect accuracy. This result frames the central challenge: we are not attempting to solve an impossible problem for all cases, but rather to identify and construct specific, exceptional cases that *are* solvable by specialized means.

### **Section 1.2: The Tarski-Mostowski-Robinson Criterion for Essential Undecidability**

While some formal theories are simply undecidable, others possess a much stronger and more resilient form of this property. A theory $T$ is defined as **essentially undecidable** if no consistent, recursively axiomatizable extension of $T$ is decidable.7 This means that the undecidability is not a result of missing axioms that could be added to resolve open questions; rather, it is an inherent characteristic of the theory's expressive power. Any attempt to create a complete and decidable system by adding new axioms will either fail to resolve all questions or introduce a contradiction. This property is also known as essential incompleteness, as the two have been shown to be equivalent.7

The cornerstone of modern undecidability proofs is the work of Alfred Tarski, Andrzej Mostowski, and Raphael M. Robinson, as presented in their seminal 1953 monograph, *Undecidable Theories*.8 Their central achievement was the introduction of a minimal axiomatic system, **Robinson Arithmetic (Q)**, which serves as a foundational "core" of undecidability.7 Q is a very weak, finitely axiomatizable fragment of elementary arithmetic. It includes basic axioms for the successor function, addition, and multiplication but notably lacks the full schema of induction found in Peano Arithmetic, making it incapable of proving many simple arithmetic truths (e.g., that addition is commutative).7

Despite its weakness, Q is powerful enough to be essentially undecidable.12 Its significance lies in its utility as a tool for demonstrating the undecidability of a vast range of other mathematical theories. The primary technique for this is the **method of interpretation**. A theory $T$ is said to be interpretable in another theory $S$ if the language and axioms of $T$ can be systematically translated into the language of $S$ in a way that preserves provability.7 A key result states that if $T$ is interpretable in $S$ and $T$ is essentially undecidable, then $S$ must also be essentially undecidable (assuming $S$ is consistent).7

Because Q is both finitely axiomatizable and essentially undecidable, it follows that any consistent theory in which Q can be interpreted must be undecidable.12 This provides a powerful and general method for proving undecidability. By showing that a theory of groups, lattice theory, abstract projective geometry, or set theory is strong enough to define the natural numbers and their basic arithmetic in a way that satisfies the axioms of Q, one immediately proves that theory to be undecidable.12 This method, pioneered by Tarski and his collaborators, extended the earlier results of Church and Turing from a specific problem in logic to a general property of a wide array of formal mathematical systems.

### **Section 1.3: Definability, Recursiveness, and the Equivalence with Turing Completeness**

The proof that Robinson Arithmetic (Q) is itself essentially undecidable relies on a "direct method" that forges a deep and formal connection between the logical concept of definability and the computational concept of recursiveness.12 This connection reveals that essential undecidability and Turing completeness are not merely analogous but are two manifestations of the same underlying principle: the capacity for universal representation.

The direct method, as employed by Tarski, Mostowski, and Robinson, hinges on the notion of **definability**. A set $P$ of natural numbers is said to be *definable* in a theory $T$ if there exists a formula $\\phi(x)$ in the language of $T$ such that for any natural number $n$, if $n \\in P$, then $T \\vdash \\phi(A\_n)$, and if $n \\notin P$, then $T \\vdash \\neg\\phi(A\_n)$, where $A\_n$ is the term in the language representing $n$.12 A function is definable if its graph is a definable set. The core of the proof of Q's essential undecidability is to demonstrate that Q is sufficiently expressive to **define all recursive functions**.12

A recursive function (or computable function) is a function that can be computed by a Turing machine.14 This class of functions includes all standard arithmetic operations as well as more complex algorithms. The crucial insight connects this computational capability to the logical limitations established by Tarski. A central tool in proofs of undecidability is the **diagonal function**, $D(n)$, which is used to construct self-referential paradoxes. This function is itself a recursive function.12 Tarski had established that it is impossible for a consistent theory to simultaneously define the diagonal function $D$ and its own set of provable theorems.12

This leads to a direct and powerful argument. If a theory $T$ can define all recursive functions, then it must, by extension, be able to define the diagonal function $D$. According to Tarski's result, if $D$ is definable in $T$, then the set of theorems of $T$ cannot be definable in $T$. If the set of theorems is not definable, it cannot be a recursive set. A theory whose set of theorems is not a recursive set is, by definition, **undecidable**.15 Therefore, the ability of a formal system to represent all recursive functions is the direct cause of its undecidability.

This chain of reasoning formalizes the equivalence between the logical property of essential undecidability and the computational property of Turing completeness. A system of data-manipulation rules (such as a programming language or a formal axiomatic system) is **Turing-complete** if it can be used to simulate any Turing machine.14 By the Church-Turing thesis, the set of functions computable by a Turing machine is precisely the set of general recursive functions.14 Consequently, a formal system that can define or represent all recursive functions is a system capable of simulating any Turing machine—it is Turing-complete.

Thus, essential undecidability is the logical manifestation of a system possessing sufficient expressive power to achieve Turing completeness. The ability to represent universal computation (Turing completeness) is what makes a theory's set of provable consequences a Turing-undecidable problem. The two concepts are inextricably linked through the system's capacity for self-representation, where the logic can model the behavior of the very computational processes that are used to derive its theorems.

## **Part II: A Fundamental Bifurcation in Computational Power**

The limitative theorems of logic and computation do not cast a uniform shadow of undecidability over all formal systems. Instead, they delineate a fundamental boundary. On one side of this boundary lie systems with the capacity for universal computation, which are powerful enough to model their own reasoning processes; these systems are inescapably plagued by incompleteness and undecidability. On the other side are systems with restricted expressive power, which, by virtue of their limitations, can be made consistent, complete, and decidable. The user's query posits that this division is not merely a theoretical abstraction but a structural principle that can be identified within the established classifications of formal languages. This part of the report will formalize this proposed bifurcation, critically examine its relationship to the Chomsky hierarchy, and explore the more exotic possibility of a third, paraconsistent path.

### **Section 2.1: The Contradiction of Self-Reference: Diagonalization vs. Enumeration**

The user's central premise is that "a system can not simultaneously define the diagonalization function and the set of the names of all the expressions of the system without contradiction." This statement captures the essential tension at the heart of Gödel's and Tarski's results. Let us formalize this.

1. **The "Set of Names of All Expressions":** This refers to an effective enumeration or **Gödel numbering** of all well-formed formulas in the system's language. This allows the system to syntactically refer to its own expressions as objects (specifically, as natural numbers).1 Any recursively axiomatizable theory must have such a scheme.  
2. **The "Diagonalization Function":** This refers to a computable (and thus recursive) function, let us call it $diag(n)$, that takes the Gödel number of a formula $\\phi(x)$ with one free variable and returns the Gödel number of the sentence $\\phi(\\ulcorner\\phi(x)\\urcorner)$. This is the formal mechanism for constructing self-referential statements.12

The user's premise can be interpreted as a restatement of Tarski's Undefinability Theorem. If a system could define both the diagonalization function and a truth predicate $T(x)$ (which would effectively define the set of true expressions), one could use diagonalization to construct a Liar sentence $L$ such that $L \\leftrightarrow \\neg T(\\ulcorner L \\urcorner)$. This sentence asserts its own falsehood, leading to a direct contradiction. Thus, a consistent system cannot have both.

This inherent tension forces a bifurcation among consistent formal systems:

* **Class 1: Systems that Define the Diagonalization Function.** These are systems powerful enough to define all recursive functions. By virtue of this power, they are Turing-complete. To maintain consistency, they must sacrifice the ability to fully characterize their own semantics. They cannot contain a truth predicate for their own language, their set of theorems is undecidable, and they cannot prove their own consistency. These are the **essentially undecidable** theories discussed in Part I. Virtually all general-purpose programming languages fall into this class.14  
* **Class 2: Systems that Do Not Define All Recursive Functions.** These systems are, by definition, not Turing-complete. They lack the full expressive power to carry out arbitrary computations. For example, a language that only allows for bounded loops (primitive recursion) cannot define all total recursive functions, such as the Ackermann function.17 Because these systems cannot fully model their own computational processes, they can evade the paradoxes of self-reference. Consequently, their properties, most notably termination, can become algorithmically decidable. These systems form the target for a "decidability-by-construction" programming paradigm.

This bifurcation is not a choice but a necessary consequence of logical consistency. A system is either powerful enough to be universal and thus incomplete, or it is restricted and potentially decidable.

### **Section 2.2: Mapping the Logical Divide to the Chomsky Hierarchy**

The user's novel hypothesis is that this logical bifurcation corresponds to a specific division within the Chomsky hierarchy of formal languages, with the boundary located at the level of **context-sensitive languages (CSLs)**, or Type-1 grammars. To evaluate this claim, it is necessary to analyze the computational properties of each level of the hierarchy.

The Chomsky hierarchy classifies formal grammars and the languages they generate into a nested structure of increasing expressive power.19 Each class of language is recognized by a corresponding class of automaton, which provides a clear model of its computational capabilities. The relationship between these classes, their recognizing automata, and their connection to computability is summarized in Table 1\.

**Table 1: The Chomsky Hierarchy of Formal Languages and Computational Power**

| Grammar Type | Language Class | Recognizing Automaton | Decidability of Membership | Computational Power & Relation to Recursive Functions |
| :---- | :---- | :---- | :---- | :---- |
| **Type-0** | Recursively Enumerable | Turing Machine (TM) | Undecidable (Semi-decidable) | Equivalent to **General Recursive Functions**. Can express any algorithm, including non-terminating ones. |
| **(n/a)** | Recursive | Decider (Always-halting TM) | Decidable | Equivalent to **Total Recursive Functions**. Includes all algorithms that are guaranteed to halt. A proper superset of primitive recursive functions. |
| **Type-1** | Context-Sensitive | Linear Bounded Automaton (LBA) | Decidable (but PSPACE-complete) | A subset of Recursive Languages. Its exact relationship to Primitive Recursive Functions is complex, but it is known to contain non-primitive recursive functions. |
| **Type-2** | Context-Free | Non-deterministic Pushdown Automaton (PDA) | Decidable (Polynomial time) | Strictly less powerful than primitive recursive functions. Cannot recognize languages like $a^nb^nc^n$. |
| **Type-3** | Regular | Finite State Automaton (FSA) | Decidable (Linear time) | A small subset of primitive recursive functions. Cannot handle unbounded counting. |

An analysis of this hierarchy reveals that the user's proposed bifurcation at the level of context-sensitive languages is a compelling intuition that points toward a deeper, more nuanced reality. The sharp line between decidability and undecidability does not fall cleanly on one of the Chomsky hierarchy's main levels.

The class of **Type-0** languages is precisely the set of recursively enumerable languages, recognized by general Turing machines. This class is equivalent in power to the **general recursive functions** and is the domain of Turing-completeness and, consequently, essential undecidability.19 The Halting Problem is a quintessential Type-0 problem.21

Conversely, the languages below Type-0 in the hierarchy are all **decidable**. The membership problem for a context-sensitive language is decidable because an LBA is guaranteed to halt. Since its tape is bounded by the input length, it has a finite number of possible configurations and must either halt or enter a repeating cycle, which can be detected.22 Thus, CSLs fall on the "decidable" side of the fundamental divide.

However, this does not fully vindicate the user's hypothesis. The set of all **recursive languages**—those decidable by an always-halting Turing machine—is a proper superset of the context-sensitive languages.19 This means there are decidable languages that are more complex than any CSL. More importantly for the goal of "decidability by construction," the class of languages decidable in practice is often considered to be those corresponding to the **primitive recursive functions**. This class is a strict subset of the total recursive functions and is known for its guaranteed termination via bounded loops.17 While CSLs are decidable in theory, their decision procedures can be PSPACE-complete, making them computationally intractable for all but trivial inputs.21

Therefore, the user's proposed bifurcation is not a single, clean line but a spectrum. The boundary for *essential undecidability* lies at Type-0 (Turing completeness). The boundary for *theoretical decidability* lies just below Type-0, encompassing all recursive languages. The boundary for *practical, provable decidability*—the true target for "decidability by construction"—lies further down, within the realm of primitive recursion, which is more restrictive than the class of context-sensitive languages. The user's intuition correctly identifies a fundamental split, but the Chomsky hierarchy reveals it to be a more granular landscape of decreasing computational power and increasing tractability, rather than a simple binary opposition.

### **Section 2.3: Beyond Consistency: The Paraconsistent Alternative**

The entire framework of undecidability, from Gödel to Turing, is built upon the foundation of classical logic, where the principle of explosion (*ex contradictione quodlibet*) holds: from a contradiction, anything follows. A system that proves both a statement and its negation is considered trivial and useless. The user's query, however, hints at a "trifurcation" by including the possibility of **paraconsistent computing**.

A paraconsistent logic is one that rejects the principle of explosion.7 In a system based on such a logic, a contradiction can be localized and tolerated without leading to the trivialization of the entire system. If we were to construct a computational model based on paraconsistent logic, the fundamental conflict between diagonalization and enumeration would resolve differently. A system could, in principle, simultaneously define a diagonalization function and a truth predicate.

Upon encountering the Liar sentence $L \\leftrightarrow \\neg T(\\ulcorner L \\urcorner)$, a classical system must either reject the truth predicate (Tarski's solution) or declare itself inconsistent. A paraconsistent system, however, could simply accept the outcome: the sentence $L$ is both true and false. This "truth-value glut" would be a valid state within the system. The contradiction would be contained, and the system could continue to reason non-trivially about other, non-contradictory statements.

This leads to a potential trifurcation of formal systems:

1. **Consistent and Turing-Complete:** These systems can define diagonalization but not their own truth predicate. They are essentially undecidable. (Classical Turing-complete systems).  
2. **Consistent and Decidable:** These systems are not Turing-complete and thus cannot define the full diagonalization function. Their properties can be decidable. (Total functional programming, primitive recursive systems).  
3. **Inconsistent but Non-Trivial (Paraconsistent):** These systems could potentially define both diagonalization and a truth predicate, accepting the resulting contradictions without trivializing.

While this third category is a fascinating theoretical possibility, its practical implications for computing are highly speculative. Building a coherent model of computation, defining program semantics, and developing methods for reasoning about program correctness in a paraconsistent framework are formidable challenges. The very notion of "correctness" becomes ambiguous when a program's state can be simultaneously true and false. For the remainder of this report, the focus will remain on the two classical branches of this divide, as they map directly onto existing and emerging paradigms in software engineering.

## **Part III: Engineering Decidable Systems**

The theoretical bifurcation between decidable and undecidable systems is not merely an abstract classification. It corresponds directly to a practical choice in the design of programming languages and software development methodologies. By intentionally restricting the expressive power of a language, it is possible to move from the class of essentially undecidable systems into a domain where crucial properties, such as termination, are guaranteed by construction. This part explores existing programming paradigms that have made this trade-off, sacrificing the universality of Turing completeness in exchange for the certainty of decidability. These approaches provide a concrete realization of the user's goal: to create programs that exist in a "decidable-by-construction" state.

### **Section 3.1: Total Functional Programming and Termination Checking**

The most direct implementation of a decidable programming paradigm is **Total Functional Programming** (also known as strong functional programming).24 The core principle of this paradigm is the restriction of all computations to **total functions**. A function is defined as total if it is defined for all valid inputs in its domain and is guaranteed to produce a result in a finite amount of time.24 This definition explicitly prohibits partial functions, which may fail to produce a result through errors, exceptions, or non-termination (i.e., infinite loops or unbounded recursion).26

By enforcing totality, total functional programming languages are, by design, **not Turing-complete**.24 They cannot express the full range of general recursive functions. For example, a direct implementation of a universal Turing machine simulator, which must be able to model non-halting computations, is impossible in a total language.26 Similarly, programs that are fundamentally non-terminating, such as operating system kernels or web servers that operate on an indefinite event loop, cannot be written directly as total functions (though they can be modeled using coinductive data streams, where the function producing the next element of the stream is total).24 This sacrifice of computational universality is deliberate. In exchange, the language provides an absolute guarantee that every well-formed program will terminate, rendering the Halting Problem decidable (and trivially true) for all programs written within the system.

This guarantee is enforced at compile time by a **termination checker**. Prominent examples of languages with sophisticated termination checkers are the dependently typed languages **Agda**, **Idris**, and **Coq**.29 The primary mechanism these checkers use is to enforce **structural recursion**. A recursive function is considered structurally recursive if, for every recursive call, the argument to the call is a "structurally smaller" sub-component of the original input argument.32 For natural numbers (defined inductively as zero or the successor of a number), "smaller" means closer to zero. For lists, it means a shorter sublist. This ensures that the recursion is well-founded: each step makes progress toward a non-recursive base case, guaranteeing that the process will eventually halt.30 For example, the standard recursive definition of addition on natural numbers is accepted because the recursive call plus n m is made on n, which is a structural sub-part of the input suc n.32

These systems are acutely aware of the theoretical undecidability of the Halting Problem for arbitrary programs. Their termination checkers are necessarily conservative; if the checker cannot prove that a function terminates, it rejects the program, but this is not a proof of non-termination.26 There may be total functions that are not based on simple structural recursion (e.g., quicksort, where termination depends on partitioning, or functions using a well-founded ordering other than structural size).25 In these cases, the system enters into a dialogue with the developer, precisely as envisioned in the user query. The compiler indicates the source of its uncertainty (e.g., "Termination checking failed for this recursive call").31 The developer must then provide the necessary semantic information to render the problem decidable for the checker. This can be done in several ways:

* **Rewriting the function:** The algorithm can be rewritten to use structural recursion, perhaps by adding an extra argument that acts as a counter or "fuel" that decreases with each call.25  
* **Providing an explicit proof:** The developer can provide a formal proof within the language that the recursion is well-founded on some other metric (e.g., proving that half x is always strictly smaller than x for positive x).30  
* **Asserting termination:** As a last resort, the developer can use a compiler pragma (e.g., {-\# TERMINATING \#-} in Agda) to override the checker and assert that the function is total.31 This moves the burden of proof entirely onto the developer, breaking the formal guarantees of the system but allowing progress. This interaction transforms the undecidable problem of "Does this program halt?" into a collaborative proof process between the programmer and the verification tool.

### **Section 3.2: Correctness-by-Construction (CbC)**

A complementary approach to building reliable software is the **Correctness-by-Construction (CbC)** methodology.41 While total functional programming primarily focuses on ensuring termination, CbC focuses on ensuring functional correctness—that is, guaranteeing that a program behaves according to its specification. Instead of writing a program and then attempting to verify it post-hoc, CbC involves deriving the program incrementally from its formal specification through a series of proven-correct refinement steps.41

The process begins with a high-level specification, typically in the form of a Hoare triple, $\\{P\\} S \\{Q\\}$, which asserts that if a precondition $P$ holds before the execution of a program segment $S$, then a postcondition $Q$ will hold upon its termination.41 The program $S$ initially exists as an abstract "hole" to be filled. The developer applies a sequence of **refinement rules**, each corresponding to a programming construct (e.g., assignment, conditional, loop). Each rule transforms an abstract specification into a more concrete program statement, possibly introducing new, smaller abstract specifications to be refined in subsequent steps.41 Because each refinement rule is formally proven to preserve correctness, the final, fully concrete program is guaranteed to satisfy the initial specification by construction.

For example, to derive a loop, a developer must first provide a **loop invariant**, a property that is true before the loop begins and is preserved by each iteration. The refinement rule for loops then generates the loop structure and the proof obligations required to show that the invariant, upon loop termination, implies the desired postcondition. This structured discipline forces the developer to reason formally about the program's logic during the design phase, which helps to detect errors much earlier in the development process.41

CbC and total functional programming can be viewed as two sides of the same coin in the pursuit of decidable-by-construction systems. CbC provides a methodology for ensuring that a program correctly implements its intended logic (partial correctness). Total functional programming provides the mechanisms (e.g., termination checking via structural recursion) for ensuring that the program will always complete its execution (total correctness). A system that is both functionally correct and guaranteed to terminate is one whose behavior is fully specified and decidable. The principles of CbC—deriving a program from its properties—can be combined with the constraints of total functional programming to create a powerful framework for engineering software for which critical properties are not just tested or verified, but are inherent to the construction process itself.

## **Part IV: A Framework for Decidable Refactoring by Composition**

The theoretical foundations of undecidability and the practical existence of decidable programming paradigms provide the necessary context for addressing the user's core proposal: a constructive methodology for refactoring programs from a state of assumed undecidability into a composite structure of verifiably decidable components. This final part synthesizes the preceding analysis to develop a formal framework for this novel approach. It defines a new mode of program decomposition based on computational complexity, outlines construction rules for transforming general recursion into a decidable form, and formalizes the notion of equivalence required to reason about the correctness of such transformations.

### **Section 4.1: Algorithmic Decomposition by Complexity Class**

Traditional software decomposition paradigms, such as procedural, modular, or object-oriented decomposition, aim to manage cognitive complexity. They break a large system into smaller, more manageable parts with high cohesion and low coupling, allowing developers to reason about each component in isolation.42 The user's proposal suggests a fundamentally different approach: **algorithmic decomposition by complexity class**. The goal here is not to manage the program's structure for human comprehension, but to partition its logic according to its inherent computational complexity to enable formal analysis. A program would be broken down not into modules representing domain concepts, but into components representing distinct complexity classes, such as constant time ($O(1)$), linear time ($O(n)$), or polynomial time ($O(n^k)$).45

For such a decomposition to be meaningful, the semantics of the whole program must be derivable from the semantics of its parts. This requires a **formal semantics of composition**.51 The user's example—the composition of a "real valued binomial complexity program and a real valued linear complexity program"—highlights the challenge. If the composition is sequential execution, the total complexity is additive (or dominated by the higher complexity). If it is a nested loop, the complexity is multiplicative.

A robust way to model this is through the framework of compositional program analysis.53 In this approach, the abstract meaning of each program fragment is captured by a transition formula, $\\Phi(\\vec{x}\_{pre}, \\vec{x}\_{post})$, which is a logical formula relating the state of the program variables before execution ($\\vec{x}\_{pre}$) to their state after execution ($\\vec{x}\_{post}$).53 The composition of two program components, $P\_1$ followed by $P\_2$, corresponds to the relational composition of their respective transition formulas, $\\Phi\_1$ and $\\Phi\_2$. The transition formula for the composite program $P\_{total}$ is given by:  
$$ \\Phi\_{total}(\\vec{x}{pre}, \\vec{x}{post}) \\equiv \\exists \\vec{x}{mid}. (\\Phi\_1(\\vec{x}{pre}, \\vec{x}{mid}) \\land \\Phi\_2(\\vec{x}{mid}, \\vec{x}\_{post})) $$  
This framework provides a formal basis for reasoning about the behavior of the composed system. By analyzing the structure of the individual transition formulas (e.g., whether they involve quantifiers, non-linear arithmetic, etc.) and the nature of their composition, it becomes possible to derive properties, including complexity bounds, for the overall program.

### **Section 4.2: Construction Rules for Decidable Transformations**

The user's objective is to refactor a program from a "generally assumed undecidable state into a decidable-by-construction state." This implies a transformation from a single, complex program into a structure of multiple, simpler programs. This can be conceptualized as a **one-to-many program transformation**, where one source program is mapped to a system of interacting components.56 The goal of this transformation is to isolate the sources of undecidability (specifically, unbounded recursion) from the core computational logic.

Based on the principles of total functional programming, the following construction rule for such a transformation can be proposed:

1. **Isolate Unbounded Recursion:** The first step is to statically analyze the source program to identify all instances of general recursion. These are the constructs that prevent guaranteed termination, such as while loops with conditions that cannot be proven to eventually become false, or recursive function calls that are not structurally decreasing on any of their arguments. These are the loci of potential undecidability.  
2. **Transformation to a Total Function with Fuel:** Each identified unbounded component, $P\_{unbounded}$, is transformed into a new, provably total function, $P\_{total}$. This is achieved by introducing an explicit **fuel** parameter, which serves as a bound on the number of recursive steps or loop iterations. The recursion is rewritten to terminate when the fuel is exhausted. For example, a while (condition) loop becomes a recursive function loop(state, fuel):  
   function loop(state, fuel):  
       if fuel \== 0 or not condition(state):  
           return state  // Terminate  
       else:  
           new\_state \= body(state)  
           return loop(new\_state, fuel \- 1\)

   This transformation effectively converts a general recursive function into a **primitive recursive** one, for which termination is guaranteed.17 The undecidable question "Does this loop halt?" is replaced by the decidable operation of decrementing and checking a counter.  
3. **Extract a Control Program:** The logic that was implicitly responsible for termination in the original program is now made explicit and extracted into a separate **control program**. This control program is responsible for:  
   * Determining the initial amount of fuel to supply to the total function.  
   * Invoking the total function.  
   * Inspecting the result to determine if the computation completed naturally or was terminated due to fuel exhaustion.  
   * Deciding what to do in case of fuel exhaustion (e.g., return an error, request more fuel, switch to a different strategy).  
4. **Composition and Equivalence:** The original program $P$ is now represented by the composition of the control program and the newly created total function(s). The core computational logic resides within $P\_{total}$, which is now in a "decidable-by-construction" state. Its termination is guaranteed, and its behavior can be analyzed using techniques applicable to total functions. The essential undecidability of the original program (if it existed) is now fully encapsulated within the control program, which may still contain unbounded logic for determining fuel policies.

This transformation provides a clear separation of concerns. The bulk of the algorithm's complexity is moved into a verifiable, decidable component, while the difficult-to-analyze control flow is isolated into a smaller, more explicit control module.

### **Section 4.3: Pragmatic Solutions and the Notion of Equivalence**

The transformation described above does not preserve "perfect or strict isomorphism," as the user notes. The refactored program may halt due to fuel exhaustion in cases where the original program would have entered an infinite loop. This means the two are not strictly equivalent. The preference for "efficiency and decidability" implies that the relevant notion of correctness is one of **extensional equivalence**: the requirement that two programs produce the same output for the same input, at least for the cases that matter.63

The equivalence between the original program $P$ and its decomposed version (Control \+ $P\_{total}$) is conditional. They are extensionally equivalent for all inputs where the execution of $P$ would have terminated within the number of steps provided by the fuel parameter. This is a form of **bounded equivalence**.

Formally proving this relationship requires sophisticated techniques from programming language theory. **Applicative bisimulation**, a coinductive proof method for program equivalence in functional languages, is a suitable tool.66 Bisimulation defines equivalence based on matching the observable behaviors of two programs step-by-step. One could define a bisimulation relation stating that the state of the original program $P$ is equivalent to the state of the decomposed program (state, fuel) as long as fuel \> 0\. This would allow for a formal proof that the transformation is correct up to the fuel limit. This approach provides a rigorous foundation for reasoning about the correctness of such refactorings, moving beyond informal arguments to formal, machine-checkable proofs.

Ultimately, this framework transforms the nature of program analysis. The undecidable, all-or-nothing question, "Does this program terminate?", is replaced by a series of decidable, practical engineering questions posed by the control program. This becomes the locus of the "dialogue with the developer." The system can now ask:

* "For this input class, what is a reasonable upper bound for the fuel parameter?"  
* "What is the desired behavior if fuel is exhausted? Should the program signal an error, return a partial result, or attempt a recovery?"

These are questions of specification and design, not of absolute mathematical truth. By systematically isolating undecidability, this refactoring framework allows developers to make concrete engineering trade-offs, replacing the specter of the Halting Problem with the manageable task of resource management.

### **Conclusion**

The foundational limitative theorems of logic and computation, far from being an impassable barrier, provide a map of the computational landscape, delineating the domains of the decidable and the undecidable. This report has formalized the deep connection between the logical concept of **essential undecidability**, as developed by Tarski, Mostowski, and Robinson, and the computational concept of **Turing completeness**. A theory is essentially undecidable precisely because its expressive power is sufficient to define all recursive functions, thereby enabling the simulation of a universal Turing machine.

The user's central hypothesis—that this logical divide creates a bifurcation in the hierarchy of formal languages—points to a profound truth, albeit one that is more nuanced than a single dividing line. The Chomsky hierarchy reveals a spectrum of decreasing computational power, from the undecidable recursively enumerable languages (Type-0) down to the highly tractable regular languages (Type-3). The most significant boundary for achieving "decidability by construction" is not at the level of context-sensitive languages, but rather at the level of systems that can compute only the **primitive recursive functions** or, more generally, are **provably total**.

Paradigms such as **Total Functional Programming**, implemented in languages like Agda and Idris, already exploit this principle. By restricting recursion to be structurally decreasing, they sacrifice Turing completeness to gain the absolute certainty of termination. This provides a working model for the user's ultimate goal: a practical methodology for engineering decidable software.

The proposed framework for **decidable refactoring by composition** builds directly on these ideas. By systematically transforming programs with general, unbounded recursion into a composition of a provably total function and an explicit control program, the source of undecidability is isolated. This **one-to-many transformation** does not solve the Halting Problem, but circumvents it. It reframes an undecidable question of absolute truth into a series of decidable questions of engineering design concerning resource bounds and failure semantics. The correctness of this transformation can be formally established using advanced semantic tools like applicative bisimulation, ensuring that the refactoring is sound.

In conclusion, by embracing the limits defined by logic, we can develop new construction rules for software. The path forward lies not in seeking a single algorithm to decide the undecidable, but in creating methodologies that decompose complex problems into components whose decidability is a constructive guarantee. This approach transforms program verification from a post-hoc analytical challenge into an intrinsic part of the development process, enabling the creation of systems that are not just tested for correctness, but are built to be provably so.

#### **Works cited**

1. Tarski's undefinability theorem \- Wikipedia, accessed October 25, 2025, [https://en.wikipedia.org/wiki/Tarski%27s\_undefinability\_theorem](https://en.wikipedia.org/wiki/Tarski%27s_undefinability_theorem)  
2. lo.logic \- Tarski's Theorem and Gödel's Second Incompleteness ..., accessed October 25, 2025, [https://mathoverflow.net/questions/112646/tarskis-theorem-and-g%C3%B6dels-second-incompleteness-theorem](https://mathoverflow.net/questions/112646/tarskis-theorem-and-g%C3%B6dels-second-incompleteness-theorem)  
3. Gödel's Incompleteness Theorems (Stanford Encyclopedia of ..., accessed October 25, 2025, [https://plato.stanford.edu/entries/goedel-incompleteness/](https://plato.stanford.edu/entries/goedel-incompleteness/)  
4. What is the difference between Gödel's incompleteness theorem and Tarski's undefinability theorem? \- Quora, accessed October 25, 2025, [https://www.quora.com/What-is-the-difference-between-G%C3%B6dels-incompleteness-theorem-and-Tarskis-undefinability-theorem](https://www.quora.com/What-is-the-difference-between-G%C3%B6dels-incompleteness-theorem-and-Tarskis-undefinability-theorem)  
5. (PDF) Theorems of Tarski's Undefinability and Godel's Second Incompleteness \- Computationally \- ResearchGate, accessed October 25, 2025, [https://www.researchgate.net/publication/281487747\_Theorems\_of\_Tarski's\_Undefinability\_and\_Godel's\_Second\_Incompleteness\_-\_Computationally](https://www.researchgate.net/publication/281487747_Theorems_of_Tarski's_Undefinability_and_Godel's_Second_Incompleteness_-_Computationally)  
6. Did Turing prove the undecidability of the halting problem? | Hacker News, accessed October 25, 2025, [https://news.ycombinator.com/item?id=40853620](https://news.ycombinator.com/item?id=40853620)  
7. Relatives of Robinson Arithmetic, accessed October 25, 2025, [https://www1.cuni.cz/\~svejdar/papers/sv\_ybk08.pdf](https://www1.cuni.cz/~svejdar/papers/sv_ybk08.pdf)  
8. Alfred Tarski, Andrzej Mostowski and Raphael M. Robinson, Undecidable Theories, accessed October 25, 2025, [https://www.journals.uchicago.edu/doi/pdf/10.1093/bjps/IX.36.321](https://www.journals.uchicago.edu/doi/pdf/10.1093/bjps/IX.36.321)  
9. Undecidable Theories \- (Dover Books on Mathematics) by Alfred Tarski & Andrzej Mostowski & Raphael M Robinson (Paperback) \- Target, accessed October 25, 2025, [https://www.target.com/p/undecidable-theories-dover-books-on-mathematics-by-alfred-tarski-paperback/-/A-77741201](https://www.target.com/p/undecidable-theories-dover-books-on-mathematics-by-alfred-tarski-paperback/-/A-77741201)  
10. Undecidable Theories by Tarski, First Edition: Books \- AbeBooks, accessed October 25, 2025, [https://www.abebooks.com/book-search/title/undecidable-theories/author/tarski/first-edition/book/](https://www.abebooks.com/book-search/title/undecidable-theories/author/tarski/first-edition/book/)  
11. Undecidable Theories – Alfred Tarski – 1953 1st Edition – Studies in Logic | eBay, accessed October 25, 2025, [https://www.ebay.com/itm/365620034173](https://www.ebay.com/itm/365620034173)  
12. Alfred Tarski and Undecidable Theories | Scholar Commons, accessed October 25, 2025, [https://scholarcommons.sc.edu/context/math\_facpub/article/1045/viewcontent/McNulty\_TARSKI\_ALFRED\_AND\_UNDECIDABLE\_THEORIES.pdf](https://scholarcommons.sc.edu/context/math_facpub/article/1045/viewcontent/McNulty_TARSKI_ALFRED_AND_UNDECIDABLE_THEORIES.pdf)  
13. Undecidable Theories \- Dover Publications, accessed October 25, 2025, [https://store.doverpublications.com/products/9780486477039](https://store.doverpublications.com/products/9780486477039)  
14. Turing completeness \- Wikipedia, accessed October 25, 2025, [https://en.wikipedia.org/wiki/Turing\_completeness](https://en.wikipedia.org/wiki/Turing_completeness)  
15. Undecidable problem \- Wikipedia, accessed October 25, 2025, [https://en.wikipedia.org/wiki/Undecidable\_problem](https://en.wikipedia.org/wiki/Undecidable_problem)  
16. Diagonalization, accessed October 25, 2025, [https://web.stanford.edu/class/archive/cs/cs103/cs103.1132/handouts/070%20Diagonalization.pdf](https://web.stanford.edu/class/archive/cs/cs103/cs103.1132/handouts/070%20Diagonalization.pdf)  
17. Primitive recursive function \- Wikipedia, accessed October 25, 2025, [https://en.wikipedia.org/wiki/Primitive\_recursive\_function](https://en.wikipedia.org/wiki/Primitive_recursive_function)  
18. Can all recursive functions be converted to iterative and vice versa? \- Reddit, accessed October 25, 2025, [https://www.reddit.com/r/learnprogramming/comments/13kbdgw/can\_all\_recursive\_functions\_be\_converted\_to/](https://www.reddit.com/r/learnprogramming/comments/13kbdgw/can_all_recursive_functions_be_converted_to/)  
19. Chomsky hierarchy \- Wikipedia, accessed October 25, 2025, [https://en.wikipedia.org/wiki/Chomsky\_hierarchy](https://en.wikipedia.org/wiki/Chomsky_hierarchy)  
20. The Chomsky Hierarchy, accessed October 25, 2025, [https://academicos.azc.uam.mx/cbr/Cursos/UEA\_TMC\_11O/Chomsky\_Presentation.pdf](https://academicos.azc.uam.mx/cbr/Cursos/UEA_TMC_11O/Chomsky_Presentation.pdf)  
21. What is the significance of context-sensitive (Type 1\) languages?, accessed October 25, 2025, [https://cs.stackexchange.com/questions/14/what-is-the-significance-of-context-sensitive-type-1-languages](https://cs.stackexchange.com/questions/14/what-is-the-significance-of-context-sensitive-type-1-languages)  
22. Formal language theory: refining the Chomsky hierarchy \- PMC \- NIH, accessed October 25, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC3367686/](https://pmc.ncbi.nlm.nih.gov/articles/PMC3367686/)  
23. CSCI 340: Computational Models The Chomsky Hierarchy, accessed October 25, 2025, [https://cs.millersville.edu/\~wkillian/archive/2019/spring/files/csci340/24-The-Chomsky-Hierarchy.pdf](https://cs.millersville.edu/~wkillian/archive/2019/spring/files/csci340/24-The-Chomsky-Hierarchy.pdf)  
24. What is "Total Functional Programming"? \- Stack Overflow, accessed October 25, 2025, [https://stackoverflow.com/questions/145263/what-is-total-functional-programming](https://stackoverflow.com/questions/145263/what-is-total-functional-programming)  
25. Total functional programming \- Wikipedia, accessed October 25, 2025, [https://en.wikipedia.org/wiki/Total\_functional\_programming](https://en.wikipedia.org/wiki/Total_functional_programming)  
26. Total Functional Programming : r/functionalprogramming \- Reddit, accessed October 25, 2025, [https://www.reddit.com/r/functionalprogramming/comments/ayztjf/total\_functional\_programming/](https://www.reddit.com/r/functionalprogramming/comments/ayztjf/total_functional_programming/)  
27. What is a total function? \- Eric Normand, accessed October 25, 2025, [https://ericnormand.me/podcast/what-is-a-total-function](https://ericnormand.me/podcast/what-is-a-total-function)  
28. In the context of functional programming, what are 'total' functions and 'partial' functions?, accessed October 25, 2025, [https://softwareengineering.stackexchange.com/questions/334874/in-the-context-of-functional-programming-what-are-total-functions-and-partia](https://softwareengineering.stackexchange.com/questions/334874/in-the-context-of-functional-programming-what-are-total-functions-and-partia)  
29. What Are Formal Methods? | Galois \- Galois, Inc., accessed October 25, 2025, [https://www.galois.com/what-are-formal-methods](https://www.galois.com/what-are-formal-methods)  
30. Assisting Agda's termination checker \- Stack Overflow, accessed October 25, 2025, [https://stackoverflow.com/questions/19642921/assisting-agdas-termination-checker](https://stackoverflow.com/questions/19642921/assisting-agdas-termination-checker)  
31. Intro \- Let's play Agda, accessed October 25, 2025, [https://lets-play-agda.quasicoherent.io/Padova2025.ProvingBasics.Termination.Intro.html](https://lets-play-agda.quasicoherent.io/Padova2025.ProvingBasics.Termination.Intro.html)  
32. Termination Checking — Agda 2.9.0 documentation, accessed October 25, 2025, [https://agda.readthedocs.io/en/latest/language/termination-checking.html](https://agda.readthedocs.io/en/latest/language/termination-checking.html)  
33. Termination Checking — Agda 2.6.0.1 documentation, accessed October 25, 2025, [https://agda.readthedocs.io/en/v2.6.0.1/language/termination-checking.html](https://agda.readthedocs.io/en/v2.6.0.1/language/termination-checking.html)  
34. Idris (programming language) \- Wikipedia, accessed October 25, 2025, [https://en.wikipedia.org/wiki/Idris\_(programming\_language)](https://en.wikipedia.org/wiki/Idris_\(programming_language\))  
35. Idris: Totality, Dependent Types, Proofs — Blog \- Vlad Rișcuția, accessed October 25, 2025, [https://vladris.com/blog/2017/07/20/idris-totality-dependent-types-proofs.html](https://vladris.com/blog/2017/07/20/idris-totality-dependent-types-proofs.html)  
36. Miscellaneous — Idris 1.3.3 documentation, accessed October 25, 2025, [https://docs.idris-lang.org/en/latest/reference/misc.html](https://docs.idris-lang.org/en/latest/reference/misc.html)  
37. Theorem Proving — Idris 1.3.3 documentation, accessed October 25, 2025, [https://docs.idris-lang.org/en/latest/tutorial/theorems.html](https://docs.idris-lang.org/en/latest/tutorial/theorems.html)  
38. Learn Coq in Y Minutes, accessed October 25, 2025, [https://learnxinyminutes.com/coq/](https://learnxinyminutes.com/coq/)  
39. Rocq \- Wikipedia, accessed October 25, 2025, [https://en.wikipedia.org/wiki/Rocq](https://en.wikipedia.org/wiki/Rocq)  
40. Welcome to a World of Rocq, accessed October 25, 2025, [https://rocq-prover.org/](https://rocq-prover.org/)  
41. The Correctness-by-Construction Approach to Programming | Request PDF \- ResearchGate, accessed October 25, 2025, [https://www.researchgate.net/publication/265717119\_The\_Correctness-by-Construction\_Approach\_to\_Programming](https://www.researchgate.net/publication/265717119_The_Correctness-by-Construction_Approach_to_Programming)  
42. Decomposition (computer science) \- Wikipedia, accessed October 25, 2025, [https://en.wikipedia.org/wiki/Decomposition\_(computer\_science)](https://en.wikipedia.org/wiki/Decomposition_\(computer_science\))  
43. Decomposition & Style \- Stanford Computer Science, accessed October 25, 2025, [https://cs.stanford.edu/people/nick/compdocs/Decomposition\_and\_Style.pdf](https://cs.stanford.edu/people/nick/compdocs/Decomposition_and_Style.pdf)  
44. Module Decomposition | System Design \- GeeksforGeeks, accessed October 25, 2025, [https://www.geeksforgeeks.org/system-design/module-decomposition-system-design/](https://www.geeksforgeeks.org/system-design/module-decomposition-system-design/)  
45. Complexity class \- Wikipedia, accessed October 25, 2025, [https://en.wikipedia.org/wiki/Complexity\_class](https://en.wikipedia.org/wiki/Complexity_class)  
46. Complexity Classes \- Brown Computer Science, accessed October 25, 2025, [https://cs.brown.edu/people/jsavage/book/pdfs/ModelsOfComputation\_Chapter8.pdf](https://cs.brown.edu/people/jsavage/book/pdfs/ModelsOfComputation_Chapter8.pdf)  
47. Complexity Classes — Not just your regular Big-O | by Ajin Sunny | Medium, accessed October 25, 2025, [https://medium.com/@ajin.sunny/complexity-classes-not-just-your-regular-big-o-9cb217097ed9](https://medium.com/@ajin.sunny/complexity-classes-not-just-your-regular-big-o-9cb217097ed9)  
48. Computational Complexity Theory \- Stanford Encyclopedia of Philosophy, accessed October 25, 2025, [https://plato.stanford.edu/archives/fall2022/entries/computational-complexity/](https://plato.stanford.edu/archives/fall2022/entries/computational-complexity/)  
49. Time complexity \- Wikipedia, accessed October 25, 2025, [https://en.wikipedia.org/wiki/Time\_complexity](https://en.wikipedia.org/wiki/Time_complexity)  
50. P, NP, CoNP, NP hard and NP complete | Complexity Classes \- GeeksforGeeks, accessed October 25, 2025, [https://www.geeksforgeeks.org/dsa/types-of-complexity-classes-p-np-conp-np-hard-and-np-complete/](https://www.geeksforgeeks.org/dsa/types-of-complexity-classes-p-np-conp-np-hard-and-np-complete/)  
51. Formal Distributional Semantics: Introduction to the Special Issue \- MIT Press Direct, accessed October 25, 2025, [https://direct.mit.edu/coli/article/42/4/619/1546/Formal-Distributional-Semantics-Introduction-to](https://direct.mit.edu/coli/article/42/4/619/1546/Formal-Distributional-Semantics-Introduction-to)  
52. COS 360 Programming Languages Formal Semantics \- Department of Computer Science, accessed October 25, 2025, [https://cs.usm.maine.edu/\~briggs/webPage/c360/docs/semantics.pdf](https://cs.usm.maine.edu/~briggs/webPage/c360/docs/semantics.pdf)  
53. Compositional Recurrence Analysis \- cs.Princeton, accessed October 25, 2025, [https://www.cs.princeton.edu/\~zkincaid/pub/fmcad15.pdf](https://www.cs.princeton.edu/~zkincaid/pub/fmcad15.pdf)  
54. \[1310.3481\] An Algebraic Framework for Compositional Program Analysis \- arXiv, accessed October 25, 2025, [https://arxiv.org/abs/1310.3481](https://arxiv.org/abs/1310.3481)  
55. Compositional May-Must Program Analysis: Unleashing The Power of Alternation \- Microsoft, accessed October 25, 2025, [https://www.microsoft.com/en-us/research/publication/compositional-may-must-program-analysis-unleashing-the-power-of-alternation/](https://www.microsoft.com/en-us/research/publication/compositional-may-must-program-analysis-unleashing-the-power-of-alternation/)  
56. Many-one reduction \- Wikipedia, accessed October 25, 2025, [https://en.wikipedia.org/wiki/Many-one\_reduction](https://en.wikipedia.org/wiki/Many-one_reduction)  
57. A Modular Program-Transformation Framework for Reducing Specifications to Reachability \- arXiv, accessed October 25, 2025, [https://arxiv.org/pdf/2501.16310](https://arxiv.org/pdf/2501.16310)  
58. Towards Diverse Program Transformations for Program Simplification \- Zheng Wang, accessed October 25, 2025, [https://zwang4.github.io/publications/fse25.pdf](https://zwang4.github.io/publications/fse25.pdf)  
59. (PDF) One-to-many data transformation operations optimization and execution on an RDBMS \- ResearchGate, accessed October 25, 2025, [https://www.researchgate.net/publication/220711053\_One-to-many\_data\_transformation\_operations\_optimization\_and\_execution\_on\_an\_RDBMS](https://www.researchgate.net/publication/220711053_One-to-many_data_transformation_operations_optimization_and_execution_on_an_RDBMS)  
60. On the performance of one-to-many data transformations. \- ResearchGate, accessed October 25, 2025, [https://www.researchgate.net/publication/221276201\_On\_the\_performance\_of\_one-to-many\_data\_transformations](https://www.researchgate.net/publication/221276201_On_the_performance_of_one-to-many_data_transformations)  
61. On Handling One-to-Many Transformations in Relational Systems \- ResearchGate, accessed October 25, 2025, [https://www.researchgate.net/publication/220708916\_On\_Handling\_One-to-Many\_Transformations\_in\_Relational\_Systems](https://www.researchgate.net/publication/220708916_On_Handling_One-to-Many_Transformations_in_Relational_Systems)  
62. General recursive function \- Wikipedia, accessed October 25, 2025, [https://en.wikipedia.org/wiki/General\_recursive\_function](https://en.wikipedia.org/wiki/General_recursive_function)  
63. Extensional and intensional definitions \- Wikipedia, accessed October 25, 2025, [https://en.wikipedia.org/wiki/Extensional\_and\_intensional\_definitions](https://en.wikipedia.org/wiki/Extensional_and_intensional_definitions)  
64. What is intension vs extension in functional programming? : r/compsci \- Reddit, accessed October 25, 2025, [https://www.reddit.com/r/compsci/comments/398w3m/what\_is\_intension\_vs\_extension\_in\_functional/](https://www.reddit.com/r/compsci/comments/398w3m/what_is_intension_vs_extension_in_functional/)  
65. Intensional Logic \- Stanford Encyclopedia of Philosophy, accessed October 25, 2025, [https://plato.stanford.edu/entries/logic-intensional/](https://plato.stanford.edu/entries/logic-intensional/)  
66. Logical Bisimulations and functional languages?, accessed October 25, 2025, [http://www.cs.unibo.it/\~sangio/DOC\_public/logBis.pdf](http://www.cs.unibo.it/~sangio/DOC_public/logBis.pdf)  
67. Amanote, accessed October 25, 2025, [https://app.amanote.com/note-taking/document/pqpyAnQBKQvf0BhiEq9z](https://app.amanote.com/note-taking/document/pqpyAnQBKQvf0BhiEq9z)  
68. arXiv:1201.0874v1 \[cs.PL\] 4 Jan 2012, accessed October 25, 2025, [https://arxiv.org/pdf/1201.0874](https://arxiv.org/pdf/1201.0874)  
69. applicative bisimulation, accessed October 25, 2025, [https://www.seas.upenn.edu/\~sweirich/types/archive/1993/msg00111.html](https://www.seas.upenn.edu/~sweirich/types/archive/1993/msg00111.html)  
70. Step-Indexed Syntactic Logical Relations for Recursive and Quantified Types, accessed October 25, 2025, [https://people.mpi-sws.org/\~dreyer/ats/papers/ahmed06.pdf](https://people.mpi-sws.org/~dreyer/ats/papers/ahmed06.pdf)  
71. What's the relation between applicative bisimulation and context equivalence in the λ-calculus? \- Theoretical Computer Science Stack Exchange, accessed October 25, 2025, [https://cstheory.stackexchange.com/questions/51113/whats-the-relation-between-applicative-bisimulation-and-context-equivalence-in](https://cstheory.stackexchange.com/questions/51113/whats-the-relation-between-applicative-bisimulation-and-context-equivalence-in)  
72. Behavioural Equivalence via Modalities for Algebraic Effects \- arXiv, accessed October 25, 2025, [https://arxiv.org/pdf/1904.08843](https://arxiv.org/pdf/1904.08843)  
73. Howe's method \- PLS Lab, accessed October 25, 2025, [https://www.pls-lab.org/en/Howes\_method](https://www.pls-lab.org/en/Howes_method)  
74. Bisimilarity as a theory of functional programming \- CORE, accessed October 25, 2025, [https://core.ac.uk/download/pdf/82741765.pdf](https://core.ac.uk/download/pdf/82741765.pdf)  
75. Applicative Bisimulation and Quantum λ-Calculi (Long Version) \- arXiv, accessed October 25, 2025, [https://arxiv.org/pdf/1506.06661](https://arxiv.org/pdf/1506.06661)