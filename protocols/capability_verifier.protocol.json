{
  "protocol_id": "capability-verification-001",
  "description": "A protocol for using the capability verifier tool to empirically test the agent's monotonic improvement.\n\n**Associated Tool Documentation (`tooling/capability_verifier.py`):**\n\n  \n  ### `/app/tooling/capability_verifier.py`\n  A tool to verify that the agent can monotonically improve its capabilities.\n  \n  This script is designed to provide a formal, automated test for the agent's\n  self-correction and learning mechanisms. It ensures that when the agent learns\n  a new capability, it does so without losing (regressing) any of its existing\n  capabilities. This is a critical safeguard for ensuring robust and reliable\n  agent evolution.\n  \n  The tool works by orchestrating a four-step process:\n  1.  **Confirm Initial Failure:** It runs a specific test file that is known to\n      fail, verifying that the agent currently lacks the target capability.\n  2.  **Invoke Self-Correction:** It simulates the discovery of a new \"lesson\" and\n      triggers the `self_correction_orchestrator.py` script, which is responsible\n      for integrating new knowledge and skills.\n  3.  **Confirm Final Success:** It runs the same test file again, confirming that\n      the agent has successfully learned the new capability and the test now passes.\n  4.  **Check for Regressions:** It runs the full, existing test suite to ensure\n      that the process of learning the new skill has not inadvertently broken any\n      previously functional capabilities.\n  \n  This provides a closed-loop verification of monotonic improvement, which is a\n  cornerstone of the agent's design philosophy.\n  \n  **Public Functions:**\n  \n  - #### `def main()`\n    > A tool to verify that the agent can monotonically improve its capabilities.\n    > \n    > This tool works by:\n    > 1. Running a target test file that is known to fail, confirming the agent lacks a capability.\n    > 2. Invoking the agent's self-correction mechanism to learn the new capability.\n    > 3. Running the target test again to confirm it now passes.\n    > 4. Running the full test suite to ensure no existing capabilities were lost.\n",
  "rules": [
    {
      "rule_id": "verify-capability-acquisition",
      "description": "The `capability_verifier.py` tool should be used to test the agent's ability to acquire a new capability defined by a failing test file. The tool orchestrates the failure, self-correction, and verification process.",
      "enforcement": "The tool is used by invoking it from the command line with the path to the target test file."
    }
  ],
  "associated_tools": [
    "tooling/capability_verifier.py"
  ]
}