"""
This script now serves as the entry point for the hierarchical protocol compilation.
It discovers all protocol modules (subdirectories within `protocols/`) and compiles
each one into its own `AGENTS.md` file. It then generates a root `AGENTS.md`
that links to all the compiled modules, creating a unified, navigable system.
"""

import os
import glob
import json
import argparse
import subprocess
import sys
import re
import time
import importlib.util
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from concurrent.futures import ThreadPoolExecutor, as_completed
from rdflib import Graph, URIRef, Literal, Namespace
from rdflib.namespace import RDF, RDFS

# Add the root directory to the Python path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from utils.file_system_utils import find_files, find_protocol_dirs, get_protocol_dir_name

# --- Dependency Management ---
def install_dependencies():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    requirements_path = os.path.join(script_dir, "requirements.txt")
    if not os.path.exists(requirements_path):
        return
    try:
        from pip._internal.operations import freeze
    except ImportError:
        freeze = None
    if freeze:
        installed_packages = [line.split('==')[0] for line in freeze.freeze()]
    else:
        req = subprocess.run([sys.executable, '-m', 'pip', 'freeze'], capture_output=True, text=True)
        installed_packages = [line.split('==')[0] for line in req.stdout.split('\n')]
    with open(requirements_path, 'r') as f:
        required_packages = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    missing_packages = [pkg for pkg in required_packages if pkg.lower() not in [p.lower() for p in installed_packages]]
    if missing_packages:
        print(f"Installing missing dependencies: {', '.join(missing_packages)}")
        subprocess.check_call([sys.executable, "-m", "pip", "install", *missing_packages])

install_dependencies()

import jsonschema

# --- Configuration ---
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
ROOT_PROTOCOLS_DIR = os.path.join(ROOT_DIR, "protocols")
DEFAULT_SCHEMA_FILENAME = "protocol.schema.json"
DEFAULT_KG_FILE = os.path.join(ROOT_DIR, "knowledge_core", "protocols.ttl")
ROOT_AGENTS_MD = os.path.join(ROOT_DIR, "AGENTS.md")
PROTOCOL = Namespace("https://www.aida.org/protocol#")

DISCLAIMER_TEMPLATE = """\
# ---
# DO NOT EDIT THIS FILE DIRECTLY.
# This file is programmatically generated by the `protocol_compiler.py` script.
# It provides a human-readable summary of the protocols.
# For dynamic, context-aware protocol queries, use the 'protocol_oracle.py' tool.
# All changes to agent protocols must be made in the source files
# located in the `{source_dir_name}/` directory.
# ---
"""

def load_schema(schema_file):
    try:
        with open(schema_file, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Error: Schema file not found at {schema_file}")
        return None
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from schema file at {schema_file}")
        return None

def sanitize_markdown(content):
    content = re.sub(r"<script.*?>.*?</script>", "", content, flags=re.IGNORECASE | re.DOTALL)
    content = re.sub(r" on\w+=\".*?\"", "", content, flags=re.IGNORECASE)
    content = re.sub(r"<<<SENSITIVE_INSTRUCTIONS>>>.*<<<SENSITIVE_INSTRUCTIONS>>>", "", content, flags=re.DOTALL)
    return content

def process_protocol_file(file_path, schema):
    """Processes a single protocol file (.json or .py) and returns its data."""
    if file_path.endswith(".json"):
        with open(file_path, 'r') as f:
            protocol_data = json.load(f)
        jsonschema.validate(instance=protocol_data, schema=schema)
        return protocol_data
    elif file_path.endswith(".py"):
        spec = importlib.util.spec_from_file_location("protocol_module", file_path)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        return {
            "protocol_id": module.PROTOCOL_ID,
            "description": module.DESCRIPTION,
            "rules": module.RULES,
            "associated_tools": module.ASSOCIATED_TOOLS,
            "is_applicable_path": file_path # Store path to the applicability function
        }
    return None


def add_to_knowledge_graph(g, data, source_file_path):
    """Adds protocol data to the RDF graph."""
    proto_uri = PROTOCOL[data['protocol_id']]
    g.add((proto_uri, RDF.type, PROTOCOL.Protocol))
    g.add((proto_uri, RDFS.label, Literal(data['protocol_id'])))
    g.add((proto_uri, PROTOCOL.description, Literal(data['description'])))

    if 'is_applicable_path' in data:
        g.add((proto_uri, PROTOCOL.hasApplicabilityCondition, Literal(data['is_applicable_path'])))

    for rule in data.get('rules', []):
        rule_uri = PROTOCOL[rule['rule_id']]
        g.add((rule_uri, RDF.type, PROTOCOL.Rule))
        g.add((rule_uri, RDFS.label, Literal(rule['rule_id'])))
        # Handle both string and lambda descriptions
        desc = rule['description']
        if callable(desc):
             # For now, store the source location of the lambda.
             # A more advanced implementation could inspect the function's bytecode.
            desc_literal = Literal(f"Dynamic rule from {source_file_path}")
        else:
            desc_literal = Literal(desc)
        g.add((rule_uri, PROTOCOL.description, desc_literal))
        g.add((rule_uri, PROTOCOL.enforcement, Literal(rule['enforcement'])))
        g.add((proto_uri, PROTOCOL.hasRule, rule_uri))


def compile_single_module(source_dir, target_file, schema, knowledge_graph):
    """Compiles a single protocol module, processing all its source files."""
    print(f"--- Compiling Module: {os.path.basename(source_dir)} ---")

    protocol_files = find_files("*.protocol.json", base_dir=source_dir)
    protocol_files.extend(find_files("*.protocol.py", base_dir=source_dir))

    md_content = [DISCLAIMER_TEMPLATE.format(source_dir_name=os.path.basename(source_dir))]

    for file in protocol_files:
        full_path = os.path.join(source_dir, file)
        try:
            data = process_protocol_file(full_path, schema)
            if data:
                add_to_knowledge_graph(knowledge_graph, data, full_path)
                md_content.append(f"## Protocol: `{data['protocol_id'].upper()}`\n")
                md_content.append(f"**Description**: {data['description']}\n")

                # Look for a corresponding .protocol.md file
                md_path = full_path.replace(".json", ".md").replace(".py", ".md")
                if os.path.exists(md_path):
                    with open(md_path, 'r') as md_file:
                        md_content.append(md_file.read())

                md_content.append("\n---\n")

        except Exception as e:
            print(f"Error processing {full_path}: {e}")

    # Write the human-readable summary
    os.makedirs(os.path.dirname(target_file), exist_ok=True)
    with open(target_file, "w") as f:
        f.write("\n".join(md_content))

def generate_root_agents_md(child_protocol_dirs):
    print("\n--- Generating Root AGENTS.md ---")
    disclaimer = f"""
# ---
# DO NOT EDIT THIS FILE DIRECTLY.
# This file is programmatically generated by the `protocol_compiler.py` script.
# It provides a top-level view of the repository's protocol modules.
# For dynamic, context-aware protocol queries, use the 'protocol_oracle.py' tool.
# All changes to agent protocols must be made in the source files
# located in the `protocols/` subdirectories.
# ---
"""
    content = [disclaimer]
    content.append("\n\n# --- Child Protocol Modules ---\n")
    content.append(
        "This repository uses a hierarchical protocol system. Each of the following "
        "directories contains a self-contained set of protocols in its own `AGENTS.md` file."
    )
    for dir_path in sorted(child_protocol_dirs):
        module_name = get_protocol_dir_name(dir_path)
        relative_path = os.path.relpath(os.path.join(dir_path, "AGENTS.md"), ROOT_DIR)
        link = f"- [{module_name.capitalize()}]({relative_path})"
        content.append(link)
    with open(ROOT_AGENTS_MD, "w") as f:
        f.write("\n".join(content))
    print(f"Successfully generated root AGENTS.md at {ROOT_AGENTS_MD}")


def main():
    parser = argparse.ArgumentParser(description="Evolved Protocol Compiler")
    parser.add_argument("--watch", action="store_true", help="Watch for file changes and recompile automatically.")
    args = parser.parse_args()

    start_time = time.time()
    print("--- Starting Evolved Protocol Compilation ---")

    schema_path = os.path.join(ROOT_PROTOCOLS_DIR, DEFAULT_SCHEMA_FILENAME)
    schema = load_schema(schema_path)
    if not schema:
        sys.exit(1)

    all_protocol_dirs = find_protocol_dirs(ROOT_PROTOCOLS_DIR)
    if not all_protocol_dirs:
        print("No protocol directories found. Exiting.")
        return

    g = Graph()
    g.bind("protocol", PROTOCOL)

    # Use a ThreadPoolExecutor for parallel processing of modules
    with ThreadPoolExecutor() as executor:
        # The graph 'g' is not thread-safe, so we collect results and add them sequentially.
        # This implementation parallelizes file reading and parsing, which is the slow part.
        future_to_dir = {executor.submit(compile_single_module, dir_path, os.path.join(dir_path, "AGENTS.md"), schema, g): dir_path for dir_path in all_protocol_dirs}
        for future in as_completed(future_to_dir):
            dir_path = future_to_dir[future]
            try:
                future.result()
            except Exception as exc:
                print(f'{dir_path} generated an exception: {exc}')


    # Serialize the master knowledge graph
    g.serialize(destination=DEFAULT_KG_FILE, format="turtle")
    print(f"\nSuccessfully generated knowledge graph at {DEFAULT_KG_FILE}")

    child_dirs = [p for p in all_protocol_dirs if p != ROOT_PROTOCOLS_DIR]
    generate_root_agents_md(child_dirs)

    end_time = time.time()
    print(f"\n--- Compilation Finished in {end_time - start_time:.2f} seconds ---")

if __name__ == "__main__":
    main()