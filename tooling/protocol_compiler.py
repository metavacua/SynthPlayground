"""
This script now serves as the entry point for the hierarchical protocol compilation.
It discovers all protocol modules (subdirectories within `protocols/`) and compiles
each one into its own `AGENTS.md` file. It then generates a root `AGENTS.md`
that links to all the compiled modules, creating a unified, navigable system.
"""

import os
import glob
import json
import argparse
import subprocess
import sys
import re
import time
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from concurrent.futures import ThreadPoolExecutor, as_completed

# Add the root directory to the Python path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from utils.file_system_utils import find_files, find_protocol_dirs, get_protocol_dir_name

# --- Dependency Management ---
def install_dependencies():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    requirements_path = os.path.join(script_dir, "requirements.txt")
    if not os.path.exists(requirements_path):
        return
    try:
        from pip._internal.operations import freeze
    except ImportError:
        freeze = None
    if freeze:
        installed_packages = [line.split('==')[0] for line in freeze.freeze()]
    else:
        req = subprocess.run([sys.executable, '-m', 'pip', 'freeze'], capture_output=True, text=T)
        installed_packages = [line.split('==')[0] for line in req.stdout.split('\n')]
    with open(requirements_path, 'r') as f:
        required_packages = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    missing_packages = [pkg for pkg in required_packages if pkg.lower() not in [p.lower() for p in installed_packages]]
    if missing_packages:
        print(f"Installing missing dependencies: {', '.join(missing_packages)}")
        subprocess.check_call([sys.executable, "-m", "pip", "install", *missing_packages])

install_dependencies()

import jsonschema
from rdflib import Graph, Namespace, URIRef, Literal
from rdflib.namespace import RDF, RDFS

# --- Configuration ---
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
ROOT_PROTOCOLS_DIR = os.path.join(ROOT_DIR, "protocols")
DEFAULT_SCHEMA_FILENAME = "protocol.schema.json"
DEFAULT_KG_FILE = os.path.join(ROOT_DIR, "knowledge_core", "protocols.ttl")
DEFAULT_AUTODOC_FILE = os.path.join(ROOT_DIR, "knowledge_core", "SYSTEM_DOCUMENTATION.md")
ROOT_AGENTS_MD = os.path.join(ROOT_DIR, "AGENTS.md")

DISCLAIMER_TEMPLATE = """\
# ---
# DO NOT EDIT THIS FILE DIRECTLY.
# This file is programmatically generated by the `protocol_compiler.py` script.
# All changes to agent protocols must be made in the source files
# located in the `{source_dir_name}/` directory.
#
# This file contains the compiled protocols in a human-readable Markdown format,
# with machine-readable JSON definitions embedded.
# ---
"""

def load_schema(schema_file):
    try:
        with open(schema_file, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Error: Schema file not found at {schema_file}")
        return None
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from schema file at {schema_file}")
        return None

def sanitize_markdown(content):
    content = re.sub(r"<script.*?>.*?</script>", "", content, flags=re.IGNORECASE | re.DOTALL)
    content = re.sub(r" on\w+=\".*?\"", "", content, flags=re.IGNORECASE)
    content = re.sub(r"<<<SENSITIVE_INSTRUCTIONS>>>.*<<<SENSITIVE_INSTRUCTIONS>>>", "", content, flags=re.DOTALL)
    return content

def compile_single_module(source_dir, target_file, schema_file, knowledge_graph=None, autodoc_file=None):
    output_filename = os.path.basename(target_file)
    print(f"--- Starting Protocol Compilation for {output_filename} ---")
    print(f"Source directory: {source_dir}")
    print(f"Target file: {target_file}")

    schema = load_schema(schema_file)
    if not schema:
        return

    autodoc_placeholders = sorted([os.path.join(source_dir, f) for f in find_files("*.autodoc.md", base_dir=source_dir)])
    all_md_files = sorted([os.path.join(source_dir, f) for f in find_files("*.protocol.md", base_dir=source_dir, recursive=False)])
    all_json_files = sorted([os.path.join(source_dir, f) for f in find_files("*.protocol.json", base_dir=source_dir, recursive=False)])

    if not all_md_files and not all_json_files and not autodoc_placeholders:
        with open(target_file, "w") as f:
            f.write(DISCLAIMER_TEMPLATE.format(source_dir_name=os.path.basename(source_dir)))
        return

    disclaimer = DISCLAIMER_TEMPLATE.format(source_dir_name=os.path.basename(source_dir))
    final_content = [disclaimer]

    all_associated_tools = set()

    for file_path in autodoc_placeholders:
        if autodoc_file and os.path.exists(autodoc_file):
            with open(autodoc_file, "r") as f:
                final_content.append(f.read())
        final_content.append("\n---\n")

    for file_path in all_md_files:
        with open(file_path, "r") as f:
            content = f.read()
            sanitized_content = sanitize_markdown(content)
            final_content.append(sanitized_content)
        final_content.append("\n---\n")

    for file_path in all_json_files:
        with open(file_path, "r") as f:
            protocol_data = json.load(f)
        jsonschema.validate(instance=protocol_data, schema=schema)

        if "associated_tools" in protocol_data:
            all_associated_tools.update(protocol_data["associated_tools"])

        if knowledge_graph is not None:
            PROTO = Namespace("https://w3id.org/ai-protocol/v1/")
            protocol_uri = URIRef(f"urn:protocol:{protocol_data['protocol_id']}")
            version = protocol_data.get("version", "N/A")
            version_uri = URIRef(f"urn:protocol:{protocol_data['protocol_id']}:version:{version}")

            knowledge_graph.add((protocol_uri, RDF.type, PROTO.Protocol))
            knowledge_graph.add((protocol_uri, RDFS.label, Literal(protocol_data['description'])))
            knowledge_graph.add((protocol_uri, PROTO.hasVersion, version_uri))

            knowledge_graph.add((version_uri, RDF.type, PROTO.ProtocolVersion))
            knowledge_graph.add((version_uri, RDFS.label, Literal(f"Version {version} of {protocol_data['protocol_id']}")))
            knowledge_graph.add((version_uri, PROTO.versionString, Literal(version)))

            for rule in protocol_data.get("rules", []):
                rule_uri = URIRef(f"urn:protocol:{protocol_data['protocol_id']}:rule:{rule['rule_id']}")
                knowledge_graph.add((version_uri, PROTO.hasRule, rule_uri))
                knowledge_graph.add((rule_uri, RDF.type, PROTO.Rule))
                knowledge_graph.add((rule_uri, RDFS.label, Literal(rule['description'])))

                test_file_path = os.path.join(ROOT_DIR, "tests", "protocols", f"test_{protocol_data['protocol_id']}.py")
                if os.path.exists(test_file_path):
                    test_uri = URIRef(f"urn:test:file:{os.path.relpath(test_file_path, ROOT_DIR)}")
                    knowledge_graph.add((rule_uri, PROTO.hasTest, test_uri))
                    knowledge_graph.add((test_uri, RDF.type, PROTO.Test))
                    knowledge_graph.add((test_uri, RDFS.label, Literal(f"Test for {protocol_data['protocol_id']}")))
        json_string = json.dumps(protocol_data, indent=2)
        version = protocol_data.get("version", "N/A")
        md_json_block = f"**Version:** {version}\n\n```json\n{json_string}\n```\n"
        final_content.append(md_json_block)
        final_content.append("\n---\n")

    if all_associated_tools:
        final_content.append("\n\n# --- Associated Tool Documentation ---\n")
        for tool_path in sorted(list(all_associated_tools)):
            tool_abs_path = os.path.join(ROOT_DIR, tool_path)
            if os.path.exists(tool_abs_path):
                with open(tool_abs_path, "r") as f:
                    tool_content = f.read()
                    match = re.search(r'\"\"\"(.*?)\"\"\"', tool_content, re.DOTALL)
                    if match:
                        docstring = match.group(1).strip()
                        final_content.append(f"## `{os.path.basename(tool_path)}`\n\n{docstring}\n\n---\n")

    final_output_string = "\n".join(final_content)
    temp_target_file = target_file + ".tmp"
    os.makedirs(os.path.dirname(target_file), exist_ok=True)
    with open(temp_target_file, "w") as f:
        f.write(final_output_string)
    os.rename(temp_target_file, target_file)

def compile_module_wrapper(path_to_protocol_dir, knowledge_graph=None):
    target_md_file = os.path.join(path_to_protocol_dir, "AGENTS.md")
    schema_file = os.path.join(ROOT_PROTOCOLS_DIR, "protocol.schema.json")
    try:
        compile_single_module(
            source_dir=path_to_protocol_dir,
            target_file=target_md_file,
            schema_file=schema_file,
            knowledge_graph=knowledge_graph
        )
        return True, path_to_protocol_dir
    except Exception as e:
        print(f"Error: Failed to compile protocols in {path_to_protocol_dir}: {e}")
        return False, path_to_protocol_dir

def generate_root_agents_md(child_protocol_dirs):
    print("\n--- Generating Root AGENTS.md ---")
    disclaimer = f"""
# ---
# DO NOT EDIT THIS FILE DIRECTLY.
# This file is programmatically generated by the `protocol_compiler.py` script.
# It provides a top-level view of the repository's protocol modules.
# All changes to agent protocols must be made in the source files
# located in the `protocols/` subdirectories.
# ---
"""
    root_protocol_files = [
        f
        for f in os.listdir(ROOT_PROTOCOLS_DIR)
        if f.endswith(".protocol.md") or f.endswith(".autodoc.md")
    ]
    content = [disclaimer]
    for filename in sorted(root_protocol_files):
        with open(os.path.join(ROOT_PROTOCOLS_DIR, filename), "r") as f:
            content.append(f.read())
        content.append("\n---\n")

    content.append("\n\n# --- Child Protocol Modules ---\n")
    content.append(
        "This repository uses a hierarchical protocol system. Each of the following "
        "directories contains a self-contained set of protocols in its own `AGENTS.md` file."
    )
    for dir_path in sorted(child_protocol_dirs):
        module_name = get_protocol_dir_name(dir_path)
        relative_path = os.path.relpath(os.path.join(dir_path, "AGENTS.md"), ROOT_DIR)
        link = f"- [{module_name.capitalize()}]({relative_path})"
        content.append(link)
    with open(ROOT_AGENTS_MD, "w") as f:
        f.write("\n".join(content))
    print(f"Successfully generated root AGENTS.md at {ROOT_AGENTS_MD}")

def main_hierarchical_compiler():
    """Main function to run the hierarchical compiler."""
    parser = argparse.ArgumentParser(description="Hierarchical Protocol Compiler")
    parser.add_argument("--knowledge-graph-file", help="Path to output knowledge graph file.")
    args = parser.parse_args()

    print("--- Starting Hierarchical Protocol Compilation ---")
    all_dirs = find_protocol_dirs(ROOT_PROTOCOLS_DIR)
    if not all_dirs:
        print("No protocol directories found. Exiting.")
        return

    g = Graph() if args.knowledge_graph_file else None

    successful_compilations = []
    failed_compilations = []

    # Note: ThreadPoolExecutor is not used here because the rdflib.Graph object is not thread-safe.
    # A more advanced implementation might use a thread-safe graph or a different parallelization strategy.
    for dir_path in all_dirs:
        try:
            compile_single_module(
                source_dir=dir_path,
                target_file=os.path.join(dir_path, "AGENTS.md"),
                schema_file=os.path.join(ROOT_PROTOCOLS_DIR, "protocol.schema.json"),
                knowledge_graph=g
            )
            successful_compilations.append(dir_path)
        except Exception as e:
            print(f"Error compiling {dir_path}: {e}")
            failed_compilations.append(dir_path)


    if failed_compilations:
        print("\n--- Compilation Summary: Failures Detected ---")
        for path in failed_compilations:
            print(f"- {get_protocol_dir_name(path)}")
        sys.exit(1)
    else:
        print("\n--- All protocol modules compiled successfully. ---")

    if g is not None:
        g.serialize(destination=args.knowledge_graph_file, format="turtle")
        print(f"Successfully generated knowledge graph at {args.knowledge_graph_file}")

    child_dirs = [p for p in successful_compilations if p != ROOT_PROTOCOLS_DIR]
    generate_root_agents_md(child_dirs)
    print("\n--- Hierarchical Protocol Compilation Finished ---")


if __name__ == "__main__":
    main_hierarchical_compiler()