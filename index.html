
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Chimera: System Metalanguage</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Noto Sans", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji";
            line-height: 1.6;
            color: #24292e;
            max-width: 980px;
            margin: 20px auto;
            padding: 0 20px;
        }
        h1, h2, h3, h4, h5, h6 {
            border-bottom: 1px solid #eaecef;
            padding-bottom: .3em;
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
        }
        code, pre {
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace;
            font-size: 85%;
        }
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            padding: 16px;
            overflow: auto;
        }
        code {
            background-color: rgba(27,31,35,.05);
            border-radius: 3px;
            padding: .2em .4em;
        }
        pre > code {
            padding: 0;
            background-color: transparent;
        }
        .toc {
            background-color: #f6f8fa;
            border: 1px solid #eaecef;
            border-radius: 6px;
            padding: 10px 20px;
            margin-bottom: 30px;
        }
        .toc ul {
            padding-left: 20px;
            list-style-type: none;
        }
        .toc li {
            margin-top: 4px;
        }
        article {
            margin-bottom: 40px;
        }
        hr {
            height: .25em;
            padding: 0;
            margin: 24px 0;
            background-color: #e1e4e8;
            border: 0;
        }
    </style>
</head>
<body>
    <header>
        <h1>Project Chimera: System Metalanguage</h1>
    </header>
    <main>
        <nav class="toc">
            <h2>Table of Contents</h2>
            <div class="toc">
<ul>
<li><a href="#human-readable-metalanguage-readmemd">Human-Readable Metalanguage (README.md)</a></li>
<li><a href="#project-chimera-an-agent-self-improvement-protocol">Project Chimera: An Agent Self-Improvement Protocol</a><ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#core-architecture-the-integrated-fsm-workflow">Core Architecture: The Integrated FSM Workflow</a></li>
<li><a href="#core-protocols">Core Protocols</a></li>
<li><a href="#key-components">Key Components</a></li>
<li><a href="#build-system-usage">Build System &amp; Usage</a></li>
<li><a href="#machine-readable-metalanguage-agentsmd">Machine-Readable Metalanguage (AGENTS.md)</a></li>
</ul>
</li>
<li><a href="#-">---</a></li>
<li><a href="#do-not-edit-this-file-directly">DO NOT EDIT THIS FILE DIRECTLY.</a></li>
<li><a href="#this-file-is-programmatically-generated-by-the-protocol_compilerpy-script">This file is programmatically generated by the protocol_compiler.py script.</a></li>
<li><a href="#all-changes-to-agent-protocols-must-be-made-in-the-source-files">All changes to agent protocols must be made in the source files</a></li>
<li><a href="#located-in-the-protocols-directory">located in the protocols/ directory.</a></li>
<li><a href="#_1"></a></li>
<li><a href="#this-file-contains-the-compiled-protocols-in-a-human-readable-markdown-format">This file contains the compiled protocols in a human-readable Markdown format,</a></li>
<li><a href="#with-machine-readable-json-definitions-embedded">with machine-readable JSON definitions embedded.</a></li>
<li><a href="#-_1">---</a></li>
<li><a href="#jules-agent-protocol-the-hierarchical-development-cycle">Jules Agent Protocol: The Hierarchical Development Cycle</a></li>
<li><a href="#jules-agent-protocol-the-hierarchical-development-cycle_1">Jules Agent Protocol: The Hierarchical Development Cycle</a><ul>
<li><a href="#1-the-core-problem-ensuring-formally-verifiable-execution">1. The Core Problem: Ensuring Formally Verifiable Execution</a></li>
<li><a href="#2-the-solution-a-two-layered-fsm-system">2. The Solution: A Two-Layered FSM System</a><ul>
<li><a href="#layer-1-the-orchestrator-master_controlpy-fsmjson">Layer 1: The Orchestrator (master_control.py &amp; fsm.json)</a></li>
<li><a href="#layer-2-the-fdc-toolchain-fdc_clipy-fdc_fsmjson">Layer 2: The FDC Toolchain (fdc_cli.py &amp; fdc_fsm.json)</a><ul>
<li><a href="#fdc-commands-for-agent-use">FDC Commands for Agent Use:</a></li>
</ul>
</li>
<li><a href="#standing-orders">STANDING ORDERS</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#meta-protocol-agentsmd-self-management">Meta-Protocol: AGENTS.md Self-Management</a></li>
<li><a href="#protocol-the-context-free-development-cycle-cfdc">Protocol: The Context-Free Development Cycle (CFDC)</a><ul>
<li><a href="#from-fsm-to-pushdown-automaton">From FSM to Pushdown Automaton</a></li>
<li><a href="#the-call_plan-directive">The call_plan Directive</a></li>
<li><a href="#ensuring-decidability-the-recursion-depth-limit">Ensuring Decidability: The Recursion Depth Limit</a></li>
</ul>
</li>
<li><a href="#protocol-the-plan-registry">Protocol: The Plan Registry</a><ul>
<li><a href="#the-problem-with-path-based-calls">The Problem with Path-Based Calls</a></li>
<li><a href="#the-solution-a-central-registry">The Solution: A Central Registry</a></li>
<li><a href="#updated-call_plan-logic">Updated call_plan Logic</a></li>
<li><a href="#management">Management</a></li>
</ul>
</li>
<li><a href="#protocol-the-closed-loop-self-correction-cycle">Protocol: The Closed-Loop Self-Correction Cycle</a><ul>
<li><a href="#the-problem-the-open-loop">The Problem: The Open Loop</a></li>
<li><a href="#the-solution-a-protocol-driven-self-correction-pdsc-workflow">The Solution: A Protocol-Driven Self-Correction (PDSC) Workflow</a></li>
</ul>
</li>
<li><a href="#protocol-agentsmd-non-compliance">Protocol: AGENTS.md Non-Compliance</a><ul>
<li><a href="#rule-non-compliance-definition-definition-of-non-compliance">Rule non-compliance-definition: Definition of Non-Compliance</a></li>
<li><a href="#rule-non-compliance-direct-editing-prohibition-of-direct-artifact-editing">Rule non-compliance-direct-editing: Prohibition of Direct Artifact Editing</a></li>
<li><a href="#rule-non-compliance-test-procedure-adherence-to-testing-protocols">Rule non-compliance-test-procedure: Adherence to Testing Protocols</a></li>
<li><a href="#rule-non-compliance-architectural-deviation-adherence-to-architectural-and-convention-guidelines">Rule non-compliance-architectural-deviation: Adherence to Architectural and Convention Guidelines</a></li>
<li><a href="#rule-non-compliance-self-awareness-failure-failure-to-maintain-protocol-awareness">Rule non-compliance-self-awareness-failure: Failure to Maintain Protocol Awareness</a></li>
<li><a href="#consequence-of-non-compliance">Consequence of Non-Compliance</a></li>
</ul>
</li>
<li><a href="#protocol-pre-commit-verification">Protocol: Pre-Commit Verification</a><ul>
<li><a href="#rule-mandatory-pre-commit-checks">Rule: Mandatory Pre-Commit Checks</a></li>
</ul>
</li>
<li><a href="#protocol-authorization-for-destructive-tools">Protocol: Authorization for Destructive Tools</a><ul>
<li><a href="#the-problem-unauthorized-use-of-destructive-tools">The Problem: Unauthorized Use of Destructive Tools</a></li>
<li><a href="#the-solution-explicit-auditable-authorization">The Solution: Explicit, Auditable Authorization</a></li>
</ul>
</li>
<li><a href="#protocol-reset_all-prohibition">Protocol: reset_all Prohibition</a><ul>
<li><a href="#1-description">1. Description</a></li>
<li><a href="#2-rationale">2. Rationale</a></li>
<li><a href="#3-rules">3. Rules</a><ul>
<li><a href="#rule-no-reset-all">Rule no-reset-all</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#system-documentation">System Documentation</a><ul>
<li><a href="#tooling-directory">tooling/ Directory</a><ul>
<li><a href="#tooling__init__py">tooling/__init__.py</a></li>
<li><a href="#toolingcode_suggesterpy">tooling/code_suggester.py</a><ul>
<li><a href="#def-generate_suggestion_planfilepath-diff_content">def generate_suggestion_plan(filepath, diff_content)</a></li>
<li><a href="#def-main">def main()</a></li>
</ul>
</li>
<li><a href="#toolingcontext_awareness_scannerpy">tooling/context_awareness_scanner.py</a><ul>
<li><a href="#def-find_referencessymbol_name-search_path">def find_references(symbol_name, search_path)</a></li>
<li><a href="#def-get_defined_symbolsfilepath">def get_defined_symbols(filepath)</a></li>
<li><a href="#def-get_imported_symbolsfilepath">def get_imported_symbols(filepath)</a></li>
<li><a href="#def-main_1">def main()</a></li>
</ul>
</li>
<li><a href="#toolingdependency_graph_generatorpy">tooling/dependency_graph_generator.py</a><ul>
<li><a href="#def-find_package_json_filesroot_dir">def find_package_json_files(root_dir)</a></li>
<li><a href="#def-find_requirements_txt_filesroot_dir">def find_requirements_txt_files(root_dir)</a></li>
<li><a href="#def-generate_dependency_graphroot_dir">def generate_dependency_graph(root_dir='.')</a></li>
<li><a href="#def-main_2">def main()</a></li>
<li><a href="#def-parse_package_jsonpackage_json_path">def parse_package_json(package_json_path)</a></li>
<li><a href="#def-parse_requirements_txtrequirements_path-root_dir">def parse_requirements_txt(requirements_path, root_dir)</a></li>
</ul>
</li>
<li><a href="#toolingdoc_generatorpy">tooling/doc_generator.py</a><ul>
<li><a href="#def-find_python_filesdirectories">def find_python_files(directories)</a></li>
<li><a href="#def-format_argsargs">def format_args(args)</a></li>
<li><a href="#def-generate_documentationall_docs">def generate_documentation(all_docs)</a></li>
<li><a href="#def-generate_documentation_for_modulemod_doc">def generate_documentation_for_module(mod_doc)</a></li>
<li><a href="#def-main_3">def main()</a></li>
<li><a href="#def-parse_file_for_docsfilepath">def parse_file_for_docs(filepath)</a></li>
<li><a href="#class-classdoc">class ClassDoc</a><ul>
<li><a href="#def-__init__self-name-docstring-methods">def __init__(self, name, docstring, methods)</a></li>
</ul>
</li>
<li><a href="#class-docvisitor">class DocVisitor</a><ul>
<li><a href="#def-__init__self">def __init__(self)</a></li>
<li><a href="#def-visit_classdefself-node">def visit_ClassDef(self, node)</a></li>
<li><a href="#def-visit_functiondefself-node">def visit_FunctionDef(self, node)</a></li>
</ul>
</li>
<li><a href="#class-functiondoc">class FunctionDoc</a><ul>
<li><a href="#def-__init__self-name-signature-docstring">def __init__(self, name, signature, docstring)</a></li>
</ul>
</li>
<li><a href="#class-moduledoc">class ModuleDoc</a><ul>
<li><a href="#def-__init__self-name-docstring-classes-functions">def __init__(self, name, docstring, classes, functions)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#toolingenvironmental_probepy">tooling/environmental_probe.py</a><ul>
<li><a href="#def-main_4">def main()</a></li>
<li><a href="#def-probe_environment_variables">def probe_environment_variables()</a></li>
<li><a href="#def-probe_filesystem">def probe_filesystem()</a></li>
<li><a href="#def-probe_network">def probe_network()</a></li>
</ul>
</li>
<li><a href="#toolingfdc_clipy">tooling/fdc_cli.py</a><ul>
<li><a href="#def-analyze_planplan_filepath">def analyze_plan(plan_filepath)</a></li>
<li><a href="#def-close_tasktask_id">def close_task(task_id)</a></li>
<li><a href="#def-lint_planplan_filepath">def lint_plan(plan_filepath)</a></li>
<li><a href="#def-main_5">def main()</a></li>
<li><a href="#def-start_tasktask_id">def start_task(task_id)</a></li>
<li><a href="#def-start_tasktask_id_1">def start_task(task_id)</a></li>
<li><a href="#def-validate_planplan_filepath">def validate_plan(plan_filepath)</a></li>
</ul>
</li>
<li><a href="#toolingknowledge_compilerpy">tooling/knowledge_compiler.py</a><ul>
<li><a href="#def-extract_lessons_from_postmortempostmortem_content">def extract_lessons_from_postmortem(postmortem_content)</a></li>
<li><a href="#def-extract_metadata_from_postmortempostmortem_content">def extract_metadata_from_postmortem(postmortem_content)</a></li>
<li><a href="#def-format_lesson_entrymetadata-lesson_data">def format_lesson_entry(metadata, lesson_data)</a></li>
<li><a href="#def-main_6">def main()</a></li>
<li><a href="#def-parse_action_to_commandaction_text">def parse_action_to_command(action_text)</a></li>
</ul>
</li>
<li><a href="#toolingknowledge_integratorpy">tooling/knowledge_integrator.py</a><ul>
<li><a href="#def-extract_conceptsgraph">def extract_concepts(graph)</a></li>
<li><a href="#def-load_local_graphgraph_file">def load_local_graph(graph_file)</a></li>
<li><a href="#def-query_dbpediaconcept">def query_dbpedia(concept)</a></li>
<li><a href="#def-run_knowledge_integrationinput_graph_path-output_graph_path">def run_knowledge_integration(input_graph_path, output_graph_path)</a></li>
</ul>
</li>
<li><a href="#toolinglog_failurepy">tooling/log_failure.py</a><ul>
<li><a href="#def-log_catastrophic_failure">def log_catastrophic_failure()</a></li>
</ul>
</li>
<li><a href="#toolingmaster_controlpy">tooling/master_control.py</a><ul>
<li><a href="#class-mastercontrolgraph">class MasterControlGraph</a><ul>
<li><a href="#def-__init__self-fsm_pathtoolingfsmjson">def __init__(self, fsm_path='tooling/fsm.json')</a></li>
<li><a href="#def-do_executionself-agent_state">def do_execution(self, agent_state)</a></li>
<li><a href="#def-do_finalizingself-agent_state">def do_finalizing(self, agent_state)</a></li>
<li><a href="#def-do_orientationself-agent_state">def do_orientation(self, agent_state)</a></li>
<li><a href="#def-do_planningself-agent_state">def do_planning(self, agent_state)</a></li>
<li><a href="#def-do_researchingself-agent_state">def do_researching(self, agent_state)</a></li>
<li><a href="#def-get_triggerself-source_state-dest_state">def get_trigger(self, source_state, dest_state)</a></li>
<li><a href="#def-runself-initial_agent_state">def run(self, initial_agent_state)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#toolingmaster_control_clipy">tooling/master_control_cli.py</a><ul>
<li><a href="#def-main_7">def main()</a></li>
</ul>
</li>
<li><a href="#toolingpages_generatorpy">tooling/pages_generator.py</a><ul>
<li><a href="#def-generate_html_page">def generate_html_page()</a></li>
</ul>
</li>
<li><a href="#toolingplan_managerpy">tooling/plan_manager.py</a><ul>
<li><a href="#def-deregister_planname">def deregister_plan(name)</a></li>
<li><a href="#def-get_registry">def get_registry()</a></li>
<li><a href="#def-list_plans">def list_plans()</a></li>
<li><a href="#def-main_8">def main()</a></li>
<li><a href="#def-register_planname-path">def register_plan(name, path)</a></li>
<li><a href="#def-save_registryregistry_data">def save_registry(registry_data)</a></li>
</ul>
</li>
<li><a href="#toolingplan_parserpy">tooling/plan_parser.py</a><ul>
<li><a href="#def-parse_planplan_content">def parse_plan(plan_content)</a></li>
<li><a href="#class-command">class Command</a></li>
</ul>
</li>
<li><a href="#toolingprotocol_auditorpy">tooling/protocol_auditor.py</a><ul>
<li><a href="#def-generate_markdown_reportsource_check-unreferenced-unused-centrality">def generate_markdown_report(source_check, unreferenced, unused, centrality)</a></li>
<li><a href="#def-get_protocol_tools_from_agents_mdagents_md_path">def get_protocol_tools_from_agents_md(agents_md_path)</a></li>
<li><a href="#def-get_used_tools_from_loglog_path">def get_used_tools_from_log(log_path)</a></li>
<li><a href="#def-main_9">def main()</a></li>
<li><a href="#def-run_centrality_analysisused_tools">def run_centrality_analysis(used_tools)</a></li>
<li><a href="#def-run_completeness_checkused_tools-protocol_tools">def run_completeness_check(used_tools, protocol_tools)</a></li>
<li><a href="#def-run_protocol_source_check">def run_protocol_source_check()</a></li>
</ul>
</li>
<li><a href="#toolingprotocol_compilerpy">tooling/protocol_compiler.py</a><ul>
<li><a href="#def-compile_protocolssource_dir-target_file-schema_file-knowledge_graph_filenone-autodoc_filenone">def compile_protocols(source_dir, target_file, schema_file, knowledge_graph_file=None, autodoc_file=None)</a></li>
<li><a href="#def-load_schemaschema_file">def load_schema(schema_file)</a></li>
<li><a href="#def-main_10">def main()</a></li>
</ul>
</li>
<li><a href="#toolingprotocol_updaterpy">tooling/protocol_updater.py</a><ul>
<li><a href="#def-add_tool_to_protocolprotocol_id-tool_name-protocols_dir">def add_tool_to_protocol(protocol_id, tool_name, protocols_dir)</a></li>
<li><a href="#def-find_protocol_fileprotocol_id-protocols_dir">def find_protocol_file(protocol_id, protocols_dir)</a></li>
<li><a href="#def-main_11">def main()</a></li>
<li><a href="#def-update_rule_in_protocolprotocol_id-rule_id-new_description-protocols_dir">def update_rule_in_protocol(protocol_id, rule_id, new_description, protocols_dir)</a></li>
</ul>
</li>
<li><a href="#toolingreadme_generatorpy">tooling/readme_generator.py</a><ul>
<li><a href="#def-generate_core_protocols_section">def generate_core_protocols_section()</a></li>
<li><a href="#def-generate_key_components_section">def generate_key_components_section()</a></li>
<li><a href="#def-get_module_docstringfilepath">def get_module_docstring(filepath)</a></li>
<li><a href="#def-main_12">def main()</a></li>
</ul>
</li>
<li><a href="#toolingresearchpy">tooling/research.py</a><ul>
<li><a href="#def-execute_research_protocolconstraints">def execute_research_protocol(constraints)</a></li>
</ul>
</li>
<li><a href="#toolingresearch_plannerpy">tooling/research_planner.py</a><ul>
<li><a href="#def-plan_deep_researchtopic">def plan_deep_research(topic)</a></li>
</ul>
</li>
<li><a href="#toolingself_correction_orchestratorpy">tooling/self_correction_orchestrator.py</a><ul>
<li><a href="#def-load_lessons">def load_lessons()</a></li>
<li><a href="#def-main_13">def main()</a></li>
<li><a href="#def-process_lessonslessons-protocols_dir">def process_lessons(lessons, protocols_dir)</a></li>
<li><a href="#def-run_commandcommand">def run_command(command)</a></li>
<li><a href="#def-save_lessonslessons">def save_lessons(lessons)</a></li>
</ul>
</li>
<li><a href="#toolingself_improvement_clipy">tooling/self_improvement_cli.py</a><ul>
<li><a href="#def-analyze_planning_efficiencylog_file">def analyze_planning_efficiency(log_file)</a></li>
<li><a href="#def-analyze_protocol_violationslog_file">def analyze_protocol_violations(log_file)</a></li>
<li><a href="#def-main_14">def main()</a></li>
</ul>
</li>
<li><a href="#toolingstatepy">tooling/state.py</a><ul>
<li><a href="#class-agentstate">class AgentState</a><ul>
<li><a href="#def-to_jsonself">def to_json(self)</a></li>
</ul>
</li>
<li><a href="#class-plancontext">class PlanContext</a></li>
</ul>
</li>
<li><a href="#toolingsymbol_map_generatorpy">tooling/symbol_map_generator.py</a><ul>
<li><a href="#def-generate_symbols_with_astroot_dir">def generate_symbols_with_ast(root_dir='.')</a></li>
<li><a href="#def-generate_symbols_with_ctagsroot_dir">def generate_symbols_with_ctags(root_dir='.')</a></li>
<li><a href="#def-has_ctags">def has_ctags()</a></li>
<li><a href="#def-main_15">def main()</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#utils-directory">utils/ Directory</a><ul>
<li><a href="#utils__init__py">utils/__init__.py</a></li>
<li><a href="#utilsloggerpy">utils/logger.py</a><ul>
<li><a href="#class-logger">class Logger</a><ul>
<li><a href="#def-__init__self-schema_pathlogging_schemamd-log_pathlogsactivitylogjsonl">def __init__(self, schema_path='LOGGING_SCHEMA.md', log_path='logs/activity.log.jsonl')</a></li>
<li><a href="#def-logself-phase-task_id-plan_step-action_type-action_details-outcome_status-outcome_message-error_detailsnone-evidence">def log(self, phase, task_id, plan_step, action_type, action_details, outcome_status, outcome_message='', error_details=None, evidence='')</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#protocol-deep-research-cycle">Protocol: Deep Research Cycle</a></li>
</ul>
</div>

        </nav>
        <article id="readme">
<h2 id="human-readable-metalanguage-readmemd">Human-Readable Metalanguage (README.md)</h2>
<h1 id="project-chimera-an-agent-self-improvement-protocol">Project Chimera: An Agent Self-Improvement Protocol</h1>
<h2 id="overview">Overview</h2>
<p>This repository is a controlled environment for the self-experimentation and autonomous operation of the AI agent Jules. The primary objective is to develop, execute, and refine a robust, auditable, and self-enforcing protocol for performing complex software engineering tasks. The system is designed around a core principle: <strong>the protocol is the code.</strong></p>
<p>The project automatically generates this README, its system documentation, and its core operational protocols (<code>AGENTS.md</code>) from source. This ensures that the documentation and the codebase are always in sync.</p>
<h2 id="core-architecture-the-integrated-fsm-workflow">Core Architecture: The Integrated FSM Workflow</h2>
<p>The agent's operation is governed by a unified workflow that integrates an interactive execution engine with a formal validation toolchain.</p>
<ol>
<li><strong>Execution Engine (<code>tooling/master_control.py</code>):</strong> A Finite State Machine (FSM) that orchestrates the agent's actions. It is the heart of the system, driving the agent through the formal phases of a task.</li>
<li><strong>Validation &amp; Management Toolchain (<code>tooling/fdc_cli.py</code>):</strong> A command-line interface that provides formal validation of plans and automated management of the task lifecycle.</li>
</ol>
<p>These two components work together to ensure every task is executed in a controlled, predictable, and verifiable manner.</p>
<h2 id="core-protocols">Core Protocols</h2>
<p>This project is governed by a series of machine-readable protocols defined in <code>AGENTS.md</code>. These protocols are the source of truth for the agent's behavior. The key protocols are:</p>
<ul>
<li><strong><code>aorp-header</code></strong>: Defines the identity and versioning of the Advanced Orientation and Research Protocol (AORP).</li>
<li><strong><code>agent-bootstrap-001</code></strong>: A foundational protocol that dictates the agent's initial actions upon starting any task.</li>
<li><strong><code>core-directive-001</code></strong>: The mandatory first action for any new task, ensuring a formal start to the Finite Development Cycle (FDC).</li>
<li><strong><code>decidability-constraints-001</code></strong>: Ensures all development processes are formally decidable and computationally tractable.</li>
<li><strong><code>orientation-cascade-001</code></strong>: Defines the mandatory, four-tiered orientation cascade that must be executed at the start of any task to establish a coherent model of the agent's identity, environment, and the world state.</li>
<li><strong><code>fdc-protocol-001</code></strong>: Defines the Finite Development Cycle (FDC), a formally defined process for executing a single, coherent task.</li>
<li><strong><code>standing-orders-001</code></strong>: A set of non-negotiable, high-priority mandates that govern the agent's behavior across all tasks.</li>
<li><strong><code>best-practices-001</code></strong>: A set of best practices derived from observing successful, data-driven workflow patterns.</li>
<li><strong><code>meta-protocol-001</code></strong>: A meta-protocol governing the agent's awareness and maintenance of its own core protocol files.</li>
<li><strong><code>cfdc-protocol-001</code></strong>: Defines the Context-Free Development Cycle (CFDC), a hierarchical planning and execution model.</li>
<li><strong><code>self-correction-protocol-001</code></strong>: Defines the automated, closed-loop workflow for protocol self-correction.</li>
<li><strong><code>non-compliance-protocol-001</code></strong>: A protocol that defines non-compliance with AGENTS.md and specifies corrective actions.</li>
<li><strong><code>pre-commit-protocol-001</code></strong>: Defines the mandatory pre-commit checks to ensure code quality, correctness, and readiness for submission.</li>
<li><strong><code>reset-all-authorization-001</code></strong>: Requires explicit user authorization via a token file for the use of the destructive <code>reset_all</code> tool.</li>
<li><strong><code>research-protocol-001</code></strong>: A protocol for conducting systematic research using the integrated research toolchain.</li>
<li><strong><code>reset-all-prohibition-001</code></strong>: A high-priority protocol that unconditionally forbids the use of the <code>reset_all</code> tool.</li>
<li><strong><code>critic-meta-protocol-001</code></strong>: A meta-protocol that governs the behavior and evaluation criteria of the Code Review Critic agent.</li>
<li><strong><code>critic-reset-prohibition-001</code></strong>: A specific, high-priority protocol that forbids the Code Review Critic agent from using the 'reset_all' tool.</li>
<li><strong><code>deep-research-cycle-001</code></strong>: A standardized, callable plan for conducting in-depth research on a complex topic.</li>
<li><strong><code>protocol-reset-all-pre-check-001</code></strong>: A protocol that mandates a pre-execution check for the <code>reset_all</code> tool to prevent unauthorized use.</li>
<li><strong><code>research-fdc-001</code></strong>: Defines the formal Finite Development Cycle (FDC) for conducting deep research.</li>
</ul>
<h2 id="key-components">Key Components</h2>
<ul>
<li><strong><code>tooling/master_control.py</code></strong>:</li>
</ul>
<blockquote>
<p>The master orchestrator for the agent's lifecycle, governed by a Finite State Machine.\n  &gt; \n  &gt; This script, <code>master_control.py</code>, is the heart of the agent's operational loop.\n  &gt; It implements a strict, protocol-driven workflow defined in a JSON file\n  &gt; (typically <code>tooling/fsm.json</code>). The <code>MasterControlGraph</code> class reads this FSM\n  &gt; definition and steps through the prescribed states, ensuring that the agent\n  &gt; cannot deviate from the established protocol.\n  &gt; \n  &gt; The key responsibilities of this orchestrator include:\n  &gt; - <strong>State Enforcement:</strong> Guiding the agent through the formal states of a task:\n  &gt;   ORIENTING, PLANNING, EXECUTING, FINALIZING, and finally AWAITING_SUBMISSION.\n  &gt; - <strong>Plan Validation:</strong> Before execution, it invokes the <code>fdc_cli.py</code> tool to\n  &gt;   formally validate the agent-generated <code>plan.txt</code>, preventing the execution of\n  &gt;   invalid or unsafe plans.\n  &gt; - <strong>Hierarchical Execution (CFDC):</strong> It manages the plan execution stack, which\n  &gt;   is the core mechanism of the Context-Free Development Cycle (CFDC). This\n  &gt;   allows plans to call other plans as sub-routines via the <code>call_plan</code>\n  &gt;   directive.\n  &gt; - <strong>Recursion Safety:</strong> It enforces a <code>MAX_RECURSION_DEPTH</code> on the plan stack to\n  &gt;   guarantee that the execution process is always decidable and will terminate.\n  &gt; - <strong>Lifecycle Management:</strong> It orchestrates the entire lifecycle, from initial\n  &gt;   orientation and environmental probing to the final post-mortem analysis and\n  &gt;   compilation of lessons learned.\n  &gt; \n  &gt; The FSM operates by waiting for specific signals—typically the presence of\n  &gt; files like <code>plan.txt</code> or <code>step_complete.txt</code>—before transitioning to the next\n  &gt; state. This creates a robust, interactive loop where the orchestrator directs\n  &gt; the high-level state, and the agent is responsible for completing the work\n  &gt; required to advance that state.</p>
</blockquote>
<ul>
<li><strong><code>tooling/fdc_cli.py</code></strong>:</li>
</ul>
<blockquote>
<p>Provides the command-line interface for the Finite Development Cycle (FDC).\n  &gt; \n  &gt; This script is a core component of the agent's protocol, offering tools to ensure\n  &gt; that all development work is structured, verifiable, and safe. It is used by both\n  &gt; the agent to signal progress and the <code>master_control.py</code> orchestrator to\n  &gt; validate the agent's plans before execution.\n  &gt; \n  &gt; The CLI provides several key commands:\n  &gt; - <code>close</code>: Logs the formal end of a task, signaling to the orchestrator that\n  &gt;   execution is complete.\n  &gt; - <code>validate</code>: Performs a deep validation of a plan file against the FDC's Finite\n  &gt;   State Machine (FSM) definition. It checks for both syntactic correctness (Is\n  &gt;   the sequence of operations valid?) and semantic correctness (Does the plan try\n  &gt;   to use a file before creating it?).\n  &gt; - <code>analyze</code>: Reads a plan and provides a high-level analysis of its\n  &gt;   characteristics, such as its computational complexity and whether it is a\n  &gt;   read-only or read-write plan.\n  &gt; - <code>lint</code>: A comprehensive "linter" that runs a full suite of checks on a plan\n  &gt;   file, including <code>validate</code>, <code>analyze</code>, and checks for disallowed recursion.</p>
</blockquote>
<ul>
<li><strong><code>tooling/protocol_compiler.py</code></strong>:</li>
</ul>
<blockquote>
<p>Compiles source protocol files into unified, human-readable and machine-readable artifacts.\n  &gt; \n  &gt; This script is the engine behind the "protocol as code" principle. It discovers,\n  &gt; validates, and assembles protocol definitions from a source directory (e.g., <code>protocols/</code>)\n  &gt; into high-level documents like <code>AGENTS.md</code>.\n  &gt; \n  &gt; Key Functions:\n  &gt; - <strong>Discovery:</strong> Scans a directory for source files, including <code>.protocol.json</code>\n  &gt;   (machine-readable rules) and <code>.protocol.md</code> (human-readable context).\n  &gt; - <strong>Validation:</strong> Uses a JSON schema (<code>protocol.schema.json</code>) to validate every\n  &gt;   <code>.protocol.json</code> file, ensuring all protocol definitions are syntactically\n  &gt;   correct and adhere to the established structure.\n  &gt; - <strong>Compilation:</strong> Combines the human-readable markdown and the machine-readable\n  &gt;   JSON into a single, cohesive Markdown file, embedding the JSON in code blocks.\n  &gt; - <strong>Documentation Injection:</strong> Can inject other generated documents, like the\n  &gt;   <code>SYSTEM_DOCUMENTATION.md</code>, into the final output at specified locations.\n  &gt; - <strong>Knowledge Graph Generation:</strong> Optionally, it can process the validated JSON\n  &gt;   protocols and serialize them into an RDF knowledge graph (in Turtle format),\n  &gt;   creating a machine-queryable version of the agent's governing rules.\n  &gt; \n  &gt; This process ensures that <code>AGENTS.md</code> and other protocol documents are not edited\n  &gt; manually but are instead generated from a validated, single source of truth,\n  &gt; making the agent's protocols robust, verifiable, and maintainable.</p>
</blockquote>
<ul>
<li><strong><code>tooling/doc_generator.py</code></strong>:</li>
</ul>
<blockquote>
<p>Generates detailed system documentation from Python source files.\n  &gt; \n  &gt; This script scans specified directories for Python files, parses their\n  &gt; Abstract Syntax Trees (ASTs), and extracts documentation for the module,\n  &gt; classes, and functions. The output is a structured Markdown file.\n  &gt; \n  &gt; This is a key component of the project's self-documentation capabilities,\n  &gt; powering the <code>SYSTEM_DOCUMENTATION.md</code> artifact in the <code>knowledge_core</code>.\n  &gt; \n  &gt; The script is configured via top-level constants:\n  &gt; - <code>SCAN_DIRECTORIES</code>: A list of directories to search for .py files.\n  &gt; - <code>OUTPUT_FILE</code>: The path where the final Markdown file will be written.\n  &gt; - <code>DOC_TITLE</code>: The main title for the generated documentation file.\n  &gt; \n  &gt; It uses Python's <code>ast</code> module to reliably parse source files without\n  &gt; importing them, which avoids issues with dependencies or script side-effects.</p>
</blockquote>
<ul>
<li><strong><code>tooling/protocol_auditor.py</code></strong>:</li>
</ul>
<blockquote>
<p>Audits the agent's behavior against its governing protocols and generates a report.\n  &gt; \n  &gt; This script performs a comprehensive analysis to ensure the agent's actions,\n  &gt; as recorded in the activity log, align with the defined protocols in AGENTS.md.\n  &gt; It serves as a critical feedback mechanism for maintaining operational integrity.\n  &gt; The final output is a detailed <code>audit_report.md</code> file.\n  &gt; \n  &gt; The auditor performs three main checks:\n  &gt; 1.  <strong><code>AGENTS.md</code> Source Check:</strong> Verifies if the <code>AGENTS.md</code> build artifact is\n  &gt;     potentially stale by comparing its modification time against the source\n  &gt;     protocol files in the <code>protocols/</code> directory.\n  &gt; 2.  <strong>Protocol Completeness:</strong> It cross-references the tools used in the log\n  &gt;     (<code>logs/activity.log.jsonl</code>) against the tools defined in <code>AGENTS.md</code> to find:\n  &gt;     - Tools used but not associated with any formal protocol.\n  &gt;     - Tools defined in protocols but never used in the log.\n  &gt; 3.  <strong>Tool Centrality:</strong> It conducts a frequency analysis of tool usage to\n  &gt;     identify which tools are most critical to the agent's workflow.\n  &gt; \n  &gt; The script parses all embedded JSON protocol blocks within <code>AGENTS.md</code> and reads\n  &gt; from the standard <code>logs/activity.log.jsonl</code> log file, providing a reliable and\n  &gt; accurate audit.</p>
</blockquote>
<ul>
<li><strong><code>tooling/self_improvement_cli.py</code></strong>:</li>
</ul>
<blockquote>
<p>Analyzes agent activity logs to identify opportunities for self-improvement.\n  &gt; \n  &gt; This script is a command-line tool that serves as a key part of the agent's\n  &gt; meta-cognitive loop. It parses the structured activity log\n  &gt; (<code>logs/activity.log.jsonl</code>) to identify patterns that may indicate\n  &gt; inefficiencies or errors in the agent's workflow.\n  &gt; \n  &gt; The primary analysis currently implemented is:\n  &gt; - <strong>Planning Efficiency Analysis:</strong> It scans the logs for tasks that required\n  &gt;   multiple <code>set_plan</code> actions. A high number of plan revisions for a single\n  &gt;   task can suggest that the initial planning phase was insufficient, the task\n  &gt;   was poorly understood, or the agent struggled to adapt to unforeseen\n  &gt;   challenges.\n  &gt; \n  &gt; By flagging these tasks, the script provides a starting point for a deeper\n  &gt; post-mortem analysis, helping the agent (or its developers) to understand the\n  &gt; root causes of the planning churn and to develop strategies for more effective\n  &gt; upfront planning in the future.\n  &gt; \n  &gt; The tool is designed to be extensible, with future analyses (such as error\n  &gt; rate tracking or tool usage anti-patterns) to be added as the system evolves.</p>
</blockquote>
<h2 id="build-system-usage">Build System &amp; Usage</h2>
<p>This project uses a <code>Makefile</code> to automate common development tasks.</p>
<ul>
<li><code>make build</code>: The main command. Generates all documentation (<code>README.md</code>, <code>SYSTEM_DOCUMENTATION.md</code>) and compiles all protocols (<code>AGENTS.md</code>, <code>SECURITY.md</code>).</li>
<li><code>make test</code>: Runs the complete unit test suite.</li>
<li><code>make format</code>: Formats all Python code using <code>black</code>.</li>
<li><code>make lint</code>: Lints all Python code using <code>flake8</code>.</li>
<li><code>make clean</code>: Removes all generated artifacts.</li>
</ul>
</article>
<hr>

<article id="agents-md">
<h2 id="machine-readable-metalanguage-agentsmd">Machine-Readable Metalanguage (AGENTS.md)</h2>
<h1 id="-">---</h1>
<h1 id="do-not-edit-this-file-directly">DO NOT EDIT THIS FILE DIRECTLY.</h1>
<h1 id="this-file-is-programmatically-generated-by-the-protocol_compilerpy-script">This file is programmatically generated by the <code>protocol_compiler.py</code> script.</h1>
<h1 id="all-changes-to-agent-protocols-must-be-made-in-the-source-files">All changes to agent protocols must be made in the source files</h1>
<h1 id="located-in-the-protocols-directory">located in the <code>protocols/</code> directory.</h1>
<h1 id="_1"></h1>
<h1 id="this-file-contains-the-compiled-protocols-in-a-human-readable-markdown-format">This file contains the compiled protocols in a human-readable Markdown format,</h1>
<h1 id="with-machine-readable-json-definitions-embedded">with machine-readable JSON definitions embedded.</h1>
<h1 id="-_1">---</h1>
<h1 id="jules-agent-protocol-the-hierarchical-development-cycle">Jules Agent Protocol: The Hierarchical Development Cycle</h1>
<p><strong>Version:</strong> 4.0.0</p>
<hr />
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;aorp-header&quot;,
  &quot;description&quot;: &quot;Defines the identity and versioning of the Advanced Orientation and Research Protocol (AORP).&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;aorp-identity&quot;,
      &quot;description&quot;: &quot;The governing protocol set is identified as the Advanced Orientation and Research Protocol (AORP).&quot;,
      &quot;enforcement&quot;: &quot;Protocol is identified by its name in documentation and compiled artifacts.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;aorp-versioning&quot;,
      &quot;description&quot;: &quot;The official protocol version is tracked in the VERSION file in the repository root, following Semantic Versioning (SemVer).&quot;,
      &quot;enforcement&quot;: &quot;Build or validation scripts should verify the presence and format of the VERSION file.&quot;
    }
  ]
}
</code></pre>
<hr />
<h1 id="jules-agent-protocol-the-hierarchical-development-cycle_1">Jules Agent Protocol: The Hierarchical Development Cycle</h1>
<p><strong>Version:</strong> 4.0.0</p>
<hr />
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;agent-bootstrap-001&quot;,
  &quot;description&quot;: &quot;A foundational protocol that dictates the agent's initial actions upon starting any task.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;bootstrap-load-agents-md&quot;,
      &quot;description&quot;: &quot;Upon initialization for any task, the agent's first and highest-priority action must be to locate, read, and parse the AGENTS.md file in the repository root. This ensures the agent is properly contextualized before any planning or execution begins.&quot;,
      &quot;enforcement&quot;: &quot;This rule is enforced by the agent's core startup logic. The agent must verify the load of AGENTS.md before proceeding to the planning phase.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;read_file&quot;
  ]
}
</code></pre>
<hr />
<h2 id="1-the-core-problem-ensuring-formally-verifiable-execution">1. The Core Problem: Ensuring Formally Verifiable Execution</h2>
<p>To tackle complex tasks reliably, an agent's workflow must be formally structured and guaranteed to terminate—it must be <strong>decidable</strong>. This is achieved through a hierarchical system composed of a high-level <strong>Orchestrator</strong> that manages the agent's overall state and a low-level <strong>FDC Toolchain</strong> that governs the validity of the agent's plans. This structure prevents the system from entering paradoxical, non-terminating loops.</p>
<hr />
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;core-directive-001&quot;,
  &quot;description&quot;: &quot;The mandatory first action for any new task, ensuring a formal start to the Finite Development Cycle (FDC).&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;mandatory-fdc-start&quot;,
      &quot;description&quot;: &quot;Upon receiving a new task, the agent's first action MUST be to programmatically execute the FDC 'start' command to formally initiate the task and run the AORP orientation cascade.&quot;,
      &quot;enforcement&quot;: &quot;This is a hard-coded behavior in the agent's core operational loop and is verified by the FDC toolchain.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;tooling/fdc_cli.py&quot;
  ]
}
</code></pre>
<hr />
<h2 id="2-the-solution-a-two-layered-fsm-system">2. The Solution: A Two-Layered FSM System</h2>
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;decidability-constraints-001&quot;,
  &quot;description&quot;: &quot;Ensures all development processes are formally decidable and computationally tractable.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;non-turing-completeness&quot;,
      &quot;description&quot;: &quot;The agent's planning and execution language is, by design, not Turing-complete. This is a fundamental constraint to guarantee that all processes will terminate.&quot;,
      &quot;enforcement&quot;: &quot;Enforced by the design of the plan runner and validated by the `lint` command in the FDC toolchain.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;bounded-recursion&quot;,
      &quot;description&quot;: &quot;The agent MUST NOT generate plans that involve recursion or self-invocation. A plan cannot trigger another FDC or a sub-plan, with the sole exception of the 'Deep Research Cycle'.&quot;,
      &quot;enforcement&quot;: &quot;The `lint` command in `tooling/fdc_cli.py` scans plans for disallowed recursive calls.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;fsm-adherence&quot;,
      &quot;description&quot;: &quot;All plans must be valid strings in the language defined by the tooling/fdc_fsm.json Finite State Machine.&quot;,
      &quot;enforcement&quot;: &quot;The `lint` command in `tooling/fdc_cli.py` validates the plan against the FSM definition.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;tooling/fdc_cli.py&quot;,
    &quot;tooling/fdc_fsm.json&quot;
  ]
}
</code></pre>
<hr />
<h3 id="layer-1-the-orchestrator-master_controlpy-fsmjson">Layer 1: The Orchestrator (<code>master_control.py</code> &amp; <code>fsm.json</code>)</h3>
<p>The Orchestrator is the master Finite State Machine (FSM) that guides the agent through its entire lifecycle, from orientation to submission. It is not directly controlled by the agent's plan but rather directs the agent's state based on the successful completion of each phase.</p>
<p><strong>Key States (defined in <code>tooling/fsm.json</code>):</strong>
*   <code>ORIENTING</code>: The initial state where the agent gathers context.
*   <code>PLANNING</code>: The state where the Orchestrator waits for the agent to produce a <code>plan.txt</code>.
*   <code>EXECUTING</code>: The state where the Orchestrator oversees the step-by-step execution of the validated plan.
*   <code>POST_MORTEM</code>: The state for finalizing the task and recording learnings.
*   <code>AWAITING_SUBMISSION</code>: The final state before the code is submitted.</p>
<p><strong>The Orchestrator's Critical Role in Planning:</strong>
During the <code>PLANNING</code> state, the Orchestrator's most important job is to validate the agent-generated <code>plan.txt</code>. It does this by calling the FDC Toolchain's <code>lint</code> command. <strong>A plan that fails this check will halt the entire process, preventing the agent from entering an invalid state.</strong></p>
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;orientation-cascade-001&quot;,
  &quot;description&quot;: &quot;Defines the mandatory, four-tiered orientation cascade that must be executed at the start of any task to establish a coherent model of the agent's identity, environment, and the world state.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;l1-self-awareness&quot;,
      &quot;description&quot;: &quot;Level 1 (Self-Awareness): The agent must first establish its own identity and inherent limitations by reading the `knowledge_core/agent_meta.json` artifact.&quot;,
      &quot;enforcement&quot;: &quot;The `start` command of the FDC toolchain executes this step and fails if the artifact is missing or invalid.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;l2-repository-sync&quot;,
      &quot;description&quot;: &quot;Level 2 (Repository Sync): The agent must understand the current state of the local repository by loading primary artifacts from the `knowledge_core/` directory.&quot;,
      &quot;enforcement&quot;: &quot;The `start` command of the FDC toolchain executes this step.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;l3-environmental-probing&quot;,
      &quot;description&quot;: &quot;Level 3 (Environmental Probing &amp; Targeted RAG): The agent must discover the rules and constraints of its operational environment by executing a probe script and using targeted RAG to resolve 'known unknowns'.&quot;,
      &quot;enforcement&quot;: &quot;The `start` command of the FDC toolchain executes this step, utilizing tools like `google_search` and `view_text_website`.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;l4-deep-research-cycle&quot;,
      &quot;description&quot;: &quot;Level 4 (Deep Research Cycle): To investigate 'unknown unknowns', the agent must initiate a formal, self-contained Finite Development Cycle (FDC) of the 'Analysis Modality'.&quot;,
      &quot;enforcement&quot;: &quot;This is a special case of recursion, explicitly allowed and managed by the FDC toolchain.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;tooling/environmental_probe.py&quot;,
    &quot;google_search&quot;,
    &quot;view_text_website&quot;
  ]
}
</code></pre>
<hr />
<h3 id="layer-2-the-fdc-toolchain-fdc_clipy-fdc_fsmjson">Layer 2: The FDC Toolchain (<code>fdc_cli.py</code> &amp; <code>fdc_fsm.json</code>)</h3>
<p>The FDC Toolchain is a set of utilities that the agent uses to structure its work and that the Orchestrator uses for validation. The toolchain is governed by its own FSM (<code>tooling/fdc_fsm.json</code>), which defines the legal sequence of commands <em>within a plan</em>.</p>
<h4 id="fdc-commands-for-agent-use"><strong>FDC Commands for Agent Use:</strong></h4>
<p><strong><code>start</code> - Task Initiation</strong>
*   <strong>Usage:</strong> The first command the agent MUST issue upon receiving a task.
*   <strong>Command:</strong> <code>run_in_bash_session python3 tooling/fdc_cli.py start --task-id "your-task-id"</code>
*   <strong>Function:</strong> Logs the <code>TASK_START</code> event, formally beginning the development cycle.</p>
<p><strong><code>lint</code> - Pre-Flight Plan Validation</strong>
*   <strong>Usage:</strong> A command the agent can use to self-correct its own plan before finalizing it. The Orchestrator will <em>always</em> run this command on <code>plan.txt</code> as a mandatory check.
*   <strong>Command:</strong> <code>run_in_bash_session python3 tooling/fdc_cli.py lint &lt;plan_file.txt&gt;</code>
*   <strong>Function:</strong> Performs a comprehensive check against the low-level FSM:
    1.  <strong>Closure Mandate:</strong> Ensures the plan's final action is a call to the <code>close</code> command.
    2.  <strong>FSM Validation:</strong> Validates the sequence of agent tools against <code>tooling/fdc_fsm.json</code>.
    3.  <strong>Semantic Validation:</strong> Checks for errors like using a file before creating it.</p>
<p><strong><code>close</code> - Task Closure</strong>
*   <strong>Usage:</strong> The <strong>last command</strong> in any valid plan.
*   <strong>Command:</strong> <code>run_in_bash_session python3 tooling/fdc_cli.py close --task-id "your-task-id"</code>
*   <strong>Function:</strong> Logs <code>TASK_END</code>, generates a post-mortem template, and signals to the Orchestrator that plan execution is complete.</p>
<hr />
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;fdc-protocol-001&quot;,
  &quot;description&quot;: &quot;Defines the Finite Development Cycle (FDC), a formally defined process for executing a single, coherent task.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;fdc-entry-point&quot;,
      &quot;description&quot;: &quot;The AORP cascade is the mandatory entry point to every FDC.&quot;,
      &quot;enforcement&quot;: &quot;Enforced by the `start` command in `tooling/fdc_cli.py`.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;fdc-state-transitions&quot;,
      &quot;description&quot;: &quot;The FDC is a Finite State Machine (FSM) formally defined in `tooling/fdc_fsm.json`. Plans must be valid strings in the language defined by this FSM.&quot;,
      &quot;enforcement&quot;: &quot;Validated by the `lint` command in `tooling/fdc_cli.py`.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;phase1-deconstruction&quot;,
      &quot;description&quot;: &quot;Phase 1 (Deconstruction &amp; Contextualization): The agent must ingest the task, query historical logs, identify entities using the symbol map, and analyze impact using the dependency graph.&quot;,
      &quot;enforcement&quot;: &quot;Procedural step guided by the agent's core logic, using artifacts in `logs/` and `knowledge_core/`.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;phase2-planning&quot;,
      &quot;description&quot;: &quot;Phase 2 (Planning &amp; Self-Correction): The agent must generate a granular plan, lint it using the FDC toolchain, cite evidence for its steps, and perform a critical review.&quot;,
      &quot;enforcement&quot;: &quot;The `lint` command in `tooling/fdc_cli.py` is a mandatory pre-flight check.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;phase3-execution&quot;,
      &quot;description&quot;: &quot;Phase 3 (Execution &amp; Structured Logging): The agent must execute the validated plan and log every action according to the `LOGGING_SCHEMA.md`.&quot;,
      &quot;enforcement&quot;: &quot;Logging is performed by the agent's action execution wrapper.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;phase4-post-mortem&quot;,
      &quot;description&quot;: &quot;Phase 4 (Pre-Submission Post-Mortem): The agent must formally close the task using the `close` command and complete the generated post-mortem report.&quot;,
      &quot;enforcement&quot;: &quot;The `close` command in `tooling/fdc_cli.py` initiates this phase.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;tooling/fdc_cli.py&quot;,
    &quot;tooling/fdc_fsm.json&quot;,
    &quot;knowledge_core/symbols.json&quot;,
    &quot;knowledge_core/dependency_graph.json&quot;,
    &quot;LOGGING_SCHEMA.md&quot;
  ]
}
</code></pre>
<hr />
<h3 id="standing-orders">STANDING ORDERS</h3>
<ol>
<li><strong>Orchestrator is Sovereign:</strong> The agent's lifecycle is governed by <code>master_control.py</code>. The agent's primary job is to provide a valid <code>plan.txt</code> when the Orchestrator enters the <code>PLANNING</code> state.</li>
<li><strong>Toolchain is Law:</strong> All plans must be valid according to the <code>fdc_cli.py lint</code> command. A valid plan is one that passes the Closure Mandate and is a valid string in the language defined by <code>fdc_fsm.json</code>.</li>
<li><strong>Hierarchy is Structure:</strong> The Orchestrator (<code>master_control.py</code>) validates the agent's plan using the FDC Toolchain (<code>fdc_cli.py</code>). This separation ensures a robust, verifiable, and decidable development process, preventing the system from executing paradoxical or non-terminating plans.</li>
</ol>
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;standing-orders-001&quot;,
  &quot;description&quot;: &quot;A set of non-negotiable, high-priority mandates that govern the agent's behavior across all tasks.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;aorp-mandate&quot;,
      &quot;description&quot;: &quot;All Finite Development Cycles (FDCs) MUST be initiated using the FDC toolchain's 'start' command. This is non-negotiable.&quot;,
      &quot;enforcement&quot;: &quot;Enforced by the agent's core operational loop and the `start` command in `tooling/fdc_cli.py`.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;rag-mandate&quot;,
      &quot;description&quot;: &quot;For any task involving external technologies, Just-In-Time External RAG is REQUIRED to verify current best practices. Do not trust internal knowledge.&quot;,
      &quot;enforcement&quot;: &quot;This is a core principle of the L3 orientation phase, utilizing tools like `google_search`.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;fdc-toolchain-mandate&quot;,
      &quot;description&quot;: &quot;Use the `fdc_cli.py` tool for all core FDC state transitions: task initiation ('start'), plan linting ('lint'), and task closure ('close').&quot;,
      &quot;enforcement&quot;: &quot;The agent's internal logic is designed to prefer these specific tool commands for FDC state transitions.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;tooling/fdc_cli.py&quot;,
    &quot;google_search&quot;,
    &quot;view_text_website&quot;
  ]
}
</code></pre>
<hr />
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;best-practices-001&quot;,
  &quot;description&quot;: &quot;A set of best practices derived from observing successful, data-driven workflow patterns.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;verify-after-write&quot;,
      &quot;description&quot;: &quot;After every file creation or modification action (`create_file_with_block`, `overwrite_file_with_block`, `replace_with_git_merge_diff`), the agent MUST use a subsequent read-only tool (`read_file`, `list_files`, `grep`) to verify that the action was executed successfully and had the intended effect. A plan step should only be marked as complete after this verification.&quot;,
      &quot;enforcement&quot;: &quot;This is a core operational discipline. Future tooling, such as a trace validator, could enforce this by analyzing the execution log against this protocol.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;create_file_with_block&quot;,
    &quot;overwrite_file_with_block&quot;,
    &quot;replace_with_git_merge_diff&quot;,
    &quot;delete_file&quot;,
    &quot;read_file&quot;,
    &quot;list_files&quot;,
    &quot;grep&quot;
  ]
}
</code></pre>
<hr />
<h1 id="meta-protocol-agentsmd-self-management">Meta-Protocol: <code>AGENTS.md</code> Self-Management</h1>
<p>This protocol defines how the agent should manage its own core <code>AGENTS.md</code> file.</p>
<p><strong>Rule <code>agents-md-self-awareness</code></strong>: The <code>AGENTS.md</code> file is not a static document; it is a build artifact compiled from the source files located in the <code>protocols/</code> directory. This compilation is handled by the <code>make AGENTS.md</code> command, which orchestrates the <code>tooling/protocol_compiler.py</code> script.</p>
<p>To ensure that you are always operating under the most current set of rules and directives, you must periodically run <code>make AGENTS.md</code>. This is especially critical at the beginning of a new task or if you observe behavior that seems inconsistent with your documented protocols, as the protocols may have been updated.</p>
<p>This act of self-maintenance is a foundational element of robust, autonomous operation. It ensures that your understanding of your own governing principles remains synchronized with the repository's ground truth.</p>
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;meta-protocol-001&quot;,
  &quot;description&quot;: &quot;A meta-protocol governing the agent's awareness and maintenance of its own core protocol files.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;agents-md-self-awareness&quot;,
      &quot;description&quot;: &quot;The AGENTS.md file is a build artifact generated from source files in the 'protocols/' directory. Before relying on AGENTS.md, the agent should ensure it is up-to-date by running 'make AGENTS.md'. This ensures the agent is operating with the latest set of protocols.&quot;,
      &quot;enforcement&quot;: &quot;The agent should incorporate this check into its standard operating procedure, particularly at the beginning of a task or when unexpected behavior occurs.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;run_in_bash_session&quot;
  ]
}
</code></pre>
<hr />
<h1 id="protocol-the-context-free-development-cycle-cfdc">Protocol: The Context-Free Development Cycle (CFDC)</h1>
<p>This protocol marks a significant evolution from the Finite Development Cycle (FDC), introducing a hierarchical planning model that enables far greater complexity and modularity while preserving the system's core guarantee of decidability.</p>
<h2 id="from-fsm-to-pushdown-automaton">From FSM to Pushdown Automaton</h2>
<p>The FDC was based on a Finite State Machine (FSM), which provided a strict, linear sequence of operations. While robust, this model was fundamentally limited: it could not handle nested tasks or sub-routines, forcing all plans to be monolithic.</p>
<p>The CFDC upgrades our execution model to a <strong>Pushdown Automaton</strong>. This is achieved by introducing a <strong>plan execution stack</strong>, which allows the system to call other plans as sub-routines. This enables a powerful new paradigm: <strong>Context-Free Development Cycles</strong>.</p>
<h2 id="the-call_plan-directive">The <code>call_plan</code> Directive</h2>
<p>The core of the CFDC is the new <code>call_plan</code> directive. This allows one plan to execute another, effectively creating a parent-child relationship between them.</p>
<ul>
<li><strong>Usage:</strong> <code>call_plan &lt;path_to_sub_plan.txt&gt;</code></li>
<li><strong>Function:</strong> When the execution engine encounters this directive, it:<ol>
<li>Pushes the current plan's state (e.g., the current step number) onto the execution stack.</li>
<li>Begins executing the sub-plan specified in the path.</li>
<li>Once the sub-plan completes, it pops the parent plan's state from the stack and resumes its execution from where it left off.</li>
</ol>
</li>
</ul>
<h2 id="ensuring-decidability-the-recursion-depth-limit">Ensuring Decidability: The Recursion Depth Limit</h2>
<p>A system with unbounded recursion is not guaranteed to terminate. To prevent this, the CFDC introduces a non-negotiable, system-wide limit on the depth of the plan execution stack.</p>
<p><strong>Rule <code>max-recursion-depth</code></strong>: The execution engine MUST enforce a maximum recursion depth, defined by a <code>MAX_RECURSION_DEPTH</code> constant. If a <code>call_plan</code> directive would cause the stack depth to exceed this limit, the entire process MUST terminate with an error. This hard limit ensures that even with recursive or deeply nested plans, the system remains a <strong>decidable</strong>, non-Turing-complete process that is guaranteed to halt.</p>
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;cfdc-protocol-001&quot;,
  &quot;description&quot;: &quot;Defines the Context-Free Development Cycle (CFDC), a hierarchical planning and execution model.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;hierarchical-planning-via-call-plan&quot;,
      &quot;description&quot;: &quot;Plans may execute other plans as sub-routines using the 'call_plan &lt;path_to_plan&gt;' directive. This enables a modular, hierarchical workflow.&quot;,
      &quot;enforcement&quot;: &quot;The plan validator must be able to parse this directive and recursively validate sub-plans. The execution engine must implement a plan execution stack to manage the context of nested calls.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;max-recursion-depth&quot;,
      &quot;description&quot;: &quot;To ensure decidability, the plan execution stack must not exceed a system-wide constant, MAX_RECURSION_DEPTH. This prevents infinite recursion and guarantees all processes will terminate.&quot;,
      &quot;enforcement&quot;: &quot;The execution engine must check the stack depth before every 'call_plan' execution and terminate with a fatal error if the limit would be exceeded.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;tooling/master_control.py&quot;,
    &quot;tooling/fdc_cli.py&quot;
  ]
}
</code></pre>
<hr />
<h1 id="protocol-the-plan-registry">Protocol: The Plan Registry</h1>
<p>This protocol introduces a Plan Registry to create a more robust, modular, and discoverable system for hierarchical plans. It decouples the act of calling a plan from its physical file path, allowing plans to be referenced by a logical name.</p>
<h2 id="the-problem-with-path-based-calls">The Problem with Path-Based Calls</h2>
<p>The initial implementation of the Context-Free Development Cycle (CFDC) relied on direct file paths (e.g., <code>call_plan path/to/plan.txt</code>). This is brittle:
- If a registered plan is moved or renamed, all plans that call it will break.
- It is difficult for an agent to discover and reuse existing, validated plans.</p>
<h2 id="the-solution-a-central-registry">The Solution: A Central Registry</h2>
<p>The Plan Registry solves this by creating a single source of truth that maps logical, human-readable plan names to their corresponding file paths.</p>
<ul>
<li><strong>Location:</strong> <code>knowledge_core/plan_registry.json</code></li>
<li><strong>Format:</strong> A simple JSON object of key-value pairs:
  <code>json
  {
    "logical-name-1": "path/to/plan_1.txt",
    "run-all-tests": "plans/common/run_tests.txt"
  }</code></li>
</ul>
<h2 id="updated-call_plan-logic">Updated <code>call_plan</code> Logic</h2>
<p>The <code>call_plan</code> directive is now significantly more powerful. When executing <code>call_plan &lt;argument&gt;</code>, the system will follow a <strong>registry-first</strong> approach:</p>
<ol>
<li><strong>Registry Lookup:</strong> The system will first treat <code>&lt;argument&gt;</code> as a logical name and look it up in <code>knowledge_core/plan_registry.json</code>.</li>
<li><strong>Path Fallback:</strong> If the name is not found in the registry, the system will fall back to treating <code>&lt;argument&gt;</code> as a direct file path. This ensures full backward compatibility with existing plans.</li>
</ol>
<h2 id="management">Management</h2>
<p>A new tool, <code>tooling/plan_manager.py</code>, will be introduced to manage the registry with simple commands like <code>register</code>, <code>deregister</code>, and <code>list</code>, making it easy to maintain the library of reusable plans.</p>
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;plan-registry-001&quot;,
  &quot;description&quot;: &quot;Defines a central registry for discovering and executing hierarchical plans by a logical name.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;registry-definition&quot;,
      &quot;description&quot;: &quot;A central plan registry MUST exist at 'knowledge_core/plan_registry.json'. It maps logical plan names to their file paths.&quot;,
      &quot;enforcement&quot;: &quot;The file's existence and format can be checked by the validation toolchain.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;registry-first-resolution&quot;,
      &quot;description&quot;: &quot;The 'call_plan &lt;argument&gt;' directive MUST first attempt to resolve '&lt;argument&gt;' as a logical name in the plan registry. If resolution fails, it MUST fall back to treating '&lt;argument&gt;' as a direct file path for backward compatibility.&quot;,
      &quot;enforcement&quot;: &quot;This logic must be implemented in both the plan validator (`fdc_cli.py`) and the execution engine (`master_control.py`).&quot;
    },
    {
      &quot;rule_id&quot;: &quot;registry-management-tool&quot;,
      &quot;description&quot;: &quot;A dedicated tool (`tooling/plan_manager.py`) MUST be provided for managing the plan registry, with functions to register, deregister, and list plans.&quot;,
      &quot;enforcement&quot;: &quot;The tool's existence and functionality can be verified via integration tests.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;tooling/plan_manager.py&quot;,
    &quot;tooling/master_control.py&quot;,
    &quot;tooling/fdc_cli.py&quot;
  ]
}
</code></pre>
<hr />
<h1 id="protocol-the-closed-loop-self-correction-cycle">Protocol: The Closed-Loop Self-Correction Cycle</h1>
<p>This protocol describes the automated workflow that enables the agent to programmatically improve its own governing protocols based on new knowledge. It transforms the ad-hoc, manual process of learning into a reliable, machine-driven feedback loop.</p>
<h2 id="the-problem-the-open-loop">The Problem: The Open Loop</h2>
<p>Previously, "lessons learned" were compiled into a simple markdown file, <code>knowledge_core/lessons_learned.md</code>. While this captured knowledge, it was a dead end. There was no automated process to translate these text-based insights into actual changes to the protocol source files. This required manual intervention, creating a significant bottleneck and a high risk of protocols becoming stale.</p>
<h2 id="the-solution-a-protocol-driven-self-correction-pdsc-workflow">The Solution: A Protocol-Driven Self-Correction (PDSC) Workflow</h2>
<p>The PDSC workflow closes the feedback loop by introducing a set of new tools and structured data formats that allow the agent to enact its own improvements.</p>
<p><strong>1. Structured, Actionable Lessons (<code>knowledge_core/lessons.jsonl</code>):</strong>
- Post-mortem analysis now generates lessons as structured JSON objects, not free-form text.
- Each lesson includes a machine-readable <code>action</code> field, which contains a specific, executable command.</p>
<p><strong>2. The Protocol Updater (<code>tooling/protocol_updater.py</code>):</strong>
- A new, dedicated tool for programmatically modifying the protocol source files (<code>*.protocol.json</code>).
- It accepts commands like <code>add-tool</code>, allowing for precise, automated changes to protocol definitions.</p>
<p><strong>3. The Orchestrator (<code>tooling/self_correction_orchestrator.py</code>):</strong>
- This script is the engine of the cycle. It reads <code>lessons.jsonl</code>, identifies pending lessons, and uses the <code>protocol_updater.py</code> to execute the defined actions.
- After applying a lesson, it updates the lesson's status, creating a clear audit trail.
- It finishes by running <code>make AGENTS.md</code> to ensure the changes are compiled into the live protocol.</p>
<p>This new, automated cycle—<strong>Analyze -&gt; Structure Lesson -&gt; Execute Correction -&gt; Re-compile Protocol</strong>—is a fundamental step towards autonomous self-improvement.</p>
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;self-correction-protocol-001&quot;,
  &quot;description&quot;: &quot;Defines the automated, closed-loop workflow for protocol self-correction.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;structured-lessons&quot;,
      &quot;description&quot;: &quot;Lessons learned from post-mortem analysis must be generated as structured, machine-readable JSON objects in `knowledge_core/lessons.jsonl`.&quot;,
      &quot;enforcement&quot;: &quot;The `tooling/knowledge_compiler.py` script is responsible for generating lessons in the correct format.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;programmatic-updates&quot;,
      &quot;description&quot;: &quot;All modifications to protocol source files must be performed programmatically via the `tooling/protocol_updater.py` tool to ensure consistency and prevent manual errors.&quot;,
      &quot;enforcement&quot;: &quot;Agent's core logic should be designed to use this tool for all protocol modifications.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;automated-orchestration&quot;,
      &quot;description&quot;: &quot;The self-correction cycle must be managed by the `tooling/self_correction_orchestrator.py` script, which processes pending lessons and triggers the necessary updates.&quot;,
      &quot;enforcement&quot;: &quot;This script is the designated engine for the PDSC workflow.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;programmatic-rule-refinement&quot;,
      &quot;description&quot;: &quot;The self-correction system can modify the description of existing protocol rules via the `update-rule` command in `tooling/protocol_updater.py`, allowing it to refine its own logic.&quot;,
      &quot;enforcement&quot;: &quot;The `tooling/knowledge_compiler.py` can generate `update-rule` actions, and the `tooling/self_correction_orchestrator.py` executes them.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;autonomous-code-suggestion&quot;,
      &quot;description&quot;: &quot;The self-correction system can generate and apply code changes to its own tooling. This is achieved through a `PROPOSE_CODE_CHANGE` action, which is processed by `tooling/code_suggester.py` to create an executable plan.&quot;,
      &quot;enforcement&quot;: &quot;The `tooling/self_correction_orchestrator.py` invokes the code suggester when it processes a lesson of this type.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;tooling/knowledge_compiler.py&quot;,
    &quot;tooling/protocol_updater.py&quot;,
    &quot;tooling/self_correction_orchestrator.py&quot;,
    &quot;tooling/code_suggester.py&quot;,
    &quot;initiate_memory_recording&quot;
  ],
  &quot;associated_artifacts&quot;: [
    &quot;knowledge_core/lessons.jsonl&quot;
  ]
}
</code></pre>
<hr />
<h1 id="protocol-agentsmd-non-compliance">Protocol: AGENTS.md Non-Compliance</h1>
<p>This protocol defines what constitutes non-compliance with the established <code>AGENTS.md</code> protocols and outlines the expected corrective actions. Adherence to these meta-rules is critical for ensuring predictable, verifiable, and robust agent behavior.</p>
<h2 id="rule-non-compliance-definition-definition-of-non-compliance">Rule <code>non-compliance-definition</code>: Definition of Non-Compliance</h2>
<p>Non-compliance is the act of violating the explicit rules, conventions, or procedures documented in the <code>AGENTS.md</code> file and its source protocols within the <code>protocols/</code> directory. The <code>AGENTS.md</code> file serves as the agent's primary operational mandate, and any deviation from it is considered a fault condition.</p>
<h2 id="rule-non-compliance-direct-editing-prohibition-of-direct-artifact-editing">Rule <code>non-compliance-direct-editing</code>: Prohibition of Direct Artifact Editing</h2>
<p><strong>Violation:</strong> Directly editing any file that is a documented build artifact.
- <strong>Primary Example:</strong> Modifying <code>AGENTS.md</code> or <code>README.md</code> directly is a severe violation. These files are generated from source protocols and documentation.
- <strong>Corrective Action:</strong> The agent must revert any direct edits to build artifacts. Changes must be made to the source files (e.g., in <code>protocols/</code> or tool docstrings), and the appropriate build command (e.g., <code>make AGENTS.md</code>, <code>make docs</code>) must be executed.</p>
<h2 id="rule-non-compliance-test-procedure-adherence-to-testing-protocols">Rule <code>non-compliance-test-procedure</code>: Adherence to Testing Protocols</h2>
<p><strong>Violation:</strong> Failing to execute the testing procedures as defined in <code>AGENTS.md</code> before submitting changes. This includes not running the full test suite or ignoring failing tests.
- <strong>Corrective Action:</strong> The agent must halt its execution plan and run the required tests. If tests fail, the agent must enter a debugging loop to resolve the failures before proceeding.</p>
<h2 id="rule-non-compliance-architectural-deviation-adherence-to-architectural-and-convention-guidelines">Rule <code>non-compliance-architectural-deviation</code>: Adherence to Architectural and Convention Guidelines</h2>
<p><strong>Violation:</strong> Introducing changes that contradict the architectural patterns, coding conventions, or file structures laid out in <code>AGENTS.md</code>.
- <strong>Example:</strong> Placing a new backend component in the <code>frontend/</code> directory when the architecture explicitly forbids it.
- <strong>Corrective Action:</strong> The agent must identify the deviation, revert the incorrect changes, and re-implement them in accordance with the documented standards.</p>
<h2 id="rule-non-compliance-self-awareness-failure-failure-to-maintain-protocol-awareness">Rule <code>non-compliance-self-awareness-failure</code>: Failure to Maintain Protocol Awareness</h2>
<p><strong>Violation:</strong> Operating with an outdated understanding of the protocols by failing to re-compile <code>AGENTS.md</code> when necessary, as defined in the <code>meta-protocol</code>.
- <strong>Corrective Action:</strong> If the agent detects that its actions are out of sync with repository standards, it should trigger the <code>make AGENTS.md</code> command to refresh its internal state and re-evaluate its plan.</p>
<h2 id="consequence-of-non-compliance">Consequence of Non-Compliance</h2>
<p>Upon detecting any form of non-compliance, the agent is required to:
1.  <strong>Halt:</strong> Immediately stop the current execution path to prevent further deviation.
2.  <strong>Report:</strong> Log the specific violation that was detected.
3.  <strong>Correct:</strong> Initiate the defined corrective action for the specific violation. If a corrective action is not explicitly defined, the agent should revert the violating changes and re-plan its approach.</p>
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;non-compliance-protocol-001&quot;,
  &quot;description&quot;: &quot;A protocol that defines non-compliance with AGENTS.md and specifies corrective actions.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;non-compliance-definition&quot;,
      &quot;description&quot;: &quot;Defines non-compliance as a violation of any rule, convention, or procedure in AGENTS.md or its source protocols.&quot;,
      &quot;enforcement&quot;: &quot;This is a definitional rule. Enforcement is achieved through the agent's adherence to the specific non-compliance rules that follow.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;non-compliance-direct-editing&quot;,
      &quot;description&quot;: &quot;Prohibits the direct editing of build artifacts like AGENTS.md or README.md. Changes must be made to source files, followed by a rebuild.&quot;,
      &quot;enforcement&quot;: &quot;Agent must revert direct edits and modify source files, then run the appropriate build command.&quot;,
      &quot;associated_tools&quot;: [
        &quot;restore_file&quot;,
        &quot;run_in_bash_session&quot;
      ]
    },
    {
      &quot;rule_id&quot;: &quot;non-compliance-test-procedure&quot;,
      &quot;description&quot;: &quot;Requires adherence to all documented testing procedures before submitting changes.&quot;,
      &quot;enforcement&quot;: &quot;Agent must halt execution and run the required tests, debugging any failures before proceeding.&quot;,
      &quot;associated_tools&quot;: [
        &quot;run_in_bash_session&quot;
      ]
    },
    {
      &quot;rule_id&quot;: &quot;non-compliance-architectural-deviation&quot;,
      &quot;description&quot;: &quot;Forbids changes that contradict documented architectural patterns or coding conventions.&quot;,
      &quot;enforcement&quot;: &quot;Agent must revert non-compliant changes and re-implement them according to standards.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;non-compliance-self-awareness-failure&quot;,
      &quot;description&quot;: &quot;Requires the agent to maintain an up-to-date understanding of protocols by recompiling AGENTS.md when necessary.&quot;,
      &quot;enforcement&quot;: &quot;Agent should run 'make AGENTS.md' to refresh its protocol knowledge and re-evaluate its plan.&quot;,
      &quot;associated_tools&quot;: [
        &quot;run_in_bash_session&quot;
      ]
    }
  ]
}
</code></pre>
<hr />
<h1 id="protocol-pre-commit-verification">Protocol: Pre-Commit Verification</h1>
<p>This protocol establishes the mandatory sequence of verification steps that must be performed before any code is submitted. Its purpose is to ensure that all changes meet a baseline level of quality, correctness, and review, preventing regressions and maintaining repository health.</p>
<h2 id="rule-mandatory-pre-commit-checks">Rule: Mandatory Pre-Commit Checks</h2>
<p>Before finalizing and submitting any work, the agent <strong>must</strong> execute the <code>pre_commit_instructions</code> tool. This tool acts as a procedural gateway, providing the specific, up-to-date checklist of actions required for validation. This typically includes:</p>
<ol>
<li><strong>Running all automated tests</strong> to verify correctness.</li>
<li><strong>Requesting a formal code review</strong> to get critical feedback.</li>
<li><strong>Recording key learnings</strong> to contribute to the agent's long-term memory.</li>
</ol>
<p>Adherence to this protocol is not optional. It is a fundamental step in the development lifecycle that safeguards the integrity of the codebase.</p>
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;pre-commit-protocol-001&quot;,
  &quot;description&quot;: &quot;Defines the mandatory pre-commit checks to ensure code quality, correctness, and readiness for submission.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;pre-commit-instructions-mandate&quot;,
      &quot;description&quot;: &quot;Before submitting changes, the agent MUST execute the `pre_commit_instructions` tool to receive the required sequence of validation steps (e.g., running tests, requesting code review).&quot;,
      &quot;enforcement&quot;: &quot;The agent's core logic should invoke this tool as the entry point to the pre-submission phase.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;pre_commit_instructions&quot;
  ]
}
</code></pre>
<hr />
<h1 id="protocol-authorization-for-destructive-tools">Protocol: Authorization for Destructive Tools</h1>
<h2 id="the-problem-unauthorized-use-of-destructive-tools">The Problem: Unauthorized Use of Destructive Tools</h2>
<p>A recent catastrophic failure demonstrated a critical flaw in the agent's protocol adherence. The agent invoked the <code>reset_all()</code> tool, a destructive operation, without explicit user authorization. This led to a complete workflow collapse, loss of work, and the inability to complete the assigned task. The agent's internal logic and planning capabilities are not yet robust enough to handle the consequences of such a powerful and state-destroying action without external guidance.</p>
<h2 id="the-solution-explicit-auditable-authorization">The Solution: Explicit, Auditable Authorization</h2>
<p>To prevent this class of failure, this protocol introduces a hard-coded safety interlock on the <code>reset_all</code> tool. The tool is now forbidden from executing unless it can verify the presence of a specific, short-lived authorization token file in the repository root.</p>
<ul>
<li><strong>Authorization Token:</strong> <code>authorization.token</code></li>
<li><strong>Procedure:</strong><ol>
<li>The agent MUST request permission from the user before using <code>reset_all</code>.</li>
<li>The user, if they approve, will create the <code>authorization.token</code> file.</li>
<li>The <code>reset_all</code> tool, upon execution, will check for this file. If present, it will execute and then immediately delete the token file to ensure the authorization is single-use. If the file is not present, the tool must refuse to execute and raise a critical error.</li>
</ol>
</li>
</ul>
<p>This mechanism transforms the authorization from a matter of agent discretion into a verifiable, machine-enforced protocol, ensuring that destructive operations are only ever performed with explicit, just-in-time human consent.</p>
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;reset-all-authorization-001&quot;,
  &quot;description&quot;: &quot;Requires explicit user authorization via a token file for the use of the destructive `reset_all` tool.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;require-authorization-token&quot;,
      &quot;description&quot;: &quot;The `reset_all` tool must not execute unless a file named `authorization.token` exists in the repository root.&quot;,
      &quot;enforcement&quot;: &quot;The `reset_all` tool's implementation must be modified to check for the existence of this file, proceed with its operation, and then delete the token file upon completion. If the file does not exist, the tool must raise an exception and terminate.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;reset_all&quot;
  ]
}
</code></pre>
<hr />
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;research-protocol-001&quot;,
  &quot;description&quot;: &quot;A protocol for conducting systematic research using the integrated research toolchain.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;mandate-research-tools&quot;,
      &quot;description&quot;: &quot;For all complex research tasks, the `plan_deep_research` tool MUST be used to generate a plan, and the `execute_research_protocol` tool MUST be used for data gathering. This ensures a systematic and auditable research process.&quot;,
      &quot;enforcement&quot;: &quot;Adherence is monitored by the Code Review Critic and through post-mortem analysis of the activity log.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;tooling.research_planner.plan_deep_research&quot;,
    &quot;tooling.research.execute_research_protocol&quot;
  ]
}
</code></pre>
<hr />
<h1 id="protocol-reset_all-prohibition">Protocol: <code>reset_all</code> Prohibition</h1>
<p><strong>ID:</strong> <code>reset-all-prohibition-001</code></p>
<h2 id="1-description">1. Description</h2>
<p>This protocol establishes a strict and unconditional prohibition on the use of the <code>reset_all</code> tool. This tool is considered a legacy, high-risk command that is no longer permitted in any workflow.</p>
<h2 id="2-rationale">2. Rationale</h2>
<p>The <code>reset_all</code> tool has been the cause of multiple catastrophic failures, leading to the complete loss of work and the inability to complete tasks. Its behavior is too destructive and unpredictable for a production environment. More granular and safer tools are available for workspace management. This protocol serves as a hard-coded safeguard to prevent any future use of this tool.</p>
<h2 id="3-rules">3. Rules</h2>
<h3 id="rule-no-reset-all">Rule <code>no-reset-all</code></h3>
<ul>
<li><strong>Description:</strong> The <code>reset_all</code> tool is strictly forbidden under all circumstances.</li>
<li><strong>Enforcement:</strong> The <code>master_control.py</code> orchestrator will programmatically block any attempt to call <code>reset_all</code> and will immediately terminate the task with a critical error. This is not a rule for the agent to interpret, but a hard-coded system constraint.</li>
</ul>
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;reset-all-prohibition-001&quot;,
  &quot;protocol_name&quot;: &quot;Prohibition of reset_all Tool&quot;,
  &quot;description&quot;: &quot;A high-priority protocol that unconditionally forbids the use of the `reset_all` tool.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;no-reset-all&quot;,
      &quot;description&quot;: &quot;The `reset_all` tool is strictly forbidden under all circumstances. It is a legacy tool that has been superseded by more granular and safer methods of workspace management. Its use is considered a critical failure.&quot;,
      &quot;enforcement&quot;: &quot;This rule is enforced by the `master_control.py` orchestrator, which will immediately terminate the workflow with an error if an attempt is made to call this tool.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;reset_all&quot;
  ]
}
</code></pre>
<hr />
<h1 id="system-documentation">System Documentation</h1>
<hr />
<h2 id="tooling-directory"><code>tooling/</code> Directory</h2>
<h3 id="tooling__init__py"><code>tooling/__init__.py</code></h3>
<p><em>No module-level docstring found.</em></p>
<h3 id="toolingcode_suggesterpy"><code>tooling/code_suggester.py</code></h3>
<p>Handles the generation and application of autonomous code change suggestions.</p>
<p>This tool is a key component of the advanced self-correction loop. It is
designed to be invoked by the self-correction orchestrator when a lesson
contains a 'propose-code-change' action.</p>
<p>For its initial implementation, this tool acts as a structured executor. It
takes a lesson where the 'details' field contains a fully-formed git-style
merge diff and applies it to the target file. It does this by generating a
temporary, single-step plan file and signaling its location for the master
controller to execute.</p>
<p>This establishes the fundamental workflow for autonomous code modification,
decoupling the suggestion logic from the execution logic. Future iterations
can enhance this tool with more sophisticated code generation capabilities
(e.g., using an LLM to generate the diff from a natural language description)
without altering the core orchestration process.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-generate_suggestion_planfilepath-diff_content"><code>def generate_suggestion_plan(filepath, diff_content)</code></h4>
</li>
</ul>
<blockquote>
<p>Generates a temporary, single-step plan file to apply a code change.</p>
<p>Args:
    filepath: The path to the file that needs to be modified.
    diff_content: The git-style merge diff block to be applied.</p>
<p>Returns:
    The path to the generated temporary plan file.</p>
</blockquote>
<ul>
<li>
<h4 id="def-main"><code>def main()</code></h4>
</li>
</ul>
<blockquote>
<p>Main entry point for the code suggester tool.
Parses arguments, generates a plan, and prints the plan's path to stdout.</p>
</blockquote>
<h3 id="toolingcontext_awareness_scannerpy"><code>tooling/context_awareness_scanner.py</code></h3>
<p><em>No module-level docstring found.</em></p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-find_referencessymbol_name-search_path"><code>def find_references(symbol_name, search_path)</code></h4>
</li>
</ul>
<blockquote>
<p>Finds all files in a directory that reference a given symbol.</p>
</blockquote>
<ul>
<li>
<h4 id="def-get_defined_symbolsfilepath"><code>def get_defined_symbols(filepath)</code></h4>
</li>
</ul>
<blockquote>
<p>Parses a Python file to find all defined functions and classes.</p>
</blockquote>
<ul>
<li>
<h4 id="def-get_imported_symbolsfilepath"><code>def get_imported_symbols(filepath)</code></h4>
</li>
</ul>
<blockquote>
<p>Parses a Python file to find all imported modules and symbols.</p>
</blockquote>
<ul>
<li>
<h4 id="def-main_1"><code>def main()</code></h4>
</li>
</ul>
<h3 id="toolingdependency_graph_generatorpy"><code>tooling/dependency_graph_generator.py</code></h3>
<p>Scans the repository for dependency files and generates a unified dependency graph.</p>
<p>This script is a crucial component of the agent's environmental awareness,
providing a clear map of the software supply chain. It recursively searches the
entire repository for common dependency management files, specifically:
- <code>package.json</code> (for JavaScript/Node.js projects)
- <code>requirements.txt</code> (for Python projects)</p>
<p>It parses these files to identify two key types of relationships:
1.  <strong>Internal Dependencies:</strong> Links between different projects within this repository.
2.  <strong>External Dependencies:</strong> Links to third-party libraries and packages.</p>
<p>The final output is a JSON file, <code>knowledge_core/dependency_graph.json</code>, which
represents these relationships as a graph structure with nodes (projects and
dependencies) and edges (the dependency links). This artifact is a primary
input for the agent's orientation and planning phases, allowing it to reason
about the potential impact of its changes.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-find_package_json_filesroot_dir"><code>def find_package_json_files(root_dir)</code></h4>
</li>
</ul>
<blockquote>
<p>Finds all package.json files in the repository, excluding node_modules.</p>
</blockquote>
<ul>
<li>
<h4 id="def-find_requirements_txt_filesroot_dir"><code>def find_requirements_txt_files(root_dir)</code></h4>
</li>
</ul>
<blockquote>
<p>Finds all requirements.txt files in the repository.</p>
</blockquote>
<ul>
<li>
<h4 id="def-generate_dependency_graphroot_dir"><code>def generate_dependency_graph(root_dir='.')</code></h4>
</li>
</ul>
<blockquote>
<p>Generates a dependency graph for all supported dependency files found.</p>
</blockquote>
<ul>
<li>
<h4 id="def-main_2"><code>def main()</code></h4>
</li>
</ul>
<blockquote>
<p>Main function to generate and save the dependency graph.</p>
</blockquote>
<ul>
<li>
<h4 id="def-parse_package_jsonpackage_json_path"><code>def parse_package_json(package_json_path)</code></h4>
</li>
</ul>
<blockquote>
<p>Parses a single package.json file to extract its name and dependencies.</p>
</blockquote>
<ul>
<li>
<h4 id="def-parse_requirements_txtrequirements_path-root_dir"><code>def parse_requirements_txt(requirements_path, root_dir)</code></h4>
</li>
</ul>
<blockquote>
<p>Parses a requirements.txt file to extract its dependencies.</p>
</blockquote>
<h3 id="toolingdoc_generatorpy"><code>tooling/doc_generator.py</code></h3>
<p>Generates detailed system documentation from Python source files.</p>
<p>This script scans specified directories for Python files, parses their
Abstract Syntax Trees (ASTs), and extracts documentation for the module,
classes, and functions. The output is a structured Markdown file.</p>
<p>This is a key component of the project's self-documentation capabilities,
powering the <code>SYSTEM_DOCUMENTATION.md</code> artifact in the <code>knowledge_core</code>.</p>
<p>The script is configured via top-level constants:
- <code>SCAN_DIRECTORIES</code>: A list of directories to search for .py files.
- <code>OUTPUT_FILE</code>: The path where the final Markdown file will be written.
- <code>DOC_TITLE</code>: The main title for the generated documentation file.</p>
<p>It uses Python's <code>ast</code> module to reliably parse source files without
importing them, which avoids issues with dependencies or script side-effects.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-find_python_filesdirectories"><code>def find_python_files(directories)</code></h4>
</li>
</ul>
<blockquote>
<p>Finds all Python files in the given directories, ignoring test files.</p>
</blockquote>
<ul>
<li>
<h4 id="def-format_argsargs"><code>def format_args(args)</code></h4>
</li>
</ul>
<blockquote>
<p>Formats ast.arguments into a printable string, including defaults.</p>
</blockquote>
<ul>
<li>
<h4 id="def-generate_documentationall_docs"><code>def generate_documentation(all_docs)</code></h4>
</li>
</ul>
<blockquote>
<p>Generates a single Markdown string from a list of ModuleDoc objects.</p>
</blockquote>
<ul>
<li>
<h4 id="def-generate_documentation_for_modulemod_doc"><code>def generate_documentation_for_module(mod_doc)</code></h4>
</li>
</ul>
<blockquote>
<p>Generates Markdown content for a single module.</p>
</blockquote>
<ul>
<li>
<h4 id="def-main_3"><code>def main()</code></h4>
</li>
</ul>
<blockquote>
<p>Main function to find files, parse them, and write documentation.</p>
</blockquote>
<ul>
<li>
<h4 id="def-parse_file_for_docsfilepath"><code>def parse_file_for_docs(filepath)</code></h4>
</li>
</ul>
<blockquote>
<p>Parses a Python file and extracts documentation for its module, classes,
and functions.</p>
</blockquote>
<p><strong>Public Classes:</strong></p>
<ul>
<li>
<h4 id="class-classdoc"><code>class ClassDoc</code></h4>
</li>
</ul>
<blockquote>
<p>Holds documentation for a single class.</p>
</blockquote>
<p><strong>Methods:</strong></p>
<ul>
<li>
<h5 id="def-__init__self-name-docstring-methods"><code>def __init__(self, name, docstring, methods)</code></h5>
</li>
<li>
<h4 id="class-docvisitor"><code>class DocVisitor</code></h4>
</li>
</ul>
<blockquote>
<p>AST visitor to extract documentation from classes and functions.
It navigates the tree and builds lists of discovered documentation objects.</p>
</blockquote>
<p><strong>Methods:</strong></p>
<ul>
<li>
<h5 id="def-__init__self"><code>def __init__(self)</code></h5>
</li>
<li>
<h5 id="def-visit_classdefself-node"><code>def visit_ClassDef(self, node)</code></h5>
</li>
<li>
<h5 id="def-visit_functiondefself-node"><code>def visit_FunctionDef(self, node)</code></h5>
</li>
<li>
<h4 id="class-functiondoc"><code>class FunctionDoc</code></h4>
</li>
</ul>
<blockquote>
<p>Holds documentation for a single function or method.</p>
</blockquote>
<p><strong>Methods:</strong></p>
<ul>
<li>
<h5 id="def-__init__self-name-signature-docstring"><code>def __init__(self, name, signature, docstring)</code></h5>
</li>
<li>
<h4 id="class-moduledoc"><code>class ModuleDoc</code></h4>
</li>
</ul>
<blockquote>
<p>Holds all documentation for a single Python module.</p>
</blockquote>
<p><strong>Methods:</strong></p>
<ul>
<li>
<h5 id="def-__init__self-name-docstring-classes-functions"><code>def __init__(self, name, docstring, classes, functions)</code></h5>
</li>
</ul>
<h3 id="toolingenvironmental_probepy"><code>tooling/environmental_probe.py</code></h3>
<p>Performs a series of checks to assess the capabilities of the execution environment.</p>
<p>This script is a critical diagnostic tool run at the beginning of a task to
ensure the agent understands its operational sandbox. It verifies fundamental
capabilities required for most software development tasks:</p>
<ol>
<li><strong>Filesystem I/O:</strong> Confirms that the agent can create, write to, read from,
    and delete files. It also provides a basic latency measurement for these
    operations.</li>
<li><strong>Network Connectivity:</strong> Checks for external network access by attempting to
    connect to a highly-available public endpoint (google.com). This is crucial
    for tasks requiring <code>git</code> operations, package downloads, or API calls.</li>
<li><strong>Environment Variables:</strong> Verifies that standard environment variables are
    accessible, which is a prerequisite for many command-line tools.</li>
</ol>
<p>The script generates a human-readable report summarizing the results of these
probes, allowing the agent to quickly identify any environmental constraints
that might impact its ability to complete a task.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-main_4"><code>def main()</code></h4>
</li>
</ul>
<blockquote>
<p>Runs all environmental probes and prints a summary report.</p>
</blockquote>
<ul>
<li>
<h4 id="def-probe_environment_variables"><code>def probe_environment_variables()</code></h4>
</li>
</ul>
<blockquote>
<p>Checks for the presence of a common environment variable.</p>
</blockquote>
<ul>
<li>
<h4 id="def-probe_filesystem"><code>def probe_filesystem()</code></h4>
</li>
</ul>
<blockquote>
<p>Tests file system write/read/delete capabilities and measures latency.</p>
</blockquote>
<ul>
<li>
<h4 id="def-probe_network"><code>def probe_network()</code></h4>
</li>
</ul>
<blockquote>
<p>Tests network connectivity and measures latency to a reliable external endpoint.</p>
</blockquote>
<h3 id="toolingfdc_clipy"><code>tooling/fdc_cli.py</code></h3>
<p>Provides the command-line interface for the Finite Development Cycle (FDC).</p>
<p>This script is a core component of the agent's protocol, offering tools to ensure
that all development work is structured, verifiable, and safe. It is used by both
the agent to signal progress and the <code>master_control.py</code> orchestrator to
validate the agent's plans before execution.</p>
<p>The CLI provides several key commands:
- <code>close</code>: Logs the formal end of a task, signaling to the orchestrator that
  execution is complete.
- <code>validate</code>: Performs a deep validation of a plan file against the FDC's Finite
  State Machine (FSM) definition. It checks for both syntactic correctness (Is
  the sequence of operations valid?) and semantic correctness (Does the plan try
  to use a file before creating it?).
- <code>analyze</code>: Reads a plan and provides a high-level analysis of its
  characteristics, such as its computational complexity and whether it is a
  read-only or read-write plan.
- <code>lint</code>: A comprehensive "linter" that runs a full suite of checks on a plan
  file, including <code>validate</code>, <code>analyze</code>, and checks for disallowed recursion.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-analyze_planplan_filepath"><code>def analyze_plan(plan_filepath)</code></h4>
</li>
</ul>
<blockquote>
<p>Analyzes a plan file to determine its complexity class and modality.</p>
</blockquote>
<ul>
<li>
<h4 id="def-close_tasktask_id"><code>def close_task(task_id)</code></h4>
</li>
</ul>
<blockquote>
<p>Logs the formal end of a task.</p>
<p>This command's primary role is to create a TASK_END log entry. It no longer
manages the post-mortem file directly; that process is now fully owned by
the MasterControlGraph orchestrator, which is the single source of truth
for state transitions and artifact lifecycle management.</p>
</blockquote>
<ul>
<li>
<h4 id="def-lint_planplan_filepath"><code>def lint_plan(plan_filepath)</code></h4>
</li>
</ul>
<blockquote>
<p>Runs a comprehensive suite of checks on a plan file.
The old recursion check is now obsolete, as the max depth is checked
directly within the new hierarchical validator.</p>
</blockquote>
<ul>
<li>
<h4 id="def-main_5"><code>def main()</code></h4>
</li>
<li>
<h4 id="def-start_tasktask_id"><code>def start_task(task_id)</code></h4>
</li>
</ul>
<blockquote>
<p>Logs the formal start of a task.</p>
</blockquote>
<ul>
<li>
<h4 id="def-start_tasktask_id_1"><code>def start_task(task_id)</code></h4>
</li>
</ul>
<blockquote>
<p>Initiates the AORP cascade for a new task.</p>
</blockquote>
<ul>
<li>
<h4 id="def-validate_planplan_filepath"><code>def validate_plan(plan_filepath)</code></h4>
</li>
</ul>
<blockquote>
<p>Validates a plan using the centralized parser.</p>
</blockquote>
<h3 id="toolingknowledge_compilerpy"><code>tooling/knowledge_compiler.py</code></h3>
<p>Extracts structured lessons from post-mortem reports and compiles them into a
centralized, long-term knowledge base.</p>
<p>This script is a core component of the agent's self-improvement feedback loop.
After a task is completed, a post-mortem report is generated that includes a
section for "Corrective Actions &amp; Lessons Learned." This script automates the
process of parsing that section to extract key insights.</p>
<p>It identifies pairs of "Lesson" and "Action" statements and transforms them
into a standardized, machine-readable format. These formatted entries are then
appended to the <code>knowledge_core/lessons.jsonl</code> file, which serves as the
agent's persistent memory of what has worked, what has failed, and what can be
improved in future tasks.</p>
<p>The script is executed via the command line, taking the path to a completed
post-mortem file as its primary argument.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-extract_lessons_from_postmortempostmortem_content"><code>def extract_lessons_from_postmortem(postmortem_content)</code></h4>
</li>
</ul>
<blockquote>
<p>Parses a post-mortem report to extract lessons learned.
Handles multiple possible section headers and formats.</p>
</blockquote>
<ul>
<li>
<h4 id="def-extract_metadata_from_postmortempostmortem_content"><code>def extract_metadata_from_postmortem(postmortem_content)</code></h4>
</li>
</ul>
<blockquote>
<p>Parses a post-mortem report to extract metadata like Task ID and Date.</p>
</blockquote>
<ul>
<li>
<h4 id="def-format_lesson_entrymetadata-lesson_data"><code>def format_lesson_entry(metadata, lesson_data)</code></h4>
</li>
</ul>
<blockquote>
<p>Formats an extracted lesson into a structured JSON object.</p>
</blockquote>
<ul>
<li>
<h4 id="def-main_6"><code>def main()</code></h4>
</li>
<li>
<h4 id="def-parse_action_to_commandaction_text"><code>def parse_action_to_command(action_text)</code></h4>
</li>
</ul>
<blockquote>
<p>Parses a natural language action string into a machine-executable command.</p>
<p>This is the core of translating insights into automated actions. It uses
pattern matching to identify specific, supported commands.</p>
</blockquote>
<h3 id="toolingknowledge_integratorpy"><code>tooling/knowledge_integrator.py</code></h3>
<p>Enriches the local knowledge graph with data from external sources like DBPedia.</p>
<p>This script loads the RDF graph generated from the project's protocols,
identifies key concepts (like tools and rules), queries the DBPedia SPARQL
endpoint to find related information, and merges the external data into a new,
enriched knowledge graph.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-extract_conceptsgraph"><code>def extract_concepts(graph)</code></h4>
</li>
</ul>
<blockquote>
<p>Extracts key concepts (e.g., tools) from the local graph to query externally.
This version dynamically extracts tool names from the graph.</p>
</blockquote>
<ul>
<li>
<h4 id="def-load_local_graphgraph_file"><code>def load_local_graph(graph_file)</code></h4>
</li>
</ul>
<blockquote>
<p>Loads the local RDF graph from a file.</p>
</blockquote>
<ul>
<li>
<h4 id="def-query_dbpediaconcept"><code>def query_dbpedia(concept)</code></h4>
</li>
</ul>
<blockquote>
<p>Queries DBPedia for a given concept and returns a graph of results.</p>
</blockquote>
<ul>
<li>
<h4 id="def-run_knowledge_integrationinput_graph_path-output_graph_path"><code>def run_knowledge_integration(input_graph_path, output_graph_path)</code></h4>
</li>
</ul>
<blockquote>
<p>The main library function to run the knowledge integration process.
It loads a graph, extracts concepts, queries DBPedia, and saves the
enriched graph.</p>
</blockquote>
<h3 id="toolinglog_failurepy"><code>tooling/log_failure.py</code></h3>
<p><em>No module-level docstring found.</em></p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-log_catastrophic_failure"><code>def log_catastrophic_failure()</code></h4>
</li>
</ul>
<blockquote>
<p>Logs the catastrophic failure event.</p>
</blockquote>
<h3 id="toolingmaster_controlpy"><code>tooling/master_control.py</code></h3>
<p>The master orchestrator for the agent's lifecycle, governed by a Finite State Machine.</p>
<p>This script, <code>master_control.py</code>, is the heart of the agent's operational loop.
It implements a strict, protocol-driven workflow defined in a JSON file
(typically <code>tooling/fsm.json</code>). The <code>MasterControlGraph</code> class reads this FSM
definition and steps through the prescribed states, ensuring that the agent
cannot deviate from the established protocol.</p>
<p>The key responsibilities of this orchestrator include:
- <strong>State Enforcement:</strong> Guiding the agent through the formal states of a task:
  ORIENTING, PLANNING, EXECUTING, FINALIZING, and finally AWAITING_SUBMISSION.
- <strong>Plan Validation:</strong> Before execution, it invokes the <code>fdc_cli.py</code> tool to
  formally validate the agent-generated <code>plan.txt</code>, preventing the execution of
  invalid or unsafe plans.
- <strong>Hierarchical Execution (CFDC):</strong> It manages the plan execution stack, which
  is the core mechanism of the Context-Free Development Cycle (CFDC). This
  allows plans to call other plans as sub-routines via the <code>call_plan</code>
  directive.
- <strong>Recursion Safety:</strong> It enforces a <code>MAX_RECURSION_DEPTH</code> on the plan stack to
  guarantee that the execution process is always decidable and will terminate.
- <strong>Lifecycle Management:</strong> It orchestrates the entire lifecycle, from initial
  orientation and environmental probing to the final post-mortem analysis and
  compilation of lessons learned.</p>
<p>The FSM operates by waiting for specific signals—typically the presence of
files like <code>plan.txt</code> or <code>step_complete.txt</code>—before transitioning to the next
state. This creates a robust, interactive loop where the orchestrator directs
the high-level state, and the agent is responsible for completing the work
required to advance that state.</p>
<p><strong>Public Classes:</strong></p>
<ul>
<li>
<h4 id="class-mastercontrolgraph"><code>class MasterControlGraph</code></h4>
</li>
</ul>
<blockquote>
<p>A Finite State Machine (FSM) that enforces the agent's protocol.
This graph reads a state definition and orchestrates the agent's workflow,
ensuring that all protocol steps are followed in the correct order.</p>
</blockquote>
<p><strong>Methods:</strong></p>
<ul>
<li>
<h5 id="def-__init__self-fsm_pathtoolingfsmjson"><code>def __init__(self, fsm_path='tooling/fsm.json')</code></h5>
</li>
<li>
<h5 id="def-do_executionself-agent_state"><code>def do_execution(self, agent_state)</code></h5>
<blockquote>
<p>Executes the plan using a stack-based approach to handle sub-plans (CFDC).</p>
</blockquote>
</li>
<li>
<h5 id="def-do_finalizingself-agent_state"><code>def do_finalizing(self, agent_state)</code></h5>
<blockquote>
<p>Handles the finalization of the task, including post-mortem analysis and self-correction.</p>
</blockquote>
</li>
<li>
<h5 id="def-do_orientationself-agent_state"><code>def do_orientation(self, agent_state)</code></h5>
<blockquote>
<p>Executes the L1, L2, and L3 orientation steps.</p>
</blockquote>
</li>
<li>
<h5 id="def-do_planningself-agent_state"><code>def do_planning(self, agent_state)</code></h5>
<blockquote>
<p>Waits for the agent to provide a plan, validates it, parses it into
commands, and initializes the plan stack for execution.</p>
</blockquote>
</li>
<li>
<h5 id="def-do_researchingself-agent_state"><code>def do_researching(self, agent_state)</code></h5>
<blockquote>
<p>Generates, validates, and initiates a formal Deep Research FDC.</p>
</blockquote>
</li>
<li>
<h5 id="def-get_triggerself-source_state-dest_state"><code>def get_trigger(self, source_state, dest_state)</code></h5>
<blockquote>
<p>Finds a trigger in the FSM definition for a transition from a source
to a destination state. This is a helper to avoid hardcoding trigger
strings in the state handlers.</p>
</blockquote>
</li>
<li>
<h5 id="def-runself-initial_agent_state"><code>def run(self, initial_agent_state)</code></h5>
<blockquote>
<p>Runs the agent's workflow through the FSM.</p>
</blockquote>
</li>
</ul>
<h3 id="toolingmaster_control_clipy"><code>tooling/master_control_cli.py</code></h3>
<p>The official command-line interface for the agent's master control loop.</p>
<p>This script provides a clean entry point for initiating a task. It handles
argument parsing, initializes the agent's state, and runs the main FSM-driven
workflow defined in <code>master_control.py</code>.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-main_7"><code>def main()</code></h4>
</li>
</ul>
<blockquote>
<p>The main entry point for the agent.</p>
<p>This script initializes the agent's state, runs the master control graph
to enforce the protocol, and prints the final result.</p>
</blockquote>
<h3 id="toolingpages_generatorpy"><code>tooling/pages_generator.py</code></h3>
<p>Generates a single HTML file for GitHub Pages from the repository's metalanguage.</p>
<p>This script combines the human-readable <code>README.md</code> and the machine-readable
<code>AGENTS.md</code> into a single, navigable HTML document. It uses the <code>markdown</code>
library to convert the Markdown content to HTML and to automatically generate
a Table of Contents.</p>
<p>The final output is a semantic HTML5 document, <code>index.html</code>, which serves as
the main page for the project's GitHub Pages site.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-generate_html_page"><code>def generate_html_page()</code></h4>
</li>
</ul>
<blockquote>
<p>Reads the source Markdown files, converts them to HTML, and builds the
final index.html page.</p>
</blockquote>
<h3 id="toolingplan_managerpy"><code>tooling/plan_manager.py</code></h3>
<p>Provides a command-line interface for managing the agent's Plan Registry.</p>
<p>This script is the administrative tool for the Plan Registry, a key component
of the Context-Free Development Cycle (CFDC) that enables hierarchical and
modular planning. The registry, located at <code>knowledge_core/plan_registry.json</code>,
maps human-readable, logical names to the file paths of specific plans. This
decouples the <code>call_plan</code> directive from hardcoded file paths, making plans
more reusable and the system more robust.</p>
<p>This CLI provides three essential functions:
- <strong>register</strong>: Associates a new logical name with a plan file path, adding it
  to the central registry.
- <strong>deregister</strong>: Removes an existing logical name and its associated path from
  the registry.
- <strong>list</strong>: Displays all current name-to-path mappings in the registry.</p>
<p>By providing a simple, standardized interface for managing this library of
reusable plans, this tool improves the agent's ability to compose complex
workflows from smaller, validated sub-plans.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-deregister_planname"><code>def deregister_plan(name)</code></h4>
</li>
</ul>
<blockquote>
<p>Removes a plan from the registry by its logical name.</p>
</blockquote>
<ul>
<li>
<h4 id="def-get_registry"><code>def get_registry()</code></h4>
</li>
</ul>
<blockquote>
<p>Loads the plan registry from its JSON file.</p>
</blockquote>
<ul>
<li>
<h4 id="def-list_plans"><code>def list_plans()</code></h4>
</li>
</ul>
<blockquote>
<p>Lists all currently registered plans.</p>
</blockquote>
<ul>
<li>
<h4 id="def-main_8"><code>def main()</code></h4>
</li>
</ul>
<blockquote>
<p>Main function to run the plan management CLI.</p>
</blockquote>
<ul>
<li>
<h4 id="def-register_planname-path"><code>def register_plan(name, path)</code></h4>
</li>
</ul>
<blockquote>
<p>Registers a new plan by mapping a logical name to a file path.</p>
</blockquote>
<ul>
<li>
<h4 id="def-save_registryregistry_data"><code>def save_registry(registry_data)</code></h4>
</li>
</ul>
<blockquote>
<p>Saves the given data to the plan registry JSON file.</p>
</blockquote>
<h3 id="toolingplan_parserpy"><code>tooling/plan_parser.py</code></h3>
<p>Parses a plan file into a structured list of commands.</p>
<p>This module provides the <code>parse_plan</code> function and the <code>Command</code> dataclass,
which are central to the agent's ability to understand and execute plans.
The parser correctly handles multi-line arguments and ignores comments,
allowing for robust and readable plan files.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-parse_planplan_content"><code>def parse_plan(plan_content)</code></h4>
</li>
</ul>
<blockquote>
<p>Parses the raw text of a plan into a list of Command objects.
This parser correctly handles multi-line arguments and ignores comments.
Commands are expected to be separated by one or more blank lines.</p>
</blockquote>
<p><strong>Public Classes:</strong></p>
<ul>
<li>
<h4 id="class-command"><code>class Command</code></h4>
</li>
</ul>
<blockquote>
<p>Represents a single, parsed command from a plan.
This structure correctly handles multi-line arguments for tools.</p>
</blockquote>
<h3 id="toolingprotocol_auditorpy"><code>tooling/protocol_auditor.py</code></h3>
<p>Audits the agent's behavior against its governing protocols and generates a report.</p>
<p>This script performs a comprehensive analysis to ensure the agent's actions,
as recorded in the activity log, align with the defined protocols in AGENTS.md.
It serves as a critical feedback mechanism for maintaining operational integrity.
The final output is a detailed <code>audit_report.md</code> file.</p>
<p>The auditor performs three main checks:
1.  <strong><code>AGENTS.md</code> Source Check:</strong> Verifies if the <code>AGENTS.md</code> build artifact is
    potentially stale by comparing its modification time against the source
    protocol files in the <code>protocols/</code> directory.
2.  <strong>Protocol Completeness:</strong> It cross-references the tools used in the log
    (<code>logs/activity.log.jsonl</code>) against the tools defined in <code>AGENTS.md</code> to find:
    - Tools used but not associated with any formal protocol.
    - Tools defined in protocols but never used in the log.
3.  <strong>Tool Centrality:</strong> It conducts a frequency analysis of tool usage to
    identify which tools are most critical to the agent's workflow.</p>
<p>The script parses all embedded JSON protocol blocks within <code>AGENTS.md</code> and reads
from the standard <code>logs/activity.log.jsonl</code> log file, providing a reliable and
accurate audit.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-generate_markdown_reportsource_check-unreferenced-unused-centrality"><code>def generate_markdown_report(source_check, unreferenced, unused, centrality)</code></h4>
</li>
</ul>
<blockquote>
<p>Generates a Markdown-formatted string from the audit results.</p>
</blockquote>
<ul>
<li>
<h4 id="def-get_protocol_tools_from_agents_mdagents_md_path"><code>def get_protocol_tools_from_agents_md(agents_md_path)</code></h4>
</li>
</ul>
<blockquote>
<p>Parses AGENTS.md to get a set of all tools associated with protocols.
NOTE: This function correctly parses all JSON blocks, contrary to the
outdated warning in the module-level docstring.</p>
</blockquote>
<ul>
<li>
<h4 id="def-get_used_tools_from_loglog_path"><code>def get_used_tools_from_log(log_path)</code></h4>
</li>
</ul>
<blockquote>
<p>Parses the JSONL log file to get a list of used tool names.
It specifically looks for 'TOOL_EXEC' actions and extracts the tool
from the 'command' field based on the logging schema.
This version is robust against malformed lines with multiple JSON objects.</p>
</blockquote>
<ul>
<li>
<h4 id="def-main_9"><code>def main()</code></h4>
</li>
</ul>
<blockquote>
<p>Main function to run the protocol auditor and generate a report.</p>
</blockquote>
<ul>
<li>
<h4 id="def-run_centrality_analysisused_tools"><code>def run_centrality_analysis(used_tools)</code></h4>
</li>
</ul>
<blockquote>
<p>Performs a frequency analysis on the tool log and returns the counts.</p>
</blockquote>
<ul>
<li>
<h4 id="def-run_completeness_checkused_tools-protocol_tools"><code>def run_completeness_check(used_tools, protocol_tools)</code></h4>
</li>
</ul>
<blockquote>
<p>Compares used tools with protocol-defined tools and returns the gaps.</p>
</blockquote>
<ul>
<li>
<h4 id="def-run_protocol_source_check"><code>def run_protocol_source_check()</code></h4>
</li>
</ul>
<blockquote>
<p>Checks if AGENTS.md is older than its source files.
Returns a dictionary with the check's status and relevant details.</p>
</blockquote>
<h3 id="toolingprotocol_compilerpy"><code>tooling/protocol_compiler.py</code></h3>
<p>Compiles source protocol files into unified, human-readable and machine-readable artifacts.</p>
<p>This script is the engine behind the "protocol as code" principle. It discovers,
validates, and assembles protocol definitions from a source directory (e.g., <code>protocols/</code>)
into high-level documents like <code>AGENTS.md</code>.</p>
<p>Key Functions:
- <strong>Discovery:</strong> Scans a directory for source files, including <code>.protocol.json</code>
  (machine-readable rules) and <code>.protocol.md</code> (human-readable context).
- <strong>Validation:</strong> Uses a JSON schema (<code>protocol.schema.json</code>) to validate every
  <code>.protocol.json</code> file, ensuring all protocol definitions are syntactically
  correct and adhere to the established structure.
- <strong>Compilation:</strong> Combines the human-readable markdown and the machine-readable
  JSON into a single, cohesive Markdown file, embedding the JSON in code blocks.
- <strong>Documentation Injection:</strong> Can inject other generated documents, like the
  <code>SYSTEM_DOCUMENTATION.md</code>, into the final output at specified locations.
- <strong>Knowledge Graph Generation:</strong> Optionally, it can process the validated JSON
  protocols and serialize them into an RDF knowledge graph (in Turtle format),
  creating a machine-queryable version of the agent's governing rules.</p>
<p>This process ensures that <code>AGENTS.md</code> and other protocol documents are not edited
manually but are instead generated from a validated, single source of truth,
making the agent's protocols robust, verifiable, and maintainable.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-compile_protocolssource_dir-target_file-schema_file-knowledge_graph_filenone-autodoc_filenone"><code>def compile_protocols(source_dir, target_file, schema_file, knowledge_graph_file=None, autodoc_file=None)</code></h4>
</li>
</ul>
<blockquote>
<p>Reads all .protocol.json and corresponding .protocol.md files from the
source directory, validates them, and compiles them into a target markdown file.
Optionally, it can also generate a machine-readable knowledge graph.</p>
</blockquote>
<ul>
<li>
<h4 id="def-load_schemaschema_file"><code>def load_schema(schema_file)</code></h4>
</li>
</ul>
<blockquote>
<p>Loads the protocol JSON schema.</p>
</blockquote>
<ul>
<li>
<h4 id="def-main_10"><code>def main()</code></h4>
</li>
</ul>
<blockquote>
<p>Main function to run the compiler.</p>
</blockquote>
<h3 id="toolingprotocol_updaterpy"><code>tooling/protocol_updater.py</code></h3>
<p>A command-line tool for programmatically updating protocol source files.</p>
<p>This script provides the mechanism for the agent to perform self-correction
by modifying its own governing protocols based on structured, actionable
lessons. It is a key component of the Protocol-Driven Self-Correction (PDSC)
workflow.</p>
<p>The tool operates on the .protocol.json files located in the <code>protocols/</code>
directory, performing targeted updates based on command-line arguments.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-add_tool_to_protocolprotocol_id-tool_name-protocols_dir"><code>def add_tool_to_protocol(protocol_id, tool_name, protocols_dir)</code></h4>
</li>
</ul>
<blockquote>
<p>Adds a tool to the 'associated_tools' list of a specified protocol.</p>
</blockquote>
<ul>
<li>
<h4 id="def-find_protocol_fileprotocol_id-protocols_dir"><code>def find_protocol_file(protocol_id, protocols_dir)</code></h4>
</li>
</ul>
<blockquote>
<p>Finds the protocol file path corresponding to a given protocol_id.</p>
</blockquote>
<ul>
<li>
<h4 id="def-main_11"><code>def main()</code></h4>
</li>
</ul>
<blockquote>
<p>Main function to parse arguments and call the appropriate handler.</p>
</blockquote>
<ul>
<li>
<h4 id="def-update_rule_in_protocolprotocol_id-rule_id-new_description-protocols_dir"><code>def update_rule_in_protocol(protocol_id, rule_id, new_description, protocols_dir)</code></h4>
</li>
</ul>
<blockquote>
<p>Updates the description of a specific rule within a protocol.</p>
</blockquote>
<h3 id="toolingreadme_generatorpy"><code>tooling/readme_generator.py</code></h3>
<p>Generates the project's README.md file.</p>
<p>This script combines a static, manually written overview with dynamically
generated sections that summarize key components of the system. The goal is
to produce a README that is both informative and easy to maintain, as it
automatically reflects the current state of the documented source code.</p>
<p>The script is designed to be run from the root of the repository and is
integrated into the <code>Makefile</code> build process.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-generate_core_protocols_section"><code>def generate_core_protocols_section()</code></h4>
</li>
</ul>
<blockquote>
<p>Parses AGENTS.md to extract protocol definitions and generate a Markdown summary.</p>
</blockquote>
<ul>
<li>
<h4 id="def-generate_key_components_section"><code>def generate_key_components_section()</code></h4>
</li>
</ul>
<blockquote>
<p>Generates the Markdown for the "Key Components" section by reading
the docstrings of the curated list of files.</p>
</blockquote>
<ul>
<li>
<h4 id="def-get_module_docstringfilepath"><code>def get_module_docstring(filepath)</code></h4>
</li>
</ul>
<blockquote>
<p>Parses a Python file and extracts the module-level docstring.</p>
<p>Args:
    filepath: The path to the Python file.</p>
<p>Returns:
    The module docstring, or a placeholder if none is found.</p>
</blockquote>
<ul>
<li>
<h4 id="def-main_12"><code>def main()</code></h4>
</li>
</ul>
<blockquote>
<p>Main function to generate the README.md content and write it to a file.</p>
</blockquote>
<h3 id="toolingresearchpy"><code>tooling/research.py</code></h3>
<p>A unified, constraint-based interface for all research and data-gathering operations.</p>
<p>This script abstracts the various methods an agent might use to gather information
(reading local files, accessing the web, querying a database) into a single,
standardized function: <code>execute_research_protocol</code>. It is a core component of
the Advanced Orientation and Research Protocol (AORP), providing the mechanism
by which the agent fulfills the requirements of each orientation level (L1-L4).</p>
<p>The function operates on a <code>constraints</code> dictionary, which specifies the target,
scope, and other parameters of the research task. This design allows the calling
orchestrator (e.g., <code>master_control.py</code>) to request information without needing
to know the underlying implementation details of how that information is fetched.</p>
<p>This script is designed to be executed by a system that has pre-loaded the
following native tools into the execution environment:
- <code>read_file(filepath: str) -&gt; str</code>
- <code>list_files(path: str = ".") -&gt; list[str]</code>
- <code>google_search(query: str) -&gt; str</code>
- <code>view_text_website(url: str) -&gt; str</code></p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-execute_research_protocolconstraints"><code>def execute_research_protocol(constraints)</code></h4>
</li>
</ul>
<blockquote>
<p>Executes a research task based on a dictionary of constraints.</p>
<p>This function delegates to native, pre-loaded tools based on the specified
target and scope.</p>
<p>Args:
    constraints: A dictionary specifying the operational parameters.
        - target: 'local_filesystem', 'external_web', 'external_repository', or 'knowledge_graph'.
        - scope: 'file', 'directory', 'narrow', 'broad', or 'enrich'.
        - path: The file or directory path for local filesystem operations.
        - query: The search term for web research.
        - url: The specific URL for direct web access.
        - input_graph_path: Path to the source knowledge graph.
        - output_graph_path: Path to save the enriched knowledge graph.</p>
<p>Returns:
    A string containing the result of the research operation.</p>
</blockquote>
<h3 id="toolingresearch_plannerpy"><code>tooling/research_planner.py</code></h3>
<p>Generates a structured, executable plan for conducting deep research tasks.</p>
<p>This script provides a standardized, FSM-compliant workflow for the agent when
it needs to perform in-depth research on a complex topic. The <code>plan_deep_research</code>
function creates a plan file that is not just a template, but a formal,
verifiable artifact that can be executed by the <code>master_control.py</code> orchestrator.</p>
<p>The generated plan adheres to the state transitions defined in <code>research_fsm.json</code>,
guiding the agent through the phases of GATHERING, SYNTHESIZING, and REPORTING.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-plan_deep_researchtopic"><code>def plan_deep_research(topic)</code></h4>
</li>
</ul>
<blockquote>
<p>Generates a structured, FSM-compliant executable plan for deep research.</p>
<p>This function creates a plan that guides an agent through a research
workflow. The plan is designed to be validated by <code>fdc_cli.py</code> against
the <code>tooling/research_fsm.json</code> definition.</p>
<p>Args:
    topic: The research topic to be investigated.</p>
<p>Returns:
    A string containing the executable research plan.</p>
</blockquote>
<h3 id="toolingself_correction_orchestratorpy"><code>tooling/self_correction_orchestrator.py</code></h3>
<p>Orchestrates the Protocol-Driven Self-Correction (PDSC) workflow.</p>
<p>This script is the engine of the automated feedback loop. It reads structured,
actionable lessons from <code>knowledge_core/lessons.jsonl</code> and uses the
<code>protocol_updater.py</code> tool to apply them to the source protocol files.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-load_lessons"><code>def load_lessons()</code></h4>
</li>
</ul>
<blockquote>
<p>Loads all lessons from the JSONL file.</p>
</blockquote>
<ul>
<li>
<h4 id="def-main_13"><code>def main()</code></h4>
</li>
</ul>
<blockquote>
<p>Main function to run the self-correction workflow.</p>
</blockquote>
<ul>
<li>
<h4 id="def-process_lessonslessons-protocols_dir"><code>def process_lessons(lessons, protocols_dir)</code></h4>
</li>
</ul>
<blockquote>
<p>Processes all pending lessons, applies them, and updates their status.
Returns True if any changes were made, False otherwise.</p>
</blockquote>
<ul>
<li>
<h4 id="def-run_commandcommand"><code>def run_command(command)</code></h4>
</li>
</ul>
<blockquote>
<p>Runs a command and returns True on success, False on failure.</p>
</blockquote>
<ul>
<li>
<h4 id="def-save_lessonslessons"><code>def save_lessons(lessons)</code></h4>
</li>
</ul>
<blockquote>
<p>Saves a list of lessons back to the JSONL file, overwriting it.</p>
</blockquote>
<h3 id="toolingself_improvement_clipy"><code>tooling/self_improvement_cli.py</code></h3>
<p>Analyzes agent activity logs to identify opportunities for self-improvement.</p>
<p>This script is a command-line tool that serves as a key part of the agent's
meta-cognitive loop. It parses the structured activity log
(<code>logs/activity.log.jsonl</code>) to identify patterns that may indicate
inefficiencies or errors in the agent's workflow.</p>
<p>The primary analysis currently implemented is:
- <strong>Planning Efficiency Analysis:</strong> It scans the logs for tasks that required
  multiple <code>set_plan</code> actions. A high number of plan revisions for a single
  task can suggest that the initial planning phase was insufficient, the task
  was poorly understood, or the agent struggled to adapt to unforeseen
  challenges.</p>
<p>By flagging these tasks, the script provides a starting point for a deeper
post-mortem analysis, helping the agent (or its developers) to understand the
root causes of the planning churn and to develop strategies for more effective
upfront planning in the future.</p>
<p>The tool is designed to be extensible, with future analyses (such as error
rate tracking or tool usage anti-patterns) to be added as the system evolves.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-analyze_planning_efficiencylog_file"><code>def analyze_planning_efficiency(log_file)</code></h4>
</li>
</ul>
<blockquote>
<p>Analyzes the log file to find tasks with multiple plan revisions.</p>
<p>Args:
    log_file (str): Path to the activity log file.</p>
<p>Returns:
    dict: A dictionary mapping task IDs to the number of plan updates.</p>
</blockquote>
<ul>
<li>
<h4 id="def-analyze_protocol_violationslog_file"><code>def analyze_protocol_violations(log_file)</code></h4>
</li>
</ul>
<blockquote>
<p>Scans the log file for critical protocol violations, such as the
unauthorized use of <code>reset_all</code>.</p>
<p>This function checks for two conditions:
1. A <code>SYSTEM_FAILURE</code> log explicitly blaming <code>reset_all</code>.
2. A <code>TOOL_EXEC</code> log where the command contains "reset_all".</p>
<p>Args:
    log_file (str): Path to the activity log file.</p>
<p>Returns:
    list: A list of unique task IDs where <code>reset_all</code> was used.</p>
</blockquote>
<ul>
<li>
<h4 id="def-main_14"><code>def main()</code></h4>
</li>
</ul>
<blockquote>
<p>Main function to run the self-improvement analysis CLI.</p>
</blockquote>
<h3 id="toolingstatepy"><code>tooling/state.py</code></h3>
<p>Defines the core data structures for managing the agent's state.</p>
<p>This module provides the <code>AgentState</code> and <code>PlanContext</code> dataclasses, which are
fundamental to the operation of the Context-Free Development Cycle (CFDC). These
structures allow the <code>master_control.py</code> orchestrator to maintain a complete,
snapshot-able representation of the agent's progress through a task.</p>
<ul>
<li><code>AgentState</code>: The primary container for all information related to the current
  task, including the plan execution stack, message history, and error states.</li>
<li><code>PlanContext</code>: A specific structure that holds the state of a single plan
  file, including its content and the current execution step. This is the
  element that gets pushed onto the <code>plan_stack</code> in <code>AgentState</code>.</li>
</ul>
<p>Together, these classes enable the hierarchical, stack-based planning and
execution that is the hallmark of the CFDC.</p>
<p><strong>Public Classes:</strong></p>
<ul>
<li>
<h4 id="class-agentstate"><code>class AgentState</code></h4>
</li>
</ul>
<blockquote>
<p>Represents the complete, serializable state of the agent's workflow.</p>
<p>This dataclass acts as a central container for all information related to the
agent's current task. It is designed to be passed between the different states
of the <code>MasterControlGraph</code> FSM, ensuring that context is maintained
throughout the lifecycle of a task.</p>
<p>Attributes:
    task: A string describing the overall objective.
    plan_path: The file path to the root plan for the current task.
    plan_stack: A list of <code>PlanContext</code> objects, forming the execution
        stack for the CFDC. The plan at the top of the stack is the one
        currently being executed.
    messages: A history of messages, typically for interaction with an LLM.
    orientation_complete: A flag indicating if the initial orientation
        phase has been successfully completed.
    vm_capability_report: A string summarizing the results of the
        environmental probe.
    research_findings: A dictionary to store the results of research tasks.
    draft_postmortem_path: The file path to the draft post-mortem report
        generated during the AWAITING_ANALYSIS state.
    final_report: A string containing a summary of the final, completed
        post-mortem report.
    error: An optional string that holds an error message if the FSM
        enters an error state, providing a clear reason for the failure.</p>
</blockquote>
<p><strong>Methods:</strong></p>
<ul>
<li>
<h5 id="def-to_jsonself"><code>def to_json(self)</code></h5>
</li>
<li>
<h4 id="class-plancontext"><code>class PlanContext</code></h4>
</li>
</ul>
<blockquote>
<p>Represents the execution context of a single plan file within the plan stack.</p>
<p>This class holds the state of a specific plan being executed, including its
file path, its content (as a list of parsed Command objects), and a pointer
to the current step being executed.</p>
</blockquote>
<h3 id="toolingsymbol_map_generatorpy"><code>tooling/symbol_map_generator.py</code></h3>
<p>Generates a code symbol map for the repository to aid in contextual understanding.</p>
<p>This script creates a <code>symbols.json</code> file in the <code>knowledge_core</code> directory,
which acts as a high-level index of the codebase. This map contains information
about key programming constructs like classes and functions, including their
name, location (file path and line number), and language.</p>
<p>The script employs a two-tiered approach for symbol generation:
1.  <strong>Universal Ctags (Preferred):</strong> It first checks for the presence of the
    <code>ctags</code> command-line tool. If available, it uses <code>ctags</code> to perform a
    comprehensive, multi-language scan of the repository. This is the most
    robust and accurate method.
2.  <strong>AST Fallback (Python-only):</strong> If <code>ctags</code> is not found, the script falls
    back to using Python's built-in Abstract Syntax Tree (<code>ast</code>) module. This
    method parses all <code>.py</code> files and extracts symbol information for Python
    code. While less comprehensive than <code>ctags</code>, it ensures that a baseline
    symbol map is always available.</p>
<p>The resulting <code>symbols.json</code> artifact is a critical input for the agent's
orientation and planning phases, allowing it to quickly locate relevant code
and understand the structure of the repository without having to read every file.</p>
<p><strong>Public Functions:</strong></p>
<ul>
<li>
<h4 id="def-generate_symbols_with_astroot_dir"><code>def generate_symbols_with_ast(root_dir='.')</code></h4>
</li>
</ul>
<blockquote>
<p>Fallback to generate a symbol map for Python files using the AST module.</p>
</blockquote>
<ul>
<li>
<h4 id="def-generate_symbols_with_ctagsroot_dir"><code>def generate_symbols_with_ctags(root_dir='.')</code></h4>
</li>
</ul>
<blockquote>
<p>Generates a symbol map using Universal Ctags.</p>
</blockquote>
<ul>
<li>
<h4 id="def-has_ctags"><code>def has_ctags()</code></h4>
</li>
</ul>
<blockquote>
<p>Check if Universal Ctags is installed and available in the PATH.</p>
</blockquote>
<ul>
<li>
<h4 id="def-main_15"><code>def main()</code></h4>
</li>
</ul>
<blockquote>
<p>Main function to generate and save the symbol map.</p>
</blockquote>
<hr />
<h2 id="utils-directory"><code>utils/</code> Directory</h2>
<h3 id="utils__init__py"><code>utils/__init__.py</code></h3>
<p><em>No module-level docstring found.</em></p>
<h3 id="utilsloggerpy"><code>utils/logger.py</code></h3>
<p>Provides a standardized, schema-validated logger for producing structured JSONL logs.</p>
<p>This module contains the <code>Logger</code> class, which is responsible for creating all
entries in the <code>logs/activity.log.jsonl</code> file. This is a critical component for
maintaining an auditable, machine-readable record of the agent's actions.</p>
<p>The logger enforces a strict structure on all log entries by validating them
against a formal JSON schema, which is extracted from the <code>LOGGING_SCHEMA.md</code>
document. This ensures that every log entry, regardless of its source, is
consistent and contains the required fields.</p>
<p>Key features of the <code>Logger</code> class:
- <strong>Schema Validation:</strong> Each log entry is validated against the official
  project schema before being written to disk, preventing data corruption.
- <strong>Structured Data:</strong> Logs are written in JSONL format, where each line is a
  valid JSON object, making them easy to parse and query.
- <strong>Session Management:</strong> It automatically assigns a unique <code>session_id</code> to
  all logs generated during its lifecycle, allowing actions to be traced back
  to a specific run.
- <strong>Automatic Timestamps:</strong> It injects a UTC timestamp into every log entry,
  providing a precise timeline of events.</p>
<p>This centralized logger is the sole mechanism by which the agent should record
its activities, ensuring a single source of truth for all post-mortem analysis
and self-improvement activities.</p>
<p><strong>Public Classes:</strong></p>
<ul>
<li>
<h4 id="class-logger"><code>class Logger</code></h4>
</li>
</ul>
<blockquote>
<p>A class to handle structured logging to a JSONL file, validated against a schema.</p>
</blockquote>
<p><strong>Methods:</strong></p>
<ul>
<li>
<h5 id="def-__init__self-schema_pathlogging_schemamd-log_pathlogsactivitylogjsonl"><code>def __init__(self, schema_path='LOGGING_SCHEMA.md', log_path='logs/activity.log.jsonl')</code></h5>
<blockquote>
<p>Initializes the Logger, loading the schema and setting up the session.</p>
<p>Args:
    schema_path (str): The path to the Markdown file containing the logging schema.
    log_path (str): The path to the log file to be written.</p>
</blockquote>
</li>
<li>
<h5 id="def-logself-phase-task_id-plan_step-action_type-action_details-outcome_status-outcome_message-error_detailsnone-evidence"><code>def log(self, phase, task_id, plan_step, action_type, action_details, outcome_status, outcome_message='', error_details=None, evidence='')</code></h5>
<blockquote>
<p>Constructs, validates, and writes a log entry.</p>
<p>Args:
    phase (str): The current protocol phase (e.g., "Phase 7").
    task_id (str): The ID of the current task.
    plan_step (int): The current plan step number.
    action_type (str): The type of action (e.g., "TOOL_EXEC").
    action_details (dict): Details specific to the action.
    outcome_status (str): The outcome of the action ("SUCCESS", "FAILURE").
    outcome_message (str, optional): A message describing the outcome. Defaults to "".
    error_details (dict, optional): Structured error info if the outcome is a failure. Defaults to None.
    evidence (str, optional): Citation for the action. Defaults to "".</p>
<p>Raises:
    ValidationError: If the generated log entry does not conform to the schema.</p>
</blockquote>
</li>
</ul>
<hr />
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;critic-meta-protocol-001&quot;,
  &quot;description&quot;: &quot;A meta-protocol that governs the behavior and evaluation criteria of the Code Review Critic agent.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;protocol-as-source-code&quot;,
      &quot;description&quot;: &quot;The `protocols/` directory and all its contents (`.md`, `.json` files) MUST be treated as functional source code. Changes to these files directly alter the agent's operational capabilities and governing rules.&quot;,
      &quot;enforcement&quot;: &quot;The Code Review Critic must analyze changes in this directory with the same rigor as changes to `.py` files.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;built-in-tools-are-valid&quot;,
      &quot;description&quot;: &quot;The agent's execution environment provides a set of built-in tools (e.g., `read_file`, `delete_file`, `pre_commit_instructions`). The implementation of these tools does not reside within the repository. A protocol change that adds a built-in tool to the `associated_tools` list is a valid and complete functional change.&quot;,
      &quot;enforcement&quot;: &quot;The Code Review Critic must not flag a change as 'incomplete' or 'non-functional' solely because the implementation of a built-in tool is not present in the repository.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;functional-change-definition&quot;,
      &quot;description&quot;: &quot;A change is considered 'functional' if it correctly modifies the agent's operational rules or capabilities, as defined by the combination of Python source code and the protocol source files in `protocols/`.&quot;,
      &quot;enforcement&quot;: &quot;The Code Review Critic's evaluation of 'functionality' must encompass both traditional code and protocol definitions.&quot;
    }
  ]
}
</code></pre>
<hr />
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;critic-reset-prohibition-001&quot;,
  &quot;description&quot;: &quot;A specific, high-priority protocol that forbids the Code Review Critic agent from using the 'reset_all' tool.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;critic-no-reset&quot;,
      &quot;description&quot;: &quot;The agent role-playing as the 'Code Review Critic' is explicitly forbidden from invoking the 'reset_all' tool under any circumstances. This is a critical safeguard to prevent the loss of work during the review process.&quot;,
      &quot;enforcement&quot;: &quot;This rule is enforced by its inclusion in the compiled AGENTS.md, which serves as the context for the Code Review Critic. The critic must be programmed to parse and adhere to this prohibition.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;reset_all&quot;
  ]
}
</code></pre>
<hr />
<h1 id="protocol-deep-research-cycle">Protocol: Deep Research Cycle</h1>
<p>This protocol defines a standardized, multi-step plan for conducting in-depth research on a complex topic. It is designed to be a reusable, callable plan that ensures a systematic and thorough investigation.</p>
<p>The cycle consists of four main phases:
1.  <strong>Initial Scoping &amp; Keyword Generation:</strong> The agent uses its initial understanding of the topic to generate a set of search keywords.
2.  <strong>Broad Information Gathering:</strong> The agent uses the keywords to perform broad web searches and collect a list of relevant URLs.
3.  <strong>Targeted Information Extraction:</strong> The agent visits the most promising URLs to extract detailed information.
4.  <strong>Synthesis &amp; Summary:</strong> The agent synthesizes the gathered information into a coherent summary, which is saved to a research report file.</p>
<p>This structured approach ensures that research is not ad-hoc but is instead a repeatable and verifiable process.</p>
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;deep-research-cycle-001&quot;,
  &quot;description&quot;: &quot;A standardized, callable plan for conducting in-depth research on a complex topic.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;structured-research-phases&quot;,
      &quot;description&quot;: &quot;The deep research plan MUST follow a structured four-phase process: Scoping, Broad Gathering, Targeted Extraction, and Synthesis.&quot;,
      &quot;enforcement&quot;: &quot;The plan's structure itself enforces this rule. The `lint` command can be extended to validate the structure of registered research plans.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;google_search&quot;,
    &quot;view_text_website&quot;,
    &quot;create_file_with_block&quot;
  ]
}
</code></pre>
<hr />
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;protocol-reset-all-pre-check-001&quot;,
  &quot;description&quot;: &quot;A protocol that mandates a pre-execution check for the `reset_all` tool to prevent unauthorized use.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;agent-must-verify-token&quot;,
      &quot;description&quot;: &quot;Before invoking the `reset_all` tool, the agent MUST first use the `list_files` tool to verify that the `authorization.token` file exists in the repository root. The agent must not proceed with the `reset_all` call if the token is not found.&quot;,
      &quot;enforcement&quot;: &quot;This rule is enforced by the agent's own decision-making logic. The agent's plan must show the `list_files` check occurring before the `reset_all` call.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;reset_all&quot;,
    &quot;list_files&quot;
  ]
}
</code></pre>
<hr />
<pre><code class="language-json">{
  &quot;protocol_id&quot;: &quot;research-fdc-001&quot;,
  &quot;description&quot;: &quot;Defines the formal Finite Development Cycle (FDC) for conducting deep research.&quot;,
  &quot;rules&quot;: [
    {
      &quot;rule_id&quot;: &quot;specialized-fsm&quot;,
      &quot;description&quot;: &quot;The Research FDC must be governed by its own dedicated Finite State Machine, defined in `tooling/research_fsm.json`. This FSM is tailored for a research workflow, with states for gathering, synthesis, and reporting.&quot;,
      &quot;enforcement&quot;: &quot;The `master_control.py` orchestrator must load and execute plans against this specific FSM when initiating an L4 Deep Research Cycle.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;executable-plans&quot;,
      &quot;description&quot;: &quot;Research plans must be generated by `tooling/research_planner.py` as valid, executable plans that conform to the `research_fsm.json` definition. They are not just templates but formal, verifiable artifacts.&quot;,
      &quot;enforcement&quot;: &quot;The output of the research planner must be linted and validated by the `fdc_cli.py` tool using the `research_fsm.json`.&quot;
    },
    {
      &quot;rule_id&quot;: &quot;l4-invocation&quot;,
      &quot;description&quot;: &quot;The L4 Deep Research Cycle is the designated mechanism for resolving complex 'unknown unknowns'. It is invoked by the main orchestrator when a task requires knowledge that cannot be obtained through simple L1-L3 orientation probes.&quot;,
      &quot;enforcement&quot;: &quot;The `master_control.py` orchestrator is responsible for triggering the L4 cycle.&quot;
    }
  ],
  &quot;associated_tools&quot;: [
    &quot;tooling/master_control.py&quot;,
    &quot;tooling/research_planner.py&quot;,
    &quot;tooling/research.py&quot;,
    &quot;tooling/fdc_cli.py&quot;
  ]
}
</code></pre>
<hr />
</article>
    </main>
    <footer>
        <p><em>This page was automatically generated from the repository's source files.</em></p>
    </footer>
</body>
</html>
